% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Exploratory Data Analysis with R},
  pdfauthor={Dylan Childs},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}

\usepackage{color}
\usepackage{framed}
\setlength{\fboxsep}{.8em}

\newenvironment{greybox}{
  \definecolor{shadecolor}{rgb}{0.95,0.95,0.95}  % grey
  \color{black}
  \begin{shaded}}
 {\end{shaded}}
 
 \newenvironment{infobox}[1]
  {
  \begin{itemize}
  \renewcommand{\labelitemi}{
    \raisebox{-.7\height}[0pt][0pt]{
      {\setkeys{Gin}{width=3em,keepaspectratio}
        \includegraphics{images/#1}}
    }
  }
  \setlength{\fboxsep}{1em}
  \begin{greybox}
  \item
  }
  {
  \end{greybox}
  \end{itemize}
  }
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Exploratory Data Analysis with R}
\author{Dylan Childs}
\date{2021-04-19}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{what-you-will-learn}{%
\chapter*{What you will learn}\label{what-you-will-learn}}
\addcontentsline{toc}{chapter}{What you will learn}

This book provides a self-contained introduction to how to use R for exploratory data analysis. Think of it as a resource to be referred to when needed. There is no need to memorise everything in this book. Instead, aim to understand the key concepts and familiarise yourself with the content, so that you know where to look for information when you need it. The details will get easier with practise.

\hypertarget{aims}{%
\section*{Aims}\label{aims}}
\addcontentsline{toc}{section}{Aims}

This book has three related aims:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Introduce the R ecosystem. R is widely used by biologists and environmental scientists to manipulate and clean data, produce high quality figures, and carry out statistical analyses. We will teach you some basic R programming so that you are in a position to address these needs in future if you need to. You don't have to become an expert programmer to have a successful career in biology but knowing a little bit of programming has almost become a prerequisite for doing research in the 21\textsuperscript{st} century.
\item
  Demonstrate how to use R to carry out data manipulation and visualisation. Designing good experiments, collecting data, and analysis are hard, and these activities often take a great deal time and money. If you want to effectively communicate your hard-won results, it is difficult to beat a good figure or diagram; conversely, if you want to be ignored, put everything into a boring table. R is really good at producing figures, so even if you end up just using it as a platform for visualising data, your time hasn't been wasted.
\item
  Provides a foundation for learning statistics later on. If you want to be a biologist, particularly one involved in research, there is really no way to avoid using statistics. You might be able to dodge it by becoming a theoretician, but if that really is your primary interest you should probably being studying for a mathematics degree. For the rest of us who collect and analyse data knowing about statistics is essential: it allows us to distinguish between real patterns (the ``signal'') and chance variation (the ``noise'').
\end{enumerate}

\hypertarget{topics}{%
\section*{Topics}\label{topics}}
\addcontentsline{toc}{section}{Topics}

The topics we will cover are divided into three `blocks':

The \textbf{Getting Started with R} block introduces the R language and the RStudio environment. The aim is to quickly run through what you need to know to start using R productively. This includes some basic terminology, how to use R packages, and how to access help. We are not trying to turn you into an expert programmer---though you may be surprised to discover that you do enjoy it. However, by the end of this block you will know enough about R to begin learning the practical material that follows.

The \textbf{Data Wrangling} block aims to show you how to manipulate data with R. If you regularly work with data a large amount of time will inevitably be spent getting data into the format you need. The informal name for this is `data wrangling'. This topic that is often not taught to beginners, which is a shame because mastering the art of data wrangling saves time in the long run. We'll learn how to get data into and out of R, makes subsets of important variables, create new variables, summarise your data, and so on.

The \textbf{Exploratory Data Analysis} block is all about using R to help you understand and describe your data. The first step in any analysis after you have managed to wrangle the data into shape should involve some kind of visualisation or numerical summary. You will learn how to do this using one of the best plotting systems in R: \textbf{ggplot2}. We will review the different kinds of `variables' you might have to analyse, discuss the different ways you can describe them, and then learn how to explore relationships between variables.

\hypertarget{technologies}{%
\section*{Technologies}\label{technologies}}
\addcontentsline{toc}{section}{Technologies}

\hypertarget{what-is-r}{%
\subsection*{What is R?}\label{what-is-r}}
\addcontentsline{toc}{subsection}{What is R?}

The answer to this question very much depends on who you ask. We could go on and on about the various features that R possesses. R is a functional programming language, it supports object orientation, etc etc\ldots{} but these kinds of explanations are only helpful to someone who already knows about computer languages. Here's what you need to know\ldots{} When a typical R user talks about ``R'' they are often referring to two things at once, the GNU R language and the ecosystem that exists around the language:

\begin{itemize}
\item
  R is all about \textbf{data analysis}. We can carry out any standard statistical analysis in R, as well as access a huge array of more sophisticated tools with impressive names like ``structural equation model'', ``random forests'' and ``penalized regression''. These days, when statisticians and computer scientists develop a new analysis tool, they often implement it in R first. This means a competent R user can always access the latest, cutting edge analysis tools. R also has the best graphics and plotting facilities of any platform. With sufficient expertise, we can make pretty much any type of figure we need (e.g.~scatter plots, phylogenetic trees, spatial maps, or even \href{http://www.r-project.org/screenshots/volcano-image.jpg}{volcanoes}). In short, R is a very productive environment for doing data analysis.
\item
  Because R is such a good environment for data analysis, a very large \textbf{community of users} has grown up around it. The size of this community has increased steadily since R was created, but this growth has really increased up in the last 5-10 years or so. In the early 2000s there were very few books about R and the main way to access help online was through the widely-feared R mailing lists. Now, there are probably hundreds of books about different aspects of R, online tutorials written by enthusiasts, and many websites that exist solely to help people learn R. The resulting ecosystem is vast, and though it can be difficult to navigate at times, when we run into an R-related problem the chances are that the answer is already written down somewhere\footnote{The other big change is that R is finally starting to become part of the commercial landscape---learning how to use it can only improve your job prospects.}.
\end{itemize}

R is not just about data analysis. R is a fully-fledged programming language, meaning that once you become proficient with it you can do things such as construct numerical simulation models, solve equations, query websites, send emails or carry out many other tasks we don't have time to write down. We won't do any of this year or next but it is worth noting that R can do much more than just analyse data if we need it to.

\hypertarget{what-is-rstudio}{%
\subsection*{What is RStudio?}\label{what-is-rstudio}}
\addcontentsline{toc}{subsection}{What is RStudio?}

R is essentially just a computer program that sits there and waits for instructions in the form of text. Those instructions can be typed in by a user or they can be sent to it from another program. R also runs in a variety of different environments. The job of RStudio is to provide an environment that makes R a more pleasant and productive tool.

\begin{infobox}{warning}

\hypertarget{r-and-rstudio-are-not-the-same-thing.}{%
\subsubsection*{R and RStudio are not the same thing.}\label{r-and-rstudio-are-not-the-same-thing.}}
\addcontentsline{toc}{subsubsection}{R and RStudio are not the same thing.}

RStudio is a different program from R---it is installed separately and occupies its own place in the Programs menu (Windows PC) or Applications folder (Mac). We can run R without RStudio if we need to, but we cannot run RStudio without R. Remember that!

\end{infobox}

One way to get a sense of why RStudio is a Very Good Thing is to look at what running R without it is like. The simplest way to run it on a Linux or Unix-based machine (like a Mac) is to use something called the Terminal. It's well beyond the scope of this book to get into what this is, but in a nutshell, the Terminal provides a low-level, text-based way to interact with a computer. Here is what R looks like running inside a Terminal on a Mac:

\begin{center}\includegraphics[width=18.94in]{images/R-terminal} \end{center}

We can run R in much the same way on Windows using the ``Command Prompt'' if we need to. The key thing you need to take away from that screenshot is that running R like this is very ``bare bones''. We typed the letter ``R'' in the Terminal and hit Enter to start R. It printed a little information as it started up and then presented us with ``the prompt'' (\texttt{\textgreater{}}), waiting for input. This is where we type or paste in instructions telling R what to do. There is no other way to interact with it when we run R like this -- no menus or buttons, just a lonely prompt waiting for instructions.

So what is RStudio? In one sense RStudio is just another Graphical User Interface for R which improves on the ``bare bones'' experience. However, it is a GUI on steroids. It is more accurate to describe it as an \href{http://en.wikipedia.org/wiki/Integrated_development_environment}{Integrated Development Environment} (IDE). There is no all-encompassing definition of an IDE, but they all exist to make programmer's lives easier by integrating various useful tools into a single piece of software. From the perspective of this book, there are four key features that we care about:

\begin{itemize}
\item
  The R interpreter---the thing that was running in the Terminal above---runs inside RStudio. It's accessed via a window labelled Console. This is where we type in instructions we want to execute when we are working directly with R. The Console also shows us any output that R prints in response to these instructions. So if we just want the ``bare bones'' experience, we can still have it.
\item
  RStudio provides facilities for working with R programs using something called a Source Code Editor. An R program ( also called a ``script'')" is just is a collection of instructions in the R language that have been saved to a text file. Nothing more! However, it is much easier to work with a script using a proper Source Code Editor than an ordinary text editor like Notepad.
\item
  An good IDE like RStudio also gives you a visual, point-and-click means of accessing various language-specific features. This is a bit difficult to explain until we have have actually used some of these, but trust us, being able to do things like manage packages, set working directories, or inspect objects we've made simplifies day-to-day use of R. This especially true for new users.
\item
  RStudio is cross-platform---it will run on a Windows PC, a Linux PC or a Mac. In terms of the appearance and the functionality it provides, RStudio is exactly the same on each of these platforms. If we learn to work with R via RStudio on a Windows PC, it's no problem migrating to a Mac or Linux PC later on if we need to. This is a big advantage for those of us who work on multiple platforms.
\end{itemize}

We'll only scratch the surface of what RStudio can do. The reason for introducing a powerful tool like RStudio is because one day you may need to access sophisticated features like debugging facilities, package build tools, and repository management. RStudio makes it easy to use these advanced tools.

\hypertarget{how-to-use-this-book}{%
\chapter*{How to use this book}\label{how-to-use-this-book}}
\addcontentsline{toc}{chapter}{How to use this book}

We have adopted a number of formatting conventions in this book to distinguish between normal text, R code, file names, and so on. You need to be aware to make best use of the book.

\hypertarget{text-instructions-and-explanations}{%
\section*{Text, instructions, and explanations}\label{text-instructions-and-explanations}}
\addcontentsline{toc}{section}{Text, instructions, and explanations}

Normal text---instructions, explanations and so on---are written in the same type as this document. We will tend to use bold for emphasis and italics to highlight specific technical terms when they are first introduced. In addition:

\begin{itemize}
\tightlist
\item
  \texttt{This\ typeface} is used to distinguish R code within a sentence of text: e.g.~``We use the \texttt{mutate} function to change or add new variables.''
\item
  A sequence of selections from an RStudio menu is indicated as follows: e.g.~\textbf{File ▶ New File ▶ R Script}
\item
  File names referred to in general text are given in upper case in the normal typeface: e.g.~MYFILE.CSV.
\end{itemize}

At various points in the text you will come across text in different coloured boxes. These are designed to highlight stand-alone exercises or little pieces of supplementary information that might otherwise break the flow. There are three different kinds of boxes:

\begin{infobox}{action}

\hypertarget{action}{%
\subsubsection*{Action!}\label{action}}
\addcontentsline{toc}{subsubsection}{Action!}

This is an \textbf{action} box. We use these when we want you to do something. Do not ignore these boxes.

\end{infobox}

\begin{infobox}{information}

\hypertarget{information}{%
\subsubsection*{Information!}\label{information}}
\addcontentsline{toc}{subsubsection}{Information!}

This is an \textbf{information} box. These aim to offer a discussion of why something works the way it does.

\end{infobox}

\begin{infobox}{warning}

\hypertarget{warning}{%
\subsubsection*{Warning!}\label{warning}}
\addcontentsline{toc}{subsubsection}{Warning!}

This is a \textbf{warning} box. These usually highlight a common `gotcha' that might trip up new users.

\end{infobox}

\hypertarget{r-code-and-output}{%
\section*{R code and output}\label{r-code-and-output}}
\addcontentsline{toc}{section}{R code and output}

We try to illustrate ideas using snippets of real R code where possible. It's a good idea to run these when working through a topic. The best way to learn something is to use it. Of course, in order to do that we need to know what we're looking at\ldots{} Stand alone snippets will be formatted like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tmp }\OtherTok{\textless{}{-}} \DecValTok{1}
\FunctionTok{print}\NormalTok{(tmp)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

At this point it does not matter what the above actually means. You just need to understand how the formatting of R code in this book works. The lines that start with \texttt{\#\#} show us what R prints to the screen after it evaluates an instruction and does whatever was asked of it, that is, they show the output. The lines that \textbf{do not} start with \texttt{\#\#} show us the instructions, that is, they show us the input. So remember, the absence of \texttt{\#\#} shows us what we are asking R to do, otherwise we are looking at something R prints in response to these instructions.

\hypertarget{get-up-and-running}{%
\chapter*{Get up and running}\label{get-up-and-running}}
\addcontentsline{toc}{chapter}{Get up and running}

\hypertarget{different-ways-to-run-rstudio}{%
\section*{Different ways to run RStudio}\label{different-ways-to-run-rstudio}}
\addcontentsline{toc}{section}{Different ways to run RStudio}

We can run RStudio in a variety of different ways---

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Most people use the version of RStudio called \textbf{RStudio Desktop}, either in its free-to-use guise (Open Source Edition) or the commercial version (RStudio Desktop Pro). The desktop version of RStudio are stand-alone applications that run locally on a computer and have to be installed like any other piece of software. This is generally easy, but you can run into problems if you have an old computer or a Chromebook.
\item
  The second way to use RStudio is by accessing a version called \textbf{RStudio Server} through a web browser. RStudio Server is usually administered by professional IT people. Life is easy if you belong to an organisation that has set up RStudio Server, because all you need to get going is a user account, a semi-modern web browser and an internet connection.
\item
  Finally, the company that makes RStudio also runs a commercial cloud-based solution called \href{https://rstudio.com/products/cloud/}{RStudio Cloud}. This allows anyone web browser and an internet connection to use R and RStudio. Although there is a free version, this is fairly limited meaning you end up paying a monthly fee to do `real work'. However, RStudio Cloud can be a good backup option when all else fails.
\end{enumerate}

\begin{infobox}{information}

\hypertarget{do-you-need-to-install-r-and-rstudio}{%
\subsubsection*{Do you need to install R and RStudio?}\label{do-you-need-to-install-r-and-rstudio}}
\addcontentsline{toc}{subsubsection}{Do you need to install R and RStudio?}

If you're lucky enough to have access to RStudio Server or an RStudio Cloud account you don't need to install R and RStudio on your own computer. Just access those cloud service through a decent web browser. That said, it can be useful to have a local copy on your own computer, e.g.~because you don't have a reliable internet connection. Obviously, if you can't access those cloud services you'll have to install R and RStudio to use them!

\end{infobox}

\hypertarget{installing-r-and-rstudio-locally}{%
\section*{Installing R and RStudio locally}\label{installing-r-and-rstudio-locally}}
\addcontentsline{toc}{section}{Installing R and RStudio locally}

It does not need to cost a penny to use R and RStudio. The source code for R is open source, meaning anyone with the time, energy and expertise is free to download it and alter it as they please. Open source does not necessarily mean free, as in it costs £0 to use, but luckily R \textbf{is} free in this sense. On the other hand, RStudio is developed and maintained by a for-profit company (called\ldots{} RStudio). Luckily, because they make their money selling professional software and services, the open source desktop version of RStudio is also free to use. This section will show you how to download and install R and RStudio.

\hypertarget{installing-r}{%
\subsubsection*{Installing R}\label{installing-r}}
\addcontentsline{toc}{subsubsection}{Installing R}

In order to install R you need to download the appropriate installer from the Comprehensive R Archive Network (\href{http://cran.r-project.org}{CRAN}). We are going to use the ``base distribution'' as this contains everything you need to use R under normal circumstances. There is a single \href{http://cran.r-project.org/bin/windows/base/}{installer} for Windows. On a Mac, it's important to match the \href{http://cran.r-project.org/bin/macosx/}{installer} to the version of OS X. In either case, R uses a the standard install mechanism that should be familiar to anyone who has installed an application on their machine. There is no need to change the default settings---doing so will probably lead to problems later on.

After installing R it should be visible in the Programs menu on a Windows computer or in the Applications folder on a Mac. In fact, that thing labelled `R' is very simple a \href{http://en.wikipedia.org/wiki/Graphical_user_interface}{Graphical User Interface} (GUI) for R. When we launch the R GUI we're presented with something called the Console, which is where we can interact directly with R by typing things at the so-called prompt, \texttt{\textgreater{}}, and a few buttons and menus for managing common tasks. We will not study the GUIs in any detail because we recommend using RStudio, but it's important to be aware they exist so that you don't accidentally use them instead of RStudio.

\hypertarget{installing-rstudio}{%
\subsection*{Installing RStudio}\label{installing-rstudio}}
\addcontentsline{toc}{subsection}{Installing RStudio}

RStudio can be downloaded from the RStudio \href{http://www.rstudio.com/products/RStudio/\#Desk}{download page}. The one to go for is the Open Source Edition of RStudio Desktop, \textbf{not} the commercial version of RStudio Desktop called RStudio Desktop Pro. RStudio installs like any other piece of software---just run the installer and follow the instructions. There's no need to configure after after installation.

\hypertarget{a-quick-look-at-rstudio}{%
\section*{A quick look at RStudio}\label{a-quick-look-at-rstudio}}
\addcontentsline{toc}{section}{A quick look at RStudio}

Once installed RStudio runs like any other stand-alone application via the Programs menu or the Applications folder on a Windows PC or Mac, respectively (though it will only work properly if R is also installed). Here is how RStudio appears the first time it runs on a Mac:

\begin{center}\includegraphics[width=40.44in]{images/RStudio-3-pane} \end{center}

There are three panes inside a single window, which we have labelled with red numbers. Each of these has a well-defined purpose. Let's take a quick look at these:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The large window on the left is the Console. This is basically where R lives inside RStudio. The Console lets you know what R is doing and provides a mechanism to interact with R by typing instructions. All this happens at the prompt, \texttt{\textgreater{}}. You will be working in the Console in the next chapter so we won't say any more about this here.
\item
  The window at the top right contains two or more tabs. One of these, labelled \textbf{Environment}, allows us to see all the R `objects' we can currently access. Another, labelled \textbf{History}, allows us to see a list of instructions we've previously sent to R. The buttons in this tab allow us to reuse or save these instructions.
\item
  The window at the bottom right contains five tabs. The first, labelled \textbf{Files}, gives us a way to interact with the files and folders. The next tab, labelled \textbf{Plots}, is where any figures we produce are displayed. This tab also allows you to save your figures to file. The \textbf{Packages} tab is where we view, install and update packages used to extend the functionality of R. The \textbf{Help} tab is where you can access and display various different help pages. Finally, \textbf{Viewer} is an embedded web browser.
\end{enumerate}

\begin{infobox}{information}

\hypertarget{my-rstudio-looks-different}{%
\subsubsection*{My RStudio looks different!}\label{my-rstudio-looks-different}}
\addcontentsline{toc}{subsubsection}{My RStudio looks different!}

Don't be alarmed if RStudio looks different on your computer. RStudio saves its state between different sessions, so if you've have already messed about with it you will see these changes when you restart it. For example, there is a fourth pane that is often be visible in RStudio---the source code Editor we mentioned above.

\end{infobox}

\hypertarget{working-at-console}{%
\section*{Working at the Console in RStudio}\label{working-at-console}}
\addcontentsline{toc}{section}{Working at the Console in RStudio}

R was designed to be used interactively---it is what is known as an \textbf{interpreted language}, which we can interact with via something called a Command Line Interface (CLI). This is just a fancy way of saying that we can type instructions to ``do something'' into the Console and those instructions will then be interpreted when we hit the Enter key. If our R instructions do not contain any errors, R will then do something like read in some data, perform a calculation, make a figure, and so on. What actually happens obviously depends on what we ask it to do.

Let's briefly see what all this means by doing something very simple with R. Type \texttt{1\ +\ 3} at the Console and hit the Enter key:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{+}\DecValTok{3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

The first line above just reminds us what we typed into the Console. The line after that beginning with \texttt{\#\#} shows us what R printed to the Console after reading and evaluating our instructions.

What just happened? We can ignore the \texttt{{[}1{]}} bit for now (the meaning of this will become clear later in the course). What are we left with -- the number 4. The instruction we gave R was in effect ``evaluate the expression \texttt{1\ +\ 3}''. R read this in, decided it was a valid R expression, evaluated the expression, and then printed the result to the Console for us. Unsurprisingly, the expression \texttt{1\ +\ 3} is a request to add the numbers 1 and 3, and so R prints the number 4 to the Console.

OK\ldots{} that was not very exciting. In the next chapter we will start learning to use R to carry out more useful calculations. The important take-away from this is that this sequence of events---reading instructions, evaluating those instructions and printing their output (if there is any output)---happens every time we type or paste something into the Console and hit Enter.

\begin{infobox}{information}

\hypertarget{what-does-that-word-expression-mean}{%
\subsubsection*{What does that word `expression' mean?}\label{what-does-that-word-expression-mean}}
\addcontentsline{toc}{subsubsection}{What does that word `expression' mean?}

Why do we keep using that word \emph{expression}? Here is what the \href{http://en.wikipedia.org/wiki/Expression_(computer_science)}{Wikipedia page} says:

\begin{quote}
An expression in a programming language is a combination of explicit values, constants, variables, operators, and functions that are interpreted according to the particular rules of precedence and of association for a particular programming language, which computes and then produces another value.
\end{quote}

That probably doesn't make much sense! In simple terms, an R expression is a small set of instructions that tell R to do something. That's it. We could write `instructions' instead of `expressions' throughout this book but we may as well use the correct word.

\end{infobox}

\hypertarget{part-introduction-to-r}{%
\part{Introduction to R}\label{part-introduction-to-r}}

\hypertarget{quick-intro-to-r}{%
\chapter{A quick introduction to R}\label{quick-intro-to-r}}

\hypertarget{r-calculator}{%
\section{Using R as a big calculator}\label{r-calculator}}

\hypertarget{basic-arithmetic}{%
\subsection{Basic arithmetic}\label{basic-arithmetic}}

The \protect\hyperlink{working-at-console}{Get up and running chapter} showed that R could handle familiar arithmetic operations: division, multiplication, addition and subtraction. If we want to add or subtract two numbers, we place the \texttt{+} or \texttt{-} symbol in between two numbers and hit Enter. R will read the arithmetic expression, evaluate it, and print the result to the Console. This works as you'd expect:

\emph{Addition}--

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{3} \SpecialCharTok{+} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

\emph{Subtraction}--

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{5} \SpecialCharTok{{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

Multiplication and division are no different. However, we can't use \texttt{x} or \texttt{÷} symbols for these operations. Instead, use \texttt{*} and \texttt{/} to multiply and divide:

\emph{Multiplication}--

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{7} \SpecialCharTok{*} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 14
\end{verbatim}

\emph{Division}--

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{3} \SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.5
\end{verbatim}

We can also exponentiate numbers, i.e.~raise one number to the power of another. Use the \texttt{\^{}} operator to do this:

\emph{Exponentiation}--

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{4}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 16
\end{verbatim}

This raises 4 to the power of 2 (i.e.~we squared it). In general, we can raise a number \texttt{x} to the power of \texttt{y} using \texttt{x\^{}y}. Neither \texttt{x} nor \texttt{y} need to be whole numbers either.

\begin{infobox}{information}

\hypertarget{operators}{%
\subsubsection*{Operators?}\label{operators}}
\addcontentsline{toc}{subsubsection}{Operators?}

What does `operator' mean? An operator is simply a symbol (or sequence of symbols) that does something specific with one or more inputs. For example, operators like \texttt{/}, \texttt{*}, \texttt{+} and \texttt{-} carry out arithmetic calculations with pairs of numbers. Operators are one of the basic building blocks of a programming language like R.

\end{infobox}

\hypertarget{combining-arithmetic-operations}{%
\subsection{Combining arithmetic operations}\label{combining-arithmetic-operations}}

We can also combine arithmetic operations. Assume we want to subtract 6 from 2\textsuperscript{3}. The expression to perform this calculation is:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{{-}} \DecValTok{6}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

Simple enough, but what if we had wanted to carry out a slightly longer calculation that required the last answer to then be divided by 2? This is the \textbf{wrong} way to do this:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{{-}} \DecValTok{6} \SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5
\end{verbatim}

The answer we expect here is \(1\). So what happened? R evaluated \(6/2\) first and then subtracted this answer from \(2^3\).

If that's obvious, great. If not, it's time to learn about \textbf{order of precedence}. R uses a standard set of rules to decide the order in which calculations feed into one another to unambiguously evaluate any expression. It uses the same order as every other computer language, which thankfully is the same one we all learn in mathematics classes at school. The order of precedence is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  exponents and roots (also, `powers' or `orders')
\item
  division and then multiplication
\item
  additional and then subtraction
\end{enumerate}

\begin{infobox}{information}

\hypertarget{bodmas-and-friends}{%
\subsubsection*{BODMAS and friends}\label{bodmas-and-friends}}
\addcontentsline{toc}{subsubsection}{BODMAS and friends}

If you find it difficult to remember the standard order of precedence there are a load of \href{http://en.wikipedia.org/wiki/Order_of_operations\#Mnemonics}{mnemonics} that can to help.

\end{infobox}

We need to control the order of evaluation to arrive at the answer we were looking for in the above example. Do this by grouping together calculations inside parentheses, i.e.~`round brackets' \texttt{(} and \texttt{)}. Here's the expression we should have used:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{2}\SpecialCharTok{\^{}}\DecValTok{3} \SpecialCharTok{{-}} \DecValTok{6}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

We can use more than one pair of parentheses to control the order of evaluation in more complex calculations. The order of evaluation then happens `inside-out'. For example, if we want to find the cube root of 2 (i.e.~2\textsuperscript{1/3}) rather than 2\textsuperscript{3} in that last calculation we would instead write:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{2}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{3}\NormalTok{) }\SpecialCharTok{{-}} \DecValTok{6}\NormalTok{) }\SpecialCharTok{/} \DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -2.370039
\end{verbatim}

The parentheses around the \texttt{1/3} are needed to ensure this is evaluated prior to being used as the exponent.

\begin{infobox}{action}

\hypertarget{working-efficiently-at-the-console}{%
\subsubsection*{Working efficiently at the Console}\label{working-efficiently-at-the-console}}
\addcontentsline{toc}{subsubsection}{Working efficiently at the Console}

Working at the Console soon gets tedious if we have to retype similar things over and over again. There is no need to do this, though. Place the cursor at the prompt and hit the up arrow. What happens? This brings back the last expression sent to R's interpreter. Hit the up arrow again to see the last-but-one expression, and so on. We go back down the list using the down arrow. Once we're at the line we need, we use the left and right arrows to move around the expression and the delete key to remove the parts we want to change. Once an expression has been edited we can hit Enter to send it to R again. Try it.

\end{infobox}

\hypertarget{problematic-calculations}{%
\section{Problematic calculations}\label{problematic-calculations}}

Now is a good time to highlight how R handles certain kinds of awkward numerical calculations. One of these involves division of a non-zero by 0. Mathematically, division of a finite number by \texttt{0} equals A Very Large Number: infinity. Some programming languages will respond to an attempt to do this with an error. R is a bit more forgiving:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{/} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] Inf
\end{verbatim}

R has a special built-in value that allows it to handle this kind of result. This is \texttt{Inf}, which stands for `infinity'.

The other special kind of value we sometimes run into is generated by calculations that don't have a well-defined numerical result. For example, look what happens when we try to divide 0 by 0:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{0} \SpecialCharTok{/} \DecValTok{0}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NaN
\end{verbatim}

The \texttt{NaN} in this result stands for `Not a Number'. R produces \texttt{NaN} because \(0 / 0\) is not defined mathematically: it produces something that is Not a Number.

The reason we are pointing out \texttt{Inf} and \texttt{NaN} is not that we expect to use them. It's important to know what they represent because they often arise due to a mistake somewhere in our code. It's hard to track down such mistakes if we don't know how \texttt{Inf} and \texttt{NaN} arise.

\begin{infobox}{information}

\hypertarget{r-as-a-fancy-calculator}{%
\subsubsection*{R as a fancy calculator}\label{r-as-a-fancy-calculator}}
\addcontentsline{toc}{subsubsection}{R as a fancy calculator}

What we've seen so far is that we can interact with R via the so-called REPL: the read-evaluate-print loop. R takes user input (e.g.~\texttt{1\ /\ 0}), evaluates it (\texttt{1\ /\ 0\ =\ Inf}), prints the results (\texttt{\#\#\ {[}1{]}\ Inf}), and then waits for the next input (e.g.~\texttt{0\ /\ 0}). This facility is handy because it means we can use R interactively, working through a set of calculations line-by-line.

\end{infobox}

\hypertarget{assignment}{%
\section{Storing and reusing results}\label{assignment}}

We've not yet tried to do anything remotely complicated or interesting beyond using parentheses to construct longer calculations. This approach is acceptable when a calculation is straightforward, but it quickly becomes unwieldy for dealing with anything more complicated.

The best way to see what we mean is by working through a simple example---solving a quadratic equation. You probably remember these from school. A quadratic equation looks like this:

\[a + bx + cx^2 = 0\] If we know the values of \(a\), \(b\) and \(c\) then we can solve this equation to find the values of \(x\) that satisfy this equation. Here's the well-known formula for these solutions: \[
x = \frac{-b\pm\sqrt{b^2-4ac}}{2a}
\] We can use R to calculate these solutions for us. Say that we want to find the solutions to the quadratic equation when \(a=1\), \(b=6\) and \(c=5\). We have to turn the above equation into a pair of R expressions:

\emph{Solution 1}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6} \SpecialCharTok{+}\NormalTok{ (}\DecValTok{6}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}}\DecValTok{4} \SpecialCharTok{*} \DecValTok{1} \SpecialCharTok{*} \DecValTok{5}\NormalTok{)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -1
\end{verbatim}

\emph{Solution 2}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6} \SpecialCharTok{{-}}\NormalTok{ (}\DecValTok{6}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}}\DecValTok{4} \SpecialCharTok{*} \DecValTok{1} \SpecialCharTok{*} \DecValTok{5}\NormalTok{)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -5
\end{verbatim}

The output tells us that the two values of \(x\) that satisfy this particular quadratic equation are -1 and -5.

But what should we do if we now need to solve a different quadratic equation? Working at the Console, we could bring up the expressions we typed (using the up arrow) and change the numbers to match the new values of \(a\), \(b\) and \(c\). However, editing expressions like this is tedious, and more importantly, it's error-prone because we have to make sure we substitute the new numbers into precisely the right positions.

A partial solution to this problem is to store the values of \(a\), \(b\) and \(c\) in some way so that we only have to change them one. We'll see why this is useful in a moment.

First, we need to learn how to store results in R. The key to this is to use the \textbf{assignment operator}, written as an arrow pointing to the left, \texttt{\textless{}-}. Sticking with the current example, we need to store the numbers 1, 6 and 5. We do this by typing out three expressions, one after the another, each time hitting enter to get R to evaluate it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}} \DecValTok{6}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{c }\OtherTok{\textless{}{-}} \DecValTok{5}
\end{Highlighting}
\end{Shaded}

The exact sequence \texttt{\textless{}-} defines the assignment operator. R won't recognise it as assignment if we try to include a space between the \texttt{\textless{}} and \texttt{-} symbols.

Notice that R didn't print anything to screen. So what actually happened? We asked R to first evaluate the expression on the right hand side of each \texttt{\textless{}-} (just a number in this case) and then \textbf{assigns the result} of that evaluation instead of printing it. Each result has a name associated with it, which appears on the left hand-side of the \texttt{\textless{}-}.

The net result of all this is that we have stored the numbers 1, 6 and 5 somewhere in R and associated them with the letters \texttt{a}, \texttt{b} and \texttt{c}, respectively. We can check whether this assignment business has worked by looking at the \textbf{Environment} tab in the top right RStudio window. There should be three `names' listed in that tab now (\texttt{a}, \texttt{b} and \texttt{c}) along with the associated numbers 1, 6 and 5.

What does this mean in practical terms? Look at what happens if we now type the letter \texttt{a} into the Console and hit Enter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

It looks the same as if we had typed the number \texttt{1} directly into the Console. We stored the output from three separate R expressions, associating each a name so that we can access it again\footnote{Technically, this is called \textbf{binding} the name to a value. You don't need to remember this.}. Whenever we use the assignment operator \texttt{\textless{}-} we are telling R to keep whatever kind of value results from the calculation on the right-hand side of \texttt{\textless{}-}, giving it the name on the left-hand side so that we can access it later.

Why is this useful? Let's imagine we want to do more than one thing with our three numbers. If we want to know their sum or their product we can now use:

\emph{Sum}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{+}\NormalTok{ c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12
\end{verbatim}

\emph{Product}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\SpecialCharTok{*}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ c}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 30
\end{verbatim}

So\ldots{} once we've stored a result and associated it with a name we can reuse it whenever needed. Returning to our example, we can now calculate the solutions to the quadratic equation by typing these two expressions into the Console:

\emph{Solution 1}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{b }\SpecialCharTok{+}\NormalTok{ (b}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}}\DecValTok{4} \SpecialCharTok{*}\NormalTok{ a }\SpecialCharTok{*}\NormalTok{ c)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -1
\end{verbatim}

\emph{Solution 2}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{b }\SpecialCharTok{{-}}\NormalTok{ (b}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}}\DecValTok{4} \SpecialCharTok{*}\NormalTok{ a }\SpecialCharTok{*}\NormalTok{ c)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -5
\end{verbatim}

Imagine we'd now like to find the solutions to a different quadratic equation where \(a=1\), \(b=5\) and \(c=5\). We only changed the value of \(b\) here. To find the new solutions we have to do two things. First we change the value of the number associated with \texttt{b}\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}} \DecValTok{5}
\end{Highlighting}
\end{Shaded}

\ldots then we bring up those lines that calculate the solutions to the quadratic equation and run them, one after the other:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{b }\SpecialCharTok{+}\NormalTok{ (b}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}}\DecValTok{4} \SpecialCharTok{*}\NormalTok{ a }\SpecialCharTok{*}\NormalTok{ c)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -1.381966
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{b }\SpecialCharTok{{-}}\NormalTok{ (b}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{{-}}\DecValTok{4} \SpecialCharTok{*}\NormalTok{ a }\SpecialCharTok{*}\NormalTok{ c)}\SpecialCharTok{\^{}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ a)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -3.618034
\end{verbatim}

We don't have to retype those expressions. We can use the up arrow to bring each one back to the prompt and hit Enter. This is much simpler than editing the expressions.

More importantly, we are beginning to see the benefits of using something like R---we can break down complex calculations into a series of steps, storing and reusing intermediate results as required.

\begin{infobox}{action}

\hypertarget{rstudio-shortcut}{%
\subsubsection*{RStudio shortcut}\label{rstudio-shortcut}}
\addcontentsline{toc}{subsubsection}{RStudio shortcut}

We use the assignment operator \texttt{\textless{}-} all the time when working with R. Because it's inefficient to type the \texttt{\textless{}} and \texttt{-} characters repeatedly, RStudio has a built-in shortcut for typing the assignment operator.

The shortcut is `Alt + \texttt{-}' . Try it now. Move the cursor to the Console, hold down the Alt key (`Option' on a Mac), and press the \texttt{-} sign key. RStudio will auto-magically add insert \texttt{\textless{}-}. \textbf{If you only learn one RStudio shortcut, learn this one!} It will save you a lot of time in the long run.

\end{infobox}

\hypertarget{how-does-assignment-work}{%
\section{How does assignment work?}\label{how-does-assignment-work}}

When we use the assignment operator \texttt{\textless{}-} to associate names and values, we refer to this as creating or modifying \textbf{a variable}. This is much less tedious than using words like `associate', `value', and `name' all the time. Why is it called a variable? What happens when we run these lines:

\emph{Create} \texttt{myvar} \emph{and print out its value}--

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myvar }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{myvar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\emph{Modify} \texttt{myvar} and \emph{and print out its new value} --

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myvar }\OtherTok{\textless{}{-}} \DecValTok{7}
\NormalTok{myvar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

The first time we used \texttt{\textless{}-} with \texttt{myvar} on the left-hand side, we \textbf{created} a variable \texttt{myvar} associated with the value 1. We then printed out the value associated with \texttt{myvar}. The second line \texttt{myvar\ \textless{}-\ 7} \textbf{modified} the value of \texttt{myvar} to be 7 (and printed this out again). This is why we refer to \texttt{myvar} as a variable: we can change its value as we please.

What happened to the old value associated with \texttt{myvar}? In short, it is gone, kaput, lost\ldots{} forever. The moment we assign a new value to \texttt{myvar} the old one is destroyed and can no longer be accessed. Remember this.

Keep in mind that the expression on the right-hand side of \texttt{\textless{}-} can be any kind of calculation and the variable can have any (valid) name we like. For example, if we want to perform the calculation \texttt{(1\ +\ 2\^{}3)\ /\ (2\ +\ 7)} and associate the result with the word \texttt{answer}, we would do this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{answer }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+} \DecValTok{2}\SpecialCharTok{\^{}}\DecValTok{3}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{+} \DecValTok{7}\NormalTok{)}
\NormalTok{answer}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

Any expression can be used on the right-hand side of the assignment operator as along as it generates an output of some kind. For example, we can create new variables from others:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{newvar }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ answer}
\end{Highlighting}
\end{Shaded}

What happened here? Start at the right-hand side of \texttt{\textless{}-}. The expression on this side contained the variable \texttt{answer} so R went to see if \texttt{answer} actually exists. It does, so it then substituted the value associated with \texttt{answer} into the calculation and assigned the resulting value of 2 to \texttt{newvar}.

Finally, look at what happens if we copy a variable using the assignment operator:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myvar }\OtherTok{\textless{}{-}} \DecValTok{7}
\NormalTok{mycopy }\OtherTok{\textless{}{-}}\NormalTok{ myvar}
\end{Highlighting}
\end{Shaded}

We now have a pair of variables, \texttt{myvar} and \texttt{mycopy}, associated with the number 7. Each of these is associated with a \textbf{different copy} of this number. If we change the value associated with one of these variables it does not change the value of the other, as this shows:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myvar }\OtherTok{\textless{}{-}} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{myvar}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mycopy}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7
\end{verbatim}

R always behaves like this unless we work hard to alter this behaviour. Remember that---every time we assign one variable to another, we actually make a completely new, independent copy of its associated value. That probably doesn't seem like an obvious or important point, but trust us, it is. It will be critical to remember this behaviour when we start learning how to manipulate data sets.

\hypertarget{global-environment}{%
\section{Global environment}\label{global-environment}}

Whenever we associate a name with a value we create a copy of both these things somewhere in the computer's memory. In R the ``somewhere'' is called an environment. We aren't going to get into a discussion of R's many different kinds of environments---that's an advanced topic well beyond the scope of this book. The one environment we do need to be aware of is the \textbf{Global Environment}.

Whenever we perform an assignment in the Console the variable we create is placed into the Global Environment. The set of variables currently in existence are listed in the \textbf{Environment} tab in RStudio. Take a look. There are two columns in the \textbf{Environment} tab: the first shows the names of the variables, the second summarises their values.

\begin{infobox}{warning}

\hypertarget{the-global-environment-is-temporary}{%
\subsubsection*{The Global Environment is temporary}\label{the-global-environment-is-temporary}}
\addcontentsline{toc}{subsubsection}{The Global Environment is temporary}

By default, R will try to save everything in the Global Environment when we close it down and restore everything when we start the next R session. It does this by writing a copy of the Global Environment to disk. In theory, this means we can close down R, reopen it, and pick things up from where we left off. \textbf{Don't rely on this behaviour!} It just increases the risk of making a mistake.

\end{infobox}

\hypertarget{naming-rules-and-conventions}{%
\section{Naming rules and conventions}\label{naming-rules-and-conventions}}

We don't have to use a single letter to name things in R. We could use the words \texttt{tom}, \texttt{dick} and \texttt{harry} in place of \texttt{a}, \texttt{b} and \texttt{c}. It might be confusing to use them, but \texttt{tom}, \texttt{dick} and \texttt{harry} are all legal names as far as to R is concerned:

\begin{itemize}
\item
  A legal name in R is any sequence of letters, numbers, \texttt{.}, or \texttt{\_}, but the sequence of characters we use must begin with a letter. Both upper and lower case letters are allowed. For example, \texttt{num\_1}, \texttt{num.1}, \texttt{num1}, \texttt{NUM1}, \texttt{myNum1} are all legal names, but \texttt{1num} and \texttt{\_num1} are not because they begin with \texttt{1} and \texttt{\_}.
\item
  R is case sensitive---it treats upper and lower case letters as different characters. This means R treats \texttt{num} and \texttt{Num} as distinct names. Forgetting about case sensitivity is a good way to create errors when using R. Try to remember that.
\end{itemize}

\begin{infobox}{warning}

\hypertarget{dont-begin-a-name-with-.}{%
\subsubsection*{\texorpdfstring{Don't begin a name with \texttt{.}}{Don't begin a name with .}}\label{dont-begin-a-name-with-.}}
\addcontentsline{toc}{subsubsection}{Don't begin a name with \texttt{.}}

We are allowed to begin a name with a \texttt{.}, but this usually is A Bad Idea. Why? Because variable names that begin with \texttt{.} are hidden from view in the Global Environment---the value it refers to exists but it's invisible. This behaviour exists to allow R to create invisible variables that control how it behaves. This is useful, but it isn't really meant to be used by the average user.

\end{infobox}

\hypertarget{using-functions}{%
\chapter{Using functions}\label{using-functions}}

\hypertarget{intro-functions}{%
\section{Introduction}\label{intro-functions}}

Functions are an essential building block of any programming language. The job of a function is to carry out a calculation or computation that would typically require many lines code to do `from scratch'. Functions allow us to reuse common computations while offering some control over the precise details of what happens. To use R effectively---even if our needs are very simple---we need to understand how to use functions. This chapter aims to explain what functions are for, how to use them, and how to avoid mistakes when doing so, without getting lost in the detail of how they work.

\hypertarget{functions-and-arguments}{%
\section{Functions and arguments}\label{functions-and-arguments}}

Functions allow us to reuse a calculation. The best way to see what we mean by this is to see one in action. The \texttt{round} function rounds numbers to a significant number of digits (no surprises there). To use it, we could type this into the Console and hit Enter:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{3.141593}\NormalTok{, }\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We have suppressed the output so that we can unpack things a bit first. We rely on the same basic construct every time we use a function. This starts with the name of the function as the prefix. In the example above, the function name is \texttt{round}. After the function name, we need a pair of opening and closing parentheses. This combination of name and parentheses alerts R to fact that we are using a function.

What about the bits inside the parentheses? These are called the \textbf{arguments} of the function. That's a horrible name, but it is the one that everyone uses, so we have to get used to it. Depending on how it was defined, a function can take zero, one, or more arguments. We will discuss this idea in more detail later in this section. In simple terms, the arguments control the behaviour of a function.

We used the \texttt{round} function with two arguments. We supplied each one as a name-value pair separated by a comma. When working with arguments, name-value pairs occur either side of the equals sign (\texttt{=}), with the argument \textbf{name} on the left-hand side and its \textbf{value} on the right-hand side. The name serves to identify which argument we are working with, and the value is the thing that controls what that argument does.

We call the process of associating argument names and values `setting the arguments' of the function (or `supplying the arguments'). Notice the similarity between supplying function arguments and the assignment operation discussed in the last topic. The difference is that name-value pairs are associated with the \texttt{=} symbol when involved in arguments.

\begin{infobox}{warning}

\hypertarget{use-to-assign-arguments}{%
\subsubsection*{\texorpdfstring{Use \texttt{=} to assign arguments}{Use = to assign arguments}}\label{use-to-assign-arguments}}
\addcontentsline{toc}{subsubsection}{Use \texttt{=} to assign arguments}

\textbf{Do not} use the assignment operator \texttt{\textless{}-} inside the parentheses when working with functions. This is a ``trust us'' situation---you will end up in all kinds of difficulty if you do this!

\end{infobox}

The arguments control the behaviour of a function. Our job as users is to set the values of these to get the behaviour we want. However, The function determines arguments we are allowed to use, i.e.~we are not free to choose whatever name we like\footnote{We say ``typically'', because R is a very flexible language and so there are certain exceptions to this simple rule of thumb. For now it is simpler to think of the names as constrained by the particular function we're using. Let's return to th example to see how all this works:}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{3.141593}\NormalTok{, }\AttributeTok{digits =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.14
\end{verbatim}

The \texttt{round} function rounds one or more numeric inputs and rounds these to a particular number of significant digits. The argument that specifies the number(s) to round is \texttt{x}; the second argument, \texttt{digits}, specifies the number of decimal places we require. Based on the supplied values of these arguments, \texttt{3.141593} and \texttt{2}, respectively, the \texttt{round} function spits out a value of \texttt{3.14}, which is then printed to the Console.

What if we had wanted to the answer to 3 significant digits? We would set the \texttt{digits} argument to 3:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{3.141593}\NormalTok{, }\AttributeTok{digits =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.142
\end{verbatim}

This illustrates what we mean when we say arguments control the behaviour of the function---\texttt{digits} sets the number of significant digits calculated by \texttt{round}.

\hypertarget{evaluating-arguments-and-returning-results}{%
\section{Evaluating arguments and returning results}\label{evaluating-arguments-and-returning-results}}

Whenever R evaluates a function, we refer to this action as `calling the function'. In our simple example, we called the \texttt{round} function with arguments \texttt{x} and \texttt{digits}. That said, we often just say `use the function' because that is more natural to most users.

Several things happen when we call functions: first they \textbf{evaluate} their arguments, then they perform some action, and finally (optionally) \textbf{return} a value to us. Let's work through what all that means\ldots{}

What do we mean by the word `evaluate'? When we call a function, what typically happens is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the R expression on the right-hand side of an \texttt{=} is evaluated,
\item
  the result is associated with the corresponding argument name, and
\item
  the function does its calculations using the resulting name-value pairs.
\end{enumerate}

To see how the evaluation step works, take a look at a new example using \texttt{round}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{2.3} \SpecialCharTok{+} \FloatTok{1.4}\NormalTok{, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

What happened above is that R evaluated \texttt{2.3\ +\ 1.4}, resulting in the number \texttt{3.7}, which was then associated with the argument \texttt{x}. We set \texttt{digits} to \texttt{0} this time so that \texttt{round} returns a whole number, \texttt{4}.

The important thing to realise is that the expression(s) on the right-hand side of the \texttt{=} can be anything we like. This third example essentially equivalent to the last one:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FloatTok{2.3} \SpecialCharTok{+} \FloatTok{1.4}
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =}\NormalTok{ y, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

This time we created a new variable called \texttt{y} and supplied this as the value of the \texttt{x} argument. When we use the \texttt{round} function like this, the R interpreter spots that something on the right-hand side of an \texttt{=} is a variable and associates the value of this variable with \texttt{x} argument. As long as we have defined the numeric variable \texttt{y} at some point we can use it as the value of an argument.

At the beginning of this section, we said that a function may optionally \textbf{return} a value to us when it completes its task. That word `return' refers to the process by which a function outputs a value. If we use a function at the Console the returned value is printed out. However, we can use this value in other ways. For example, there is nothing to stop us combining function calls with the arithmetic operations:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{*} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{2.64}\NormalTok{, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

Here the R interpreter evaluates the function call and then multiplies the value it returns by 2. If we want to reuse this value, we have to assign the result of function call, for example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roundnum }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*} \FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{2.64}\NormalTok{, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Using a function with \texttt{\textless{}-} is no different from the examples using multiple arithmetic operations in the last topic. The R interpreter starts on the right-hand side of the \texttt{\textless{}-}, evaluates the function call there, and only then assigns the value to \texttt{roundnum}.

\begin{infobox}{information}

\hypertarget{argument-names-vs-variable-names}{%
\subsubsection*{Argument names vs variable names}\label{argument-names-vs-variable-names}}
\addcontentsline{toc}{subsubsection}{Argument names vs variable names}

Keeping in mind what we've just learned, take a careful look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{3.7}\NormalTok{, }\AttributeTok{digits =}\NormalTok{ x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

What is going on here? The key to understanding this is to realise that the symbol \texttt{x} is used in two different ways here. When it appears on the left-hand side of the \texttt{=} it represents an argument name. When it appears on the right-hand side, it is treated as a variable name, which must have a value associated with it for the above to be valid. That is a confusing way to use the \texttt{round} function, but it is perfectly valid.

The message here is that what matters is where things appear relative to the \texttt{=}, not the symbols used to represent them.

\end{infobox}

\hypertarget{function-arguments}{%
\section{Specifying function arguments}\label{function-arguments}}

So far, we have been concentrating on functions that carry out mathematical calculations with numbers. Functions can do all kinds of things. For example, some functions are designed to extract information about other functions. Take a look at the \texttt{args} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{args}\NormalTok{(}\AttributeTok{name =}\NormalTok{ round)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## function (x, digits = 0) 
## NULL
\end{verbatim}

\texttt{args} prints a summary of the main arguments of a function. What can we learn from the summary of the arguments of \texttt{round}? Notice that the first one, \texttt{x}, is shown without an associated value, whereas the \texttt{digits} part of the summary is printed as \texttt{digits\ =\ 0}.

\textbf{The significance of this is that} \texttt{digits} \textbf{has a default value} (0 in this case). This means that we can leave out \texttt{digits} when using the round function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\AttributeTok{x =} \FloatTok{3.7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

This is the same result as we would get using \texttt{round(x\ =\ 3.7,\ digits\ =\ 0)}. This `default value' behaviour is useful because it allows us keep our R code concise. Some functions take a large number of arguments, many of which are defined with sensible defaults. Unless we need to change these default arguments, we can ignore them when we call such functions.

Notice that the \texttt{x} argument of \texttt{round} does not have a default, which means we have to supply a value. This is sensible, as the whole purpose of \texttt{round} is to round any number we give it.

There is another way to simplify our use of functions. Take a look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FloatTok{3.72}\NormalTok{, }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.7
\end{verbatim}

What does this demonstrate? \textbf{We do not have to specify argument names}. In the absence of a name R uses the position of the supplied argument to work out which name to associate it with. In this example we left out the name of the argument at position 1. This is where \texttt{x} belongs, so we end up rounding 3.71 to 1 decimal place.

R is even more flexible than this. \textbf{We don't necessarily have to use the full name of an argument,} because R can use partial matching on argument names:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FloatTok{3.72}\NormalTok{, }\AttributeTok{dig =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.7
\end{verbatim}

This also works because R can unambiguously match the argument we named \texttt{dig} to \texttt{digits}.

\begin{infobox}{warning}

\hypertarget{be-careful-with-your-arguments}{%
\subsubsection*{Be careful with your arguments}\label{be-careful-with-your-arguments}}
\addcontentsline{toc}{subsubsection}{Be careful with your arguments}

Here is some advice. Do not rely on partial matching of function names. It just leads to confusion and the odd error. If you use it a lot, you end up forgetting the true name of arguments, and if you abbreviate too much, you create name matching conflicts. For example, if a function has arguments \texttt{arg1} and \texttt{arg2} and you use the partial name \texttt{a} for an argument, there is no way to know which argument you meant. We are pointing out partial matching so that you are aware of the behaviour. It is not worth the hassle of getting it wrong to save on a little typing, so do not use it.

What about position matching? This can also cause problems if we're not paying attention. For example, if you forget the order of the arguments to a function and then place your arguments in the wrong place, you will either generate an error or produce a nonsensical result. It is nice not to have to type out the \texttt{name\ =\ value} construct all the time though, so our advice is to rely on positional matching only for the first argument. This is a common convention in R that makes sense because it is often obvious what kind of information the first argument should carry.

\end{infobox}

\hypertarget{combining-functions}{%
\section{Combining functions}\label{combining-functions}}

Using R to do `real work' usually involves linked steps, each facilitated by a different function. There is more than one way to achieve this. Here's a simple example that uses an approach we already know about---storing intermediate results:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\FunctionTok{round}\NormalTok{(y, }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.2
\end{verbatim}

These two lines calculate the square root of the number 10 and assigned the result to \texttt{y}, then round this to one decimal place and print the result. We linked the two calculations by assigning a name to the first result and then used this as the input to a function in the second step.

Here is another way to replicate the same calculation:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{10}\NormalTok{), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.2
\end{verbatim}

The technical name for this is \textbf{function composition} or \textbf{function nesting}: the \texttt{sqrt} function is `nested inside' the \texttt{round} function. The way we have to read these constructs is \textbf{from the inside out}. The \texttt{sqrt(10)} expression is inside the \texttt{round} function, so this is evaluated first. The result of \texttt{sqrt(10)} is then associated with the first argument of the \texttt{round} function, and only then does the \texttt{round} function do its job.

There aren't any new ideas here. We have already seen that R evaluates whatever is on the right-hand side of the \texttt{=} symbol first before associating the resulting value with the appropriate argument name.

We can extend this nesting idea to do more complicated calculations, i.e.~there's nothing to stop us using multiple levels of nesting either. Take a look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{)), }\AttributeTok{digits =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.2
\end{verbatim}

The \texttt{abs} function takes the absolute value of a number, i.e.~removes the \texttt{-} sign if it is there. Remember, read nested calls from the inside out:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  we find the absolute value of -10,
\item
  we calculate the square root of the resulting number (+10), and
\item
  then we rounded this to a whole number.
\end{enumerate}

Nested function calls can be useful because they make R code less verbose (we write less), but this comes at a high cost of reduced readability. No reasonable person would say that \texttt{round(sqrt(abs(-10)),\ digits\ =\ 1)} is easy to read! For this reason, we aim to keep function nesting to a minimum. We will occasionally have to use the nesting construct, so it is important to understand how it works even if we don't like it.

The good news is that we'll see a much-easier-to-read method for applying a series of functions in the Data Wrangling block.

\hypertarget{functions-do-not-have-side-effects}{%
\section{Functions do not have `side effects'}\label{functions-do-not-have-side-effects}}

We'll finish this chapter with an idea every R user needs to understand to avoid confusion. It relates to how functions modify their arguments, or more accurately, how they \textbf{do not} modify their arguments. Take a look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FloatTok{3.7}
\FunctionTok{round}\NormalTok{(y, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.7
\end{verbatim}

We created a variable \texttt{y} with the value 3.7, rounded this to a whole number with \texttt{round}, printed out the result, and then printed the value of \texttt{y}. Notice that \textbf{the value of \texttt{y} has not changed} after using it as an argument to \texttt{round}.

This is important. R functions do not typically alter the values of their arguments (we say `typically' because there are ways to alter this behaviour if we really want to). This behaviour is captured by the phrase `functions do not have side effects'.

If we had intended to round the value of \texttt{y} so that we can use this new value later on, we have to assign the result of function evaluation, like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FloatTok{3.7}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(y, }\AttributeTok{digits =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The reason for pointing out this behaviour is because new R users sometimes assume a function will change its arguments. R functions do not typically do this. If we want to make use of changes, rather than print them to the Console, we need to assign the result a name, either by creating a new variable or overwriting the old one. Remember---functions do not have side effects! Forgetting this creates all kinds of headaches.

\hypertarget{vectors}{%
\chapter{Vectors}\label{vectors}}

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

This chapter has three goals. First, we want to learn how to work with a vector, one of the basic structures used to represent data in R-land. Second, we'll learn how to work with vectors by using \textbf{numeric} vectors to perform simple calculations. Finally, we'll introduce a couple of different kinds of vectors---\textbf{character} vectors and \textbf{logical} vectors. This material provides a foundation for working with real data sets in the next block.

\begin{infobox}{information}

\hypertarget{data-structures}{%
\subsubsection*{Data structures?}\label{data-structures}}
\addcontentsline{toc}{subsubsection}{Data structures?}

The term `data structure' is used to describe conventions or rules for organising and storing data on a computer. Computer languages use many different kinds of data structures. Fortunately, we only need to learn about a couple of relatively simple ones to use R for data analysis: `vectors' and `data frames'. This chapter will consider vectors. The next chapter will look at collections of vectors (a.k.a. data frames).

\end{infobox}

\hypertarget{atomic-vectors}{%
\section{Atomic vectors}\label{atomic-vectors}}

We'll start with a definition, even though it probably won't make much sense yet: a \textbf{vector} is a 1-dimensional data structure for storing a set of values, each accessible by its position in the vector. The simplest kind of vectors in R are called \textbf{atomic vectors}\footnote{The other common vector is called a ``list''. Lists are very useful but we won't cover them in this book.}.

There are different kinds of atomic vector, but their defining, common feature is that it can only contain data of one `type'. They might contain all integers (e.g.~2, 4, 6, \ldots) or all characters (e.g.~``A'', ``B'', ``C''), but they can't mix and match integers and characters (e.g.~``A'', 2, ``C'', 5).

The word `atomic' in the name refers to the fact that an atomic vector can't be broken down into anything simpler---they are the simplest kind of data structure R knows. Even when working with a single number we're actually dealing with an atomic vector. Here's the very first expression we evaluated in the \protect\hyperlink{r-calculator}{Introduction to R chapter}:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

Look at the output. What is that \texttt{{[}1{]}} at the beginning? It's actually a clue that the output resulting from \texttt{1\ +\ 1} is an atomic vector. We can verify this with the \texttt{is.atomic} functions. First, make a variable called \texttt{x} with the result of the \texttt{1\ +\ 1} calculation:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{+} \DecValTok{1}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

Then use \texttt{is.atomic} to check whether \texttt{x} really is an atomic vector:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.atomic}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Atomic vectors really are the simplest kind of data structure in R. Unlike many other languages, there is simply no way to represent just a number. Instead, a single number is always stored as a vector of length one\footnote{The same is true for things like sets of characters (\texttt{"dog"}, \texttt{"cat"}, \texttt{"fish"}, \ldots) and logical values (\texttt{TRUE} or \texttt{FALSE}) discussed in the next two chapters.}.

\hypertarget{intro-vectors}{%
\section{Numeric vectors}\label{intro-vectors}}

A lot of work in R involves \textbf{numeric vectors}. After all, data analysis is all about numbers. Here's one simple way to construct a numeric vector (and print it out):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numvec }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(}\AttributeTok{length =} \DecValTok{50}\NormalTok{)}
\NormalTok{numvec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
## [39] 0 0 0 0 0 0 0 0 0 0 0 0
\end{verbatim}

What happened? We made a numeric vector with 50 \textbf{elements}, each of which is the number 0. The word `element' is used to refer to the values that reside in a vector.

When we create a vector but don't assign it to a name using \texttt{\textless{}-} R just prints it for us. Notice what happens when a vector is printed to the screen. Since a length-50 vector can't fit on one line, it was printed over two. At the beginning of each line there is a \texttt{{[}X{]}}: the number \texttt{X} gives the position of the elements printed at the beginning of each line.

If we need to check that we really have made a numeric vector, we can use the \texttt{is.numeric}\footnote{This may not look like the most useful function in the world, but sometimes we need functions like \texttt{is.numeric} to understand what R is doing or root out mistakes in our scripts.} function to do this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.numeric}\NormalTok{(numvec)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

This confirms \texttt{numvec} is numeric by returning \texttt{TRUE} (a value of \texttt{FALSE} would mean that \texttt{numvec} is some other kind of object).

Keep in mind that R won't always print the exact values of the elements of a vector. For example, when R prints a numeric vector, it only prints the elements to 7 significant figures by default. We can see this by printing the built in constant \texttt{pi} to the Console:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pi}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.141593
\end{verbatim}

The actual value stored in \texttt{pi} is much more precise than this. We can see this by printing \texttt{pi} again using the \texttt{print} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(pi, }\AttributeTok{digits =} \DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.141592653589793
\end{verbatim}

\begin{infobox}{information}

\hypertarget{different-kinds-of-numbers}{%
\subsubsection*{Different kinds of numbers}\label{different-kinds-of-numbers}}
\addcontentsline{toc}{subsubsection}{Different kinds of numbers}

Roughly speaking, R stores numbers in two different ways depending of whether they are whole numbers (``integers'') or numbers containing decimal points (``doubles'' -- don't ask). We're not going to worry about this difference. Most of the time, the distinction is invisible to users, so it is easier to think in terms of numeric vectors. We can mix and match integers and doubles in R without having to worry about how it is storing the numbers.

\end{infobox}

\hypertarget{constructing-numeric-vectors}{%
\section{Constructing numeric vectors}\label{constructing-numeric-vectors}}

We just saw to make a numeric vector of zeros using the \texttt{numeric} function. This is arguably not a particularly useful skill because we usually need to work vectors of particular values (not just 0). A useful function for creating custom vectors is the \texttt{c} function. Take a look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\FloatTok{1.1}\NormalTok{, }\FloatTok{2.3}\NormalTok{, }\FloatTok{4.0}\NormalTok{, }\FloatTok{5.7}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.1 2.3 4.0 5.7
\end{verbatim}

The `c' in the function name stands for `combine'. The \texttt{c} function takes a variable number of arguments, each of which must be a vector of some kind, and combines these into a single vector. We supplied the \texttt{c} function with four arguments, each of which was a single number (i.e.~a length-one vector). The \texttt{c} function combines these to generate a vector of length 4. Simple.

Now look at this example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vec1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{1.1}\NormalTok{, }\FloatTok{2.3}\NormalTok{)}
\NormalTok{vec2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{4.0}\NormalTok{, }\FloatTok{5.7}\NormalTok{, }\FloatTok{3.6}\NormalTok{)}
\FunctionTok{c}\NormalTok{(vec1, vec2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.1 2.3 4.0 5.7 3.6
\end{verbatim}

This shows that we can use the \texttt{c} function to combine two or more vectors of any length. We combined a length-2 vector with a length-3 vector to produce a new length-5 vector.

\begin{infobox}{information}

\hypertarget{the-c-function-is-odd}{%
\subsubsection*{\texorpdfstring{The \texttt{c} function is odd}{The c function is odd}}\label{the-c-function-is-odd}}
\addcontentsline{toc}{subsubsection}{The \texttt{c} function is odd}

Notice that we did not have to name the arguments in those two examples---there were no \texttt{=} involved. The \texttt{c} function is an example of one of those flexible functions that breaks the simple rules of thumb for using arguments that we set out earlier: it can take a variable number of arguments that do not have predefined names. This behaviour is necessary for \texttt{c} to be of any use: to be useful it needs to be flexible enough to take any combination of arguments.

\end{infobox}

\hypertarget{named-vectors}{%
\section{Named vectors}\label{named-vectors}}

What happens if use named arguments with \texttt{c}? Take a look at this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{namedv }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{a =} \DecValTok{1}\NormalTok{, }\AttributeTok{b =} \DecValTok{2}\NormalTok{, }\AttributeTok{c =} \DecValTok{3}\NormalTok{)}
\NormalTok{namedv}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a b c 
## 1 2 3
\end{verbatim}

What happened? R used the argument names to set the names of each element in the vector. The resulting vector is still a 1-dimensional data structure. When printed to the Console, each element's value is printed along with its associated name above it. We can extract the names from a named vector using the \texttt{names} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(namedv)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "a" "b" "c"
\end{verbatim}

Being able to name the elements of a vector is useful because it makes it easier to identify and extract the bits we need.

\hypertarget{vectorised-operations}{%
\section{Vectorised operations}\label{vectorised-operations}}

All the simple arithmetic operators (e.g.~\texttt{+} and \texttt{-}) and many mathematical functions are \textbf{vectorised} in R. When we use a vectorised function it operates on vectors on an element-by-element basis. We'll make a couple of simple vectors to illustrate what we mean:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1  2  3  4  5  6  7  8  9 10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.4}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.6}\NormalTok{, }\FloatTok{0.7}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\FloatTok{0.9}\NormalTok{, }\FloatTok{1.0}\NormalTok{)}
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
\end{verbatim}

This constructed two length-10 numeric vectors, called \texttt{x} and \texttt{y}, where \texttt{x} is a sequence from 1 to 10 and \texttt{y} is a sequence from 0.1 to 1.0. \texttt{x} and \texttt{y} are the same length. Now look at what happens when we add these using \texttt{+}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\SpecialCharTok{+}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1.1  2.2  3.3  4.4  5.5  6.6  7.7  8.8  9.9 11.0
\end{verbatim}

When R evaluates the expression \texttt{x\ +\ y} it does this by adding the first element of \texttt{x} to the first element of \texttt{y}, the second element of \texttt{x} to the second element of \texttt{y}, and so on, working through all ten elements of \texttt{x} and \texttt{y}. That's what is meant by a \textbf{vectorised} operation.

Vectorisation is implemented in all the standard mathematical functions. For example, the \texttt{round} function rounds each element of a numeric vector to the nearest integer by default:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0 0 0 0 0 1 1 1 1 1
\end{verbatim}

The same behaviour is seen with other mathematical functions like \texttt{sin}, \texttt{cos}, \texttt{exp}, and \texttt{log}---they apply the relevant function to each element of a numeric vector.

It is important to realise that not all functions are vectorised. For example, the \texttt{sum} function takes a vector of numbers and adds them up:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.5
\end{verbatim}

Although \texttt{sum} obviously works on a numeric vector it is not `vectorised' in the sense that it works element-by-element to return an output vector of the same length as its main argument. It just returns a single number---the sum total of the elements of its input.

\begin{infobox}{information}

\hypertarget{vectorisation-is-not-the-norm}{%
\subsubsection*{Vectorisation is not the norm}\label{vectorisation-is-not-the-norm}}
\addcontentsline{toc}{subsubsection}{Vectorisation is not the norm}

R's vectorised behaviour may seem like the obvious thing to do, but most computer languages do not work like this. In other languages, we typically have to write a much more complicated expression to do something so simple. This is one reason R is such a good data analysis language: vectorisation allows us to express repetitious calculations in a simple, intuitive way. This behaviour can save a lot of time.

\end{infobox}

\hypertarget{other-vectors}{%
\section{Other kinds of atomic vectors}\label{other-vectors}}

The data we collect and analyse are often in the form of numbers. It comes as no surprise, therefore, that we work with numeric vectors a lot in R. Nonetheless, we also need to use other kinds of vectors, either to represent different types of data, or to help us manipulate our data. This section introduces two new types of atomic vector to help us do this: character vectors and logical vectors.

\hypertarget{character-vectors}{%
\subsection{Character vectors}\label{character-vectors}}

Each element of a \textbf{character vectors} is what is known as a ``character string'' (or ``string'' if we are feeling lazy). That term ``character string'' refers to a sequence of characters, such as ``Treatment 1'', ``University of Sheffield'', ``Population Density''. A character vector is an atomic vector that stores an ordered collection of one or more character strings.

If we want to construct a character vector in R, we have to place double (\texttt{"}) or single (\texttt{\textquotesingle{}}) quotation marks around the characters. For example, we can print the name ``Dylan'' to the Console like this:

\begin{Shaded}
\begin{Highlighting}[]
\StringTok{"Dylan"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Dylan"
\end{verbatim}

Notice the \texttt{{[}1{]}}. This shows that what we just printed is an atomic vector of some kind. We know it's a character vector because the output is printed with double quotes around the value. We often need to make simple character vectors containing only one value---for example, to set the values of arguments to a function.

The quotation marks are not optional---they tell R we want to treat whatever is inside them as a literal value. The quoting is important. If we try to do the same thing as above without the quotes, we end up with an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Dylan}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in eval(expr, envir, enclos): object 'Dylan' not found
\end{verbatim}

What happened? When the interpreter sees the word \texttt{Dylan} without quotes it assumes that this must be the name of a variable, so it goes in search of it in the global environment. We haven't made a variable called Dylan, so there is no way to evaluate the expression and R spits out an error to let us know there's a problem.

Character vectors are typically constructed to represent data of some kind. The \texttt{c} function is one starting point for this kind of thing:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# make a length{-}3 character vector}
\NormalTok{my\_name }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Dylan"}\NormalTok{, }\StringTok{"Zachary"}\NormalTok{, }\StringTok{"Childs"}\NormalTok{)}
\NormalTok{my\_name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Dylan"   "Zachary" "Childs"
\end{verbatim}

Here we made a length-3 character vector, with elements corresponding to a first name, middle name, and last name. If we want to extract one or more elements from a character vector by their position

Take note, this is \textbf{not} equivalent to the above :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_name }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Dylan Zachary Childs"}\NormalTok{)}
\NormalTok{my\_name}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Dylan Zachary Childs"
\end{verbatim}

This length-1 character vector's only element is a single character string containing the first, middle and last name separated by spaces. We didn't even need to use the the \texttt{c} function here because we were only ever working with a length-1 character vector. i.e.~we could have typed \texttt{"Dylan\ Zachary\ Childs"} and we would have ended up with exactly the same text printed at the Console.

\hypertarget{logical-vectors}{%
\subsection{Logical vectors}\label{logical-vectors}}

The elements of \textbf{logical vectors} only take two values: \texttt{TRUE} or \texttt{FALSE}. Don't let the simplicity of logical vectors fool you. They're very useful. As with other kinds of atomic vectors, the \texttt{c} function can be used to construct a logical vector:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{l\_vec }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{)}
\NormalTok{l\_vec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  TRUE FALSE
\end{verbatim}

So why are logical vectors useful? Their allow us to represent the results of questions such as, ``is x greater than y'' or ``is x equal to y''. The results of such comparisons may then be used to carry out various kinds of subsetting operations.

Before we can look at how to use logical vectors to evaluate comparisons, we need to introduce \textbf{relational operators}. These sound fancy, but they are very simple: we use relational operators to evaluate the relative value of vector elements. Six are available in R:

\begin{itemize}
\tightlist
\item
  \texttt{x\ \textless{}\ y}: is x less than y?
\item
  \texttt{x\ \textgreater{}\ y}: is x greater than y?
\item
  \texttt{x\ \textless{}=\ y}: is x less than or equal to y?
\item
  \texttt{x\ \textgreater{}=\ y}: is x greater than or equal to y?
\item
  \texttt{x\ ==\ y}: is x equal to y?
\item
  \texttt{x\ !=\ y}: is x not equal to y?
\end{itemize}

The easiest way to understand how these work is by example. We need a couple of numeric variables first:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{20}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{21}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{30}\NormalTok{)}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 11 12 13 14 15 16 17 18 19 20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  3  6  9 12 15 18 21 24 27 30
\end{verbatim}

Now, if we need to evaluate and represent a question like, ``is x greater than than y'', we can use either \texttt{\textless{}} or \texttt{\textgreater{}}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\SpecialCharTok{\textgreater{}}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
\end{verbatim}

The \texttt{x\ \textgreater{}\ y} expression produces a logical vector, with \texttt{TRUE} values associated with elements in \texttt{x} are less than \texttt{y}, and \texttt{FALSE} otherwise. In this example, x is less than y until we reach the value of 15 in each sequence. Notice too that relational operators are vectorised: they work on an element by element basis.

What does the \texttt{==} operator do? It compares the elements of two vectors to determine if they are exactly equal:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\SpecialCharTok{==}\NormalTok{ y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
\end{verbatim}

The output of this comparison is true only for one element, the number 15, which is at the 5\textsuperscript{th} position in both \texttt{x} and \texttt{y}. The \texttt{!=} operator is essentially the opposite of \texttt{==}. It identifies cases where two elements are not exactly equal. We could step through each of the different relational operators, but hopefully, they are self-explanatory at this point (if not, experiment with them).

\begin{infobox}{warning}

\hypertarget{and-are-not-the-same}{%
\subsubsection*{\texorpdfstring{\texttt{=} and \texttt{==} are not the same}{= and == are not the same}}\label{and-are-not-the-same}}
\addcontentsline{toc}{subsubsection}{\texttt{=} and \texttt{==} are not the same}

If we want to test for equivalence between the elements of two vectors we must use double equals (\texttt{==}), not single equals (\texttt{=}). Forgetting to use \texttt{==} instead of \texttt{=} is a very common source of mistakes. The \texttt{=} symbol already has a use in R---assigning name-value pairs---so it can't also be used to compare vectors because this would lead to ambiguity in our R scripts. Using \texttt{=} when you meant to use \texttt{==} is a very common mistake. If you make it, this will lead to all kinds of difficult-to-comprehend problems with your scripts. Try to remember the difference!

\end{infobox}

\hypertarget{chapter-data-frames}{%
\chapter{Data frames}\label{chapter-data-frames}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

The \protect\hyperlink{quick-intro-to-r}{quick introduction to R} chapter introduced the word `variable' as a short-hand for a named object. For example, we can make a variable called \texttt{num\_vec} that refers to a simple numeric vector using:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{num\_vec }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{1.1}\NormalTok{, }\FloatTok{2.3}\NormalTok{, }\FloatTok{4.0}\NormalTok{, }\FloatTok{5.7}\NormalTok{)}
\NormalTok{num\_vec}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.1 2.3 4.0 5.7
\end{verbatim}

When a computer scientist talks about variables they're referring to these sorts of name-value associations.

However, the word `variable' has a second, more abstract meaning in the world of statistics: it refers to anything we can control or measure. For example, data from an experiment will involve variables whose values describe the experimental conditions (e.g.~low temperature vs.~high temperature) and the quantities we chose to measure (e.g.~enzyme activity). We refer to these kinds of variables as `statistical variables'.

We'll discuss these statistical variables later on. We're pointing out the dual meaning of the word `variable' now because we need to work with both interpretations. The duality can be confusing at times, but both meanings are in widespread use, so we just have to get used to them. We try to minimise confusion by using the phrase ``statistical variable'' when referring to data, rather than R objects.

We're introducing these ideas now because we're going to consider a new type of data object in this chapter---the \textbf{data frame}. Real-world data analysis involves collections of related statistical variables. How should we keep a large collection of variables organised? We could work with them individually, but this tends to be error prone. Instead, we need a way to keep related variables together. This is the problem that \textbf{data frames} are designed to manage.

\hypertarget{data-frames-intro}{%
\section{Data frames}\label{data-frames-intro}}

Data frames are one of R's features that mark it out as particularly good for data analysis. We can think of a data frame as a table-like object with rows and columns. A data frame collects together different statistical variables, storing each of them as a separate column. Related observations are all found in the same row.

We'll think about the columns first.

Each column of a data frame is a vector of some kind. These are usually simple atomic vectors containing numbers or character strings, though it is possible to include more complicated vectors. The critical constraint that a data frame applies is that each vector must have the same length. This is what gives a data frame it table-like structure.

The simplest way to get a feel for data frames is to make one. We can make one `by hand' using some artificial data describing a made-up experiment. Imagine we had conducted a small experiment to examine biomass and community diversity in six field plots. Three plots were subjected to fertiliser enrichment. The other three plots act as experimental controls.

We could store the data describing this experiment in three vectors:

\begin{itemize}
\tightlist
\item
  \texttt{trt} (short for ``treatment'') shows which experimental manipulation was used in a given plot.
\item
  \texttt{bms} (short for ``biomass'') shows the total biomass measured at the end of the experiment.
\item
  \texttt{div} (short for ``diversity'') shows the number of species present at the end of the experiment.
\end{itemize}

Here's some R code to generate these three vectors (it doesn't matter what the actual values are, they're made up):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trt }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"Control"}\NormalTok{,}\StringTok{"Fertilser"}\NormalTok{), }\AttributeTok{each =} \DecValTok{3}\NormalTok{) }
\NormalTok{bms }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{284}\NormalTok{, }\DecValTok{328}\NormalTok{, }\DecValTok{291}\NormalTok{, }\DecValTok{956}\NormalTok{, }\DecValTok{954}\NormalTok{, }\DecValTok{685}\NormalTok{)}
\NormalTok{div }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trt}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Control"   "Control"   "Control"   "Fertilser" "Fertilser" "Fertilser"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bms}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 284 328 291 956 954 685
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{div}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  8 12 11  8  4  5
\end{verbatim}

Notice that the information about different observations are linked by their positions in these vectors. For example, the third control plot had a biomass of `291' and a species diversity `11'.

We use the \texttt{data.frame} function to construct a data frame from one or more vectors, i.e.~to build a data frame from the three vectors we just created:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experim.data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(trt, bms, div)}
\NormalTok{experim.data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         trt bms div
## 1   Control 284   8
## 2   Control 328  12
## 3   Control 291  11
## 4 Fertilser 956   8
## 5 Fertilser 954   4
## 6 Fertilser 685   5
\end{verbatim}

Notice what happens when we print the data frame: it is displayed as though it has rows and columns. That's what we meant when we said a data frame is a table-like structure.

The \texttt{data.frame} function takes a variable number of arguments. We used the \texttt{trt}, \texttt{bms} and \texttt{div} vectors, resulting in a data frame with three columns. Each of these vectors has 6 elements, so the resulting data frame has 6 rows. The names of the vectors were used to name its columns. The rows do not have names, but they are numbered to reflect their position.

The words \texttt{trt}, \texttt{bms} and \texttt{div} are not very informative. If we prefer to work with more meaningful column names---which is always a good idea---then we can name the \texttt{data.frame} arguments:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experim.data }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Treatment =}\NormalTok{ trt, }\AttributeTok{Biomass =}\NormalTok{ bms, }\AttributeTok{Diversity =}\NormalTok{ div)}
\NormalTok{experim.data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Treatment Biomass Diversity
## 1   Control     284         8
## 2   Control     328        12
## 3   Control     291        11
## 4 Fertilser     956         8
## 5 Fertilser     954         4
## 6 Fertilser     685         5
\end{verbatim}

The new data frame contains the same data as the previous one but now the column names correspond to the human-readable words we chose.

\begin{infobox}{warning}

\hypertarget{dont-bother-with-row-names}{%
\subsubsection*{Don't bother with row names}\label{dont-bother-with-row-names}}
\addcontentsline{toc}{subsubsection}{Don't bother with row names}

We can also name the rows of a data frame using the \texttt{row.names} argument of the \texttt{data.frame} function. We won't bother to show an example of this, though. Why? We can't easily work with the information in row names which means there's not much point adding it. If we need to include row-specific information in a data frame it's best to include an additional variable, i.e.~an extra column.

\end{infobox}

\hypertarget{exploring-data-frames}{%
\section{Exploring data frames}\label{exploring-data-frames}}

The first things to do when presented with a new data set is to explore its structure to understand what we're dealing with. There are plenty of options for doing this when the data are stored in a data frame. For example, the \texttt{head} and \texttt{tail} functions extract the first and last few rows of a data set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(experim.data, }\AttributeTok{n =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Treatment Biomass Diversity
## 1   Control     284         8
## 2   Control     328        12
## 3   Control     291        11
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tail}\NormalTok{(experim.data, }\AttributeTok{n =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   Treatment Biomass Diversity
## 4 Fertilser     956         8
## 5 Fertilser     954         4
## 6 Fertilser     685         5
\end{verbatim}

Notice that the \texttt{n} argument controls the number of rows printed. The \texttt{View} function can be used to open up the whole data set in a table- or spreadsheet-like like view:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{View}\NormalTok{(experim.data)}
\end{Highlighting}
\end{Shaded}

Exactly what happens when we use \texttt{View} depends on how we're interacting with R. When we run it in RStudio a new tab opens up with the data shown inside it.

\begin{infobox}{warning}

\hypertarget{view-only-displays-the-data}{%
\subsubsection*{\texorpdfstring{\texttt{View} only displays the data}{View only displays the data}}\label{view-only-displays-the-data}}
\addcontentsline{toc}{subsubsection}{\texttt{View} only displays the data}

The \texttt{View} function is only designed to display a data frame as a table of rows and columns. We can't change the data in any way with the \texttt{View} function. We can reorder the way the data are presented, but keep in mind that this won't alter the underlying data.

\end{infobox}

There are quite a few different R functions that will extract information about a data frame. The \texttt{nrow} and \texttt{ncol} functions return the number of rows and columns, respectively:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nrow}\NormalTok{(experim.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ncol}\NormalTok{(experim.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

The \texttt{names} function can be used to extract the column names from a data frame:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{colnames}\NormalTok{(experim.data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Treatment" "Biomass"   "Diversity"
\end{verbatim}

The \texttt{experim.data} data frame has three columns, so \texttt{names} returns a character vector of length three, where each element corresponds to a column name.

\hypertarget{extracting-and-adding-a-single-variable}{%
\section{Extracting and adding a single variable}\label{extracting-and-adding-a-single-variable}}

Remember, each column of a data frame can be thought of as a variable. Data frames would not be much use if we could not extract and modify the variables they contain. In this section, we will briefly review how to extract a variable. We'll examine ways to manipulate the data within a data frame in later chapters.

One way of extracting a variable from a data frame uses a double square brackets construct, \texttt{{[}{[}}. For example, we extract the \texttt{Biomass} variable from our example data frame with the double square brackets like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experim.data[[}\StringTok{"Biomass"}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 284 328 291 956 954 685
\end{verbatim}

This prints whatever is in the \texttt{Biomass} column to the Console. What kind of object is this? It's a numeric vector:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{is.numeric}\NormalTok{(experim.data[[}\StringTok{"Biomass"}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

See? A data frame is a collection of vectors. Notice that all we did was print the resulting vector to the Console. If we want to do something with this numeric vector we need to assign the result:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bmass }\OtherTok{\textless{}{-}}\NormalTok{ experim.data}\SpecialCharTok{$}\NormalTok{Biomass}
\NormalTok{bmass}\SpecialCharTok{\^{}}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  80656 107584  84681 913936 910116 469225
\end{verbatim}

Here, we extracted the \texttt{Biomass} variable, assigned it to \texttt{bmass}, and then squared this.

Notice that we used \texttt{"Biomass"} instead of \texttt{Biomass} inside the double square brackets, i.e.~we quoted the name of the variable. This is because we want R to treat the word ``Biomass'' as a literal value. This little detail is important! If we don't quote the name, R will assume that \texttt{Biomass} is the name of an object and go in search of it in the global environment. Since we haven't created something called \texttt{Biomass}, leaving out the quotes would generate an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experim.data[[Biomass]]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in (function(x, i, exact) if (is.matrix(i)) as.matrix(x)[[i]] else .subset2(x, : object 'Biomass' not found
\end{verbatim}

The error message is telling us that R can't find a variable called \texttt{Biomass}.

The second method for extracting a variable uses the \texttt{\$} operator. For example, to extract the \texttt{Biomass} column from \texttt{experim.data}, we use:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{experim.data}\SpecialCharTok{$}\NormalTok{Biomass}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 284 328 291 956 954 685
\end{verbatim}

We use the \texttt{\$} operator by placing the name of the data frame we want to work with on the left-hand side and the name of the column (i.e.~the variable) we want to extract on the right-hand side. Notice that we didn't have to put quotes around the variable name when using the \texttt{\$} operator. We can do this if we want to---i.e.~\texttt{experim.data\$"Biomass"} also works---but \texttt{\$} doesn't require it.

\begin{infobox}{warning}

\hypertarget{why-is-there-more-than-one-way-to-extract-variables}{%
\subsubsection*{Why is there more than one way to extract variables?}\label{why-is-there-more-than-one-way-to-extract-variables}}
\addcontentsline{toc}{subsubsection}{Why is there more than one way to extract variables?}

There's no simple way to answer this question without getting into the details of how R represents data frames. The simple answer is that \texttt{\$} and \texttt{{[}{[}} are not strictly equivalent, even though they appear to do much the same thing. The \texttt{\$} method is a bit easier to read, and people tend to prefer it for interactive data analysis tasks, whereas the \texttt{{[}{[}} construct tends to be used when we need a bit more flexibility for programming.

\end{infobox}

\hypertarget{packages}{%
\chapter{Packages}\label{packages}}

\hypertarget{package-system}{%
\section{The R package system}\label{package-system}}

The R package system is the most important single factor driving increased adoption of R. Packages are used to extend the basic capabilities of R. In \href{http://r-pkgs.had.co.nz}{his book} about R packages Hadley Wickam says,

\begin{quote}
Packages are the fundamental units of reproducible R code. They include reusable R functions, the documentation that describes how to use them, and sample data.
\end{quote}

An R package is a collection of folders and files in a standard, well-defined format that bundles together computer code, data, and documentation in a way that is easy to use and share with other users. The computer code might all be R code, but it can also include code written in other languages. Packages provide an R-friendly interface to use this ``foreign'' code without needing to understand how it works.

The base R distribution it comes with quite a few pre-installed packages. These base R packages represent a tiny subset of all available R packages. The majority of these are hosted on a worldwide network of web servers collectively know as \href{http://cran.r-project.org}{CRAN}: the Comprehensive R Archive Network, pronounced either ``see-ran'' or ``kran''.

CRAN is a fairly spartan web site, so it's easy to navigate. The \href{http://cran.r-project.org}{landing page} has about a dozen links on the right-hand side. Under the \emph{Software} section there is a link called \href{http://cran.r-project.org/web/packages/}{Packages}. Near the top of that packages page there is a link called \href{http://cran.r-project.org/web/packages/available_packages_by_name.html}{Table of available packages, sorted by name} that points to a very long list of all the packages on CRAN. The column on the left shows each package name, followed by a brief description of what the package does on the right. There are 1000s of packages listed there.

\hypertarget{task-views}{%
\section{Task views}\label{task-views}}

The huge list of packages on the \href{http://cran.r-project.org/web/packages/available_packages_by_name.html}{available packages} is pretty overwhelming. A more user-friendly view of many R packages is found on the \href{http://cran.r-project.org/web/views/}{Task Views} page (the link is on the left hand side, under the section labelled \emph{CRAN}). A Task View is basically a curated guide to the packages and functions that are useful for certain disciplines. The Task Views page shows a list of these discipline-specific topics, along with a brief description. For example---

\begin{itemize}
\tightlist
\item
  The \href{http://cran.r-project.org/web/views/Environmetrics.html}{Environmentrics} Task View contains information about using R to analyse ecological and environmental data.
\item
  The \href{https://cran.r-project.org/web/views/ClinicalTrials.html}{Clinical Trials} Task View contains information about using R to design, monitor, and analyse data from clinical trials.
\item
  The \href{https://cran.r-project.org/web/views/MedicalImaging.html}{Medical Image Analysis} Task View contains information about packages for working with commercial medical image data.
\item
  The \href{https://cran.r-project.org/web/views/Pharmacokinetics.html}{Pharmacokinetic} Task View contains information about packages for working with pharmacokinetic (PK) data.
\end{itemize}

Task views are often a good place to start looking for a new package to support a particular analysis in future projects.

\hypertarget{use-packages}{%
\section{Using packages}\label{use-packages}}

Two things need to happen to make use of a package. First, we need to copy the folders and files that make up the package to an appropriate location on our computer. This process is called \textbf{installing} the package. Second, we need to \textbf{load and attach} the package for use in an R session. The word ``session'' refers to the time between when we start up R and close it down again.

It's worth unpacking these two ideas because packages are a very frequent source of confusion for new users:

\begin{itemize}
\item
  If we don't have a copy of a package's folders and files our computer, we can't use it. The process of making this copy is called \textbf{installing} the package. It's possible to manually install packages by going to the CRAN website, downloading the package, and then using various tools to install it. We don't recommend using this approach though, because it's inefficient and error-prone. Instead, use built-in R functions to grab the package from CRAN and install it one step.
\item
  Once we have a copy of the package on our computer, it will remain there for us to use. We don't need to re-install a package we want to use every time we start a new R session. It is worth saying that again, \textbf{there is no need to install a package every time we start up R / RStudio}. The only exception to this rule is that a major update to R will sometimes require a complete re-install of the packages. Such major updates are infrequent.
\item
  Installing a package does nothing more than place a copy of the relevant files on our hard drive. If we want to use the functions or the data that comes with a package we need to make them available in our current R session. Unlike package installation, this \textbf{load and attach} process as it's known has to be repeated every time we restart R. If we forget to load up the package we can't use it.
\end{itemize}

\hypertarget{viewing-installed-packages}{%
\subsection{Viewing installed packages}\label{viewing-installed-packages}}

We sometimes need to check whether a package is currently installed. RStudio provides a simple, intuitive way to see which packages are installed on our computer. The \textbf{Packages} tab in the bottom right pane shows the name of every installed package, a brief description and a version number.

There are also a few R functions that can be used to check whether a package is currently installed. For example, the \texttt{find.package} function can do this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{find.package}\NormalTok{(}\StringTok{"MASS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "/Library/Frameworks/R.framework/Versions/4.0/Resources/library/MASS"
\end{verbatim}

The \texttt{find.package} function either prints a ``file path'' showing us where the package is located, as above, or return an error if the package can't be found. Alternatively, a function called \texttt{installed.packages} will return a data frame containing a lot of information about the installed packages.

\hypertarget{installing-packages}{%
\subsection{Installing packages}\label{installing-packages}}

R packages can be installed from several different sources. For example, they can be installed from a local file on a computer, from the CRAN repository, or from an other kind of online repository called Github. Although various alternatives to CRAN are becoming more popular, we're only going to worry about installing packages that live on CRAN.

To install a package from an online repository like CRAN we have to download the package files, uncompress them (like we would a ZIP file), and move them to the correct location. All of this can be done using a single function: \texttt{install.packages}. For example, to install a package called \textbf{fortunes} we use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"fortunes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The quotes are necessary by the way. If everything is working---we have an active internet connection, the package name is valid, and so on---R will briefly pause while it communicates with the CRAN servers, we should see some red text reporting back what's happening, and then we're returned to the prompt. The red text is just letting us know what R is up to. As long as this text does not include the word ``error'', there is usually no need to worry about it.

There are a couple of things to keep in mind. First, package names are case sensitive. For example, \textbf{fortunes} is not the same as \textbf{Fortunes}. Quite often package installations fail because we used the wrong case somewhere in the package name. The other aspect of packages we need to know about is related to \textbf{dependencies}: some packages rely on other packages in order to work properly. By default \texttt{install.packages} will install these dependencies, so we don't usually have to worry too much about them. Just don't be surprised if the \texttt{install.packages} function installs more than one package when only one was requested.

RStudio provides a way of interacting with \texttt{install.packages} via point-and-click. The \textbf{Packages} tab has an ``Install''" button at the top right. Clicking on this brings up a small window with three main fields: ``Install from'', ``Packages'', and ``Install to Library''. We only need to work with the ``Packages'' field -- the other two can be left at their defaults. When we start typing in the first few letters of a package name (e.g.~\textbf{dplyr}) RStudio provides a list of available packages that match this. After we select the one we want and click the ``Install'' button, RStudio invokes \texttt{install.packages} for us.

\hypertarget{loading-and-attaching-packages}{%
\subsection{Loading and attaching packages}\label{loading-and-attaching-packages}}

Once we've installed a package or two, we'll probably want to use them. Two things have to happen to access a package's facilities: the package has to be loaded into memory, and then it has to attached to something called a search path so that R can find it.

It is beyond the scope of this book to get in to ``how'' and ``why'' of these events. Fortunately, there's no need to worry about these details, as both loading and attaching can be done in a single step with a function called \texttt{library}. The \texttt{library} function works as we might expect it to. If we want to start using the \texttt{fortunes} package---which was just installed above---all we need is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"fortunes"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Nothing much happens if everything is working as it should. R just returns us to the prompt without printing anything to the Console. The difference is that now we can use the functions that \textbf{fortunes} provides. As it turns out, there is only one function, called fortune:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{fortune}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Friends don't let friends use Excel for statistics!
##    -- Jonathan D. Cryer (about problems with using Microsoft Excel for
##       statistics)
##       JSM 2001, Atlanta (August 2001)
\end{verbatim}

The \textbf{fortunes} package is either very useful or utterly pointless, depending on one's perspective. It dispenses quotes from various R experts delivered to the venerable R mailing list.

\begin{infobox}{warning}

\hypertarget{dont-use-rstudio-for-loading-packages}{%
\subsection{Don't use RStudio for loading packages!}\label{dont-use-rstudio-for-loading-packages}}

As usual, if we don't like working in the Console RStudio can help us out. There is a small button next to each package listed in the \textbf{Packages} tab. Packages that have been loaded and attached have a blue check box next to them, whereas this is absent from those that have not. Clicking on an empty check box will load up the package. We mention this because at some point most people realise they can use RStudio to load and attach packages. \textbf{We don't recommend using this route}. It's much better to put \texttt{library} statements into your R script. Read the relevant appendix if you're not sure what a script is yet.

\end{infobox}

\hypertarget{an-analogy}{%
\subsection{An analogy}\label{an-analogy}}

The package system frequently confuses new users. This stems from the fact that they aren't clear about what the \texttt{install.packages} and \texttt{library} functions are doing. One way to think about these is by analogy with smartphone ``Apps''. Think of an R package as analogous to a smartphone App--- a package effectively extends what R can do, just as an App extends what a phone can do.

When we want to use a new App, we download it from the App store and install it on our phone. Once downloaded, the App lives permanently on the phone and can be used whenever it's needed. Downloading and installing the App is something we only have to do once. Packages are no different. When we want to use an R package we first have to make sure it is installed on the computer (e.g.~using \texttt{install.packages}). Installing a package is a `do once' operation. Once installed, we don't need to install a package again each time we restart R.

To actually use an App on our phone we open it up by tapping on its icon. This has to happen every time we want to use the App. The package equivalent of opening a smartphone App is the ``load and attach'' operation. This is what \texttt{library} does. It makes a package available for use in a particular session. We have to use \texttt{library} to load the package every time we start a new R session if we plan to access the functions in that package: loading and attaching a package via \texttt{library} is a ``do every time'' operation.

\hypertarget{package-data}{%
\section{Package data}\label{package-data}}

Remember what Hadley Wickam said about packages? ``\ldots{} include reusable R functions, the documentation that describes how to use them, \textbf{and sample data}.'' Many packages include sample data sets for use in examples and package vignettes. Use the \texttt{data} function to list the data sets hiding away in packages:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(}\AttributeTok{package =} \FunctionTok{.packages}\NormalTok{(}\AttributeTok{all.available =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The mysterious \texttt{.packages(all.available\ =\ TRUE)} part of this generates a character vector with the names of all the installed packages in it. If we only use \texttt{data()} then R only lists the data sets found in a package called \texttt{datasets} and any additional packages we have loaded in the current R session.

The \texttt{datasets} package is part of the base R distribution. It exists for one reason---to store example data sets. The \texttt{datasets} package is automatically loaded when we start R, i.e.~there's no need to use \texttt{library} to access it, meaning any data stored in this package can be accessed every time we start R.

From the perspective of learning to use R, working with package data is really useful because it allows us to work with `well-behaved' data sets without having to worry about getting them into R. Importing data is certainly an important skill but it's not necessarily something a new user wants to worry about. For this reason, we tend to use package data sets in this book.

\hypertarget{the-tidyverse-ecosystem-of-packages}{%
\section{The tidyverse ecosystem of packages}\label{the-tidyverse-ecosystem-of-packages}}

We're going to be using several packages that belong to a widely used, well-known ecosystem of packages known as the \textbf{tidyverse}. Here is the description of the tidyverse on its \href{https://www.tidyverse.org/}{website}:

\begin{quote}
The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.
\end{quote}

Using the tidyverse makes data analysis simpler, faster and a more entertaining experience (honestly).

\hypertarget{part-data-wrangling}{%
\part{Data Wrangling}\label{part-data-wrangling}}

\hypertarget{getting-ready-to-use-dplyr}{%
\chapter{\texorpdfstring{Getting ready to use \textbf{dplyr}}{Getting ready to use dplyr}}\label{getting-ready-to-use-dplyr}}

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

Data wrangling is the process of cleaning and manipulating data to get it ready for analysis, for example, by creating derived variables and subsets of the data. Although not the most exciting part of a study---we want to answer questions, not format data---data wrangling is critical. This step in a data analysis workflow can become very time-consuming if not tackled with the right tools.

The next few chapters will introduce the \textbf{dplyr} package. \textbf{dplyr} is an important member of the tidyverse ecosystem. Its job is to provide a set of tools to address common data manipulation tasks, such as selecting subsets of data, making new variables, and summarising data in various ways.

However, before we can start to use these tools, we need a bit of a foundation. That is the aim of this chapter. We will provide some background to the so-called tidy data principles, introduce the data set we'll be using in our examples, discuss the tidyverse version of data frames known as the tibble, and finally, introduce the \textbf{dplyr} package.

\hypertarget{tidy-data}{%
\section{Tidy data}\label{tidy-data}}

\textbf{dplyr} will work with any data frame. However, it is most powerful when data are organised according to \href{http://vita.had.co.nz/papers/tidy-data.pdf}{tidy data} conventions for rectangular data sets. Tidy data has a specific structure that makes it easy to manipulate, model and visualise. A tidy data set is one where each variable is only found in one column and each row contains one unique observation (an imaged cell, a treated organism, an experimental plot, and so on).

The basic principles of tidy data are not too difficult to understand. We'll use an example to illustrate what the ``one variable = one column'' and ``one observation = one row'' idea means. Let's return to the made-up experiment investigating the response of communities to fertilizer addition. This time, imagine we had only measured biomass, but that we had measured it at two time points throughout the experiment.

We'll look at two ways to organise some artificial data from this experimental setup. The first uses a separate column for each biomass measurement:

\begin{verbatim}
##   Treatment BiomassT1 BiomassT2
## 1   Control       284       324
## 2   Control       328       400
## 3   Control       291       355
## 4 Fertilser       956      1197
## 5 Fertilser       954      1012
## 6 Fertilser       685       859
\end{verbatim}

This feels like a reasonable way to store such data, especially for an Excel user. However, this format is \textbf{not} \textbf{tidy}. Why? The biomass variable has been split across two columns (\texttt{BiomassT1} and \texttt{BiomassT2}), which means each row corresponds to two distinct observations. We won't go into the `whys' here but take our word for it---adopting this format makes it difficult to use \textbf{dplyr} efficiently.

A tidy version of that example data set would still have three columns but now these would be: \texttt{Treatment}, denoting the experimental treatment applied; \texttt{Time}, denoting the sampling occasion; and \texttt{Biomass}, denoting the biomass measured:

\begin{verbatim}
##    Treatment Time Biomass
## 1    Control   T1     284
## 2    Control   T1     328
## 3    Control   T1     291
## 4  Fertilser   T1     956
## 5  Fertilser   T1     954
## 6  Fertilser   T1     685
## 7    Control   T2     324
## 8    Control   T2     400
## 9    Control   T2     355
## 10 Fertilser   T2    1197
## 11 Fertilser   T2    1012
## 12 Fertilser   T2     859
\end{verbatim}

The change we made was to create an indicator variable called \texttt{Time} for the sampling occasion. In version one of the data, the time information was implicit---the time associated with a biomass measurement was encoded by column membership (\texttt{BiomassT1} vs \texttt{BiomassT2}). In the second version of the data set an indicator variable, \texttt{Time}, was created to label the sampling occasion explicitly. That simple change means each row corresponds to one distinct observation and each variable lives in one column. These data are now tidy and ideally set up for use with \textbf{dplyr}.

\begin{infobox}{warning}

\hypertarget{always-try-to-start-with-tidy-data}{%
\subsubsection*{Always try to start with tidy data}\label{always-try-to-start-with-tidy-data}}
\addcontentsline{toc}{subsubsection}{Always try to start with tidy data}

The best way to make sure your data set is tidy is to store in that format \textbf{when it's first collected and recorded}. Some packages can help convert non-tidy data into the tidy data format (e.g.~the \textbf{tidyr} package), but life is much simpler if we ensure our data are tidy from the very beginning.

\end{infobox}

\hypertarget{penguins-data-overview}{%
\section{Penguins! 🐧+📊= 😃}\label{penguins-data-overview}}

To make progress with \textbf{dplyr}, we are going to need some data to play around with. The data we'll use contains measurements taken from penguins on the Palmer Archipelago, off the north-western coast of the Antarctic Peninsula. Each row contains information about an individual penguin, including:

\begin{itemize}
\tightlist
\item
  the species it belongs to,
\item
  the island it was found on,
\item
  morphometric data (flipper length, body mass, bill dimensions)
\item
  its body mass and sex,
\item
  and finally, the year of capture.
\end{itemize}

\begin{figure}

{\centering \includegraphics[width=0.75\linewidth]{./images/lter_penguins} 

}

\caption{Meet the Palmer penguins (artwork by Allison Horst)}\label{fig:unnamed-chunk-101}
\end{figure}

Why use this data set? Apart from the fact that everyone likes penguins, obviously, these data are sufficiently complex to demonstrate everything we want to do, while remaining easily understandable. Here is the full data set shown as a table:

\emph{N.B. --- the data will only show up in the HTML version of the book.}

This shows the first ten rows along with the first few columns. The \emph{Previous / Next} links at the bottom right can be used to navigate the rows; the arrows in the top header row are used to view the different columns. Below each column name you can also see three-letter abbreviations like \texttt{\textless{}dbl\textgreater{}}, \texttt{\textless{}int\textgreater{}} and \texttt{\textless{}chr\textgreater{}}. These are telling us that each column is a vector of some kind:

\begin{itemize}
\item
  \texttt{\textless{}dbl\textgreater{}} = a numeric `double' vector (real numbers, i.e.~with decimals)
\item
  \texttt{\textless{}int\textgreater{}} = a numeric integer vector (integer numbers)
\item
  \texttt{\textless{}chr\textgreater{}} = character vector.
\end{itemize}

So\ldots{} data frames are table-like objects with rows and columns. They can also be seen in even simpler terms---data frames are simply collections of vectors, where each one represents a different aspect of a multi-faceted data set.

We're going to be seeing a lot of this data set in the remaining chapters so we won't say anything more about it now.

\begin{infobox}{information}

\hypertarget{where-can-we-get-the-penguins-data}{%
\subsubsection*{Where can we get the penguins data?}\label{where-can-we-get-the-penguins-data}}
\addcontentsline{toc}{subsubsection}{Where can we get the penguins data?}

The Palmer penguins data were collected and made available by \href{https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php}{Dr.~Kristen Gorman} and the \href{https://pal.lternet.edu/}{Palmer Station}. The data set exists mostly to support people learning and teaching R. It isn't part of base R, though. We have to import it into R somehow. There are two options:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The data are available in an R package called\ldots{} \href{https://allisonhorst.github.io/palmerpenguins/index.html}{palmerpenguins}. Like other packages, \textbf{palmerpenguins} can be installed from \href{https://cran.r-project.org/web/packages/palmerpenguins/index.html}{CRAN} using either \texttt{install.packages} or the usual RStudio point-and-click mechanism. Once installed, we can make it available by running \texttt{library(palmerpenguins)} in any R session. After that, just type the name of the data set and R will find it and use it. The version in \textbf{palmerpenguins} is called \texttt{penguins}, by the way.
\item
  We could get a copy of the data set and store it as a file on our hard drive, ideally using a standard data format. The most common and portable format for storing rectangular data is as a `Comma Separated Value' (CSV) text file. Once you have a copy of the data as a CSV file, it's just a matter of using a function like read\_csv from the readr package to import the data into R. This is explained in the \protect\hyperlink{project-scripts-data}{Managing projects, scripts and data files} appendix.
\end{enumerate}

\end{infobox}

\hypertarget{um-tibbles}{%
\section{Um\ldots{} tibbles?}\label{um-tibbles}}

To increase the scope of what the tidyverse can do, its makers created a special kind of data object known as a `tibble'. This is meant to sound like the word `table' pronounced by a New Zealander. We're not lying---the person who started the tidyverse is from New Zealand. Its name is a clue that a tibble is a table-like object, i.e.~a rectangular data structure similar to a data frame.

In fact, the easiest way to conceptualise a tibble is as a special data frame with a few extra whistles and bells. More often than not, it's not necessary to pay attention to whether we're working with an ordinary data frame or a tidyverse tibble---we can often treat them as though they are interchangeable.

That said, there are exceptions to this rule of thumb, and we do occasionally need to work out which one we're using. A simple way to do this is by printing the data object. Imagine that we've imported the Palmer penguins into R and stored it in a tibble called \texttt{penguins}. This is what that would look like if we printed it at the Console:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

The formatting applied to the output is telling us \texttt{penguins} is a tibble rather than an ordinary data frame (we only called it a data frame earlier because we had not introduced the concept of a tibble yet). There are a couple of clues about this in that printout. The very obvious one is the first line: \texttt{\#\ A\ tibble:\ 344\ x\ 8}. The printed output states \texttt{penguins} is a tibble! The output is also truncated---only the first ten lines were printed, and any columns that won't fit on one row are summarised at the bottom (i.e.~\texttt{sex} and \texttt{year}).

\hypertarget{missing-values}{%
\section{Missing values}\label{missing-values}}

Take a close look at the values of the body mass data (\texttt{body\_mass\_g}) in \texttt{penguins} (we're using \texttt{\$} to extract the whole column):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   [1] 3750 3800 3250   NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400
##  [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950
##  [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000
##  [46] 4600 3425 2975 3450 4150 3500 4300 3450 4050 2900 3700 3550 3800 2850 3750
##  [61] 3150 4400 3600 4050 2850 3950 3350 4100 3050 4450 3600 3900 3550 4150 3700
##  [76] 4250 3700 3900 3550 4000 3200 4700 3800 4200 3350 3550 3800 3500 3950 3600
##  [91] 3550 4300 3400 4450 3300 4300 3700 4350 2900 4100 3725 4725 3075 4250 2925
## [106] 3550 3750 3900 3175 4775 3825 4600 3200 4275 3900 4075 2900 3775 3350 3325
## [121] 3150 3500 3450 3875 3050 4000 3275 4300 3050 4000 3325 3500 3500 4475 3425
## [136] 3900 3175 3975 3400 4250 3400 3475 3050 3725 3000 3650 4250 3475 3450 3750
## [151] 3700 4000 4500 5700 4450 5700 5400 4550 4800 5200 4400 5150 4650 5550 4650
## [166] 5850 4200 5850 4150 6300 4800 5350 5700 5000 4400 5050 5000 5100 4100 5650
## [181] 4600 5550 5250 4700 5050 6050 5150 5400 4950 5250 4350 5350 3950 5700 4300
## [196] 4750 5550 4900 4200 5400 5100 5300 4850 5300 4400 5000 4900 5050 4300 5000
## [211] 4450 5550 4200 5300 4400 5650 4700 5700 4650 5800 4700 5550 4750 5000 5100
## [226] 5200 4700 5800 4600 6000 4750 5950 4625 5450 4725 5350 4750 5600 4600 5300
## [241] 4875 5550 4950 5400 4750 5650 4850 5200 4925 4875 4625 5250 4850 5600 4975
## [256] 5500 4725 5500 4700 5500 4575 5500 5000 5950 4650 5500 4375 5850 4875 6000
## [271] 4925   NA 4850 5750 5200 5400 3500 3900 3650 3525 3725 3950 3250 3750 4150
## [286] 3700 3800 3775 3700 4050 3575 4050 3300 3700 3450 4400 3600 3400 2900 3800
## [301] 3300 4150 3400 3800 3700 4550 3200 4300 3350 4100 3600 3900 3850 4800 2700
## [316] 4500 3950 3650 3550 3500 3675 4450 3400 4300 3250 3675 3325 3950 3600 4050
## [331] 3350 3450 3250 4050 3800 3525 3950 3650 3650 4000 3400 3775 4100 3775
\end{verbatim}

The body mass information lives in a numeric (integer) vector, but not every element in that vector is a number. Two values are \texttt{NA}. That stands for `Not Available'---the \texttt{NA}'s job is to label cases where a value is missing or unknown. If you scroll around the table view of \texttt{penguins} above you'll find \texttt{NA}'s in several of the columns.

Missing data crop up all the time. They are just one of those facts of life---maybe the recording machine broke one afternoon, perhaps one of our organisms was infected by a pathogen, or maybe a cow ate one of our experimental plots. One of the nice things about R is that it knows how to represent missing data. It does this using the \texttt{NA} symbol.

You need to be aware of missing values when they are present. Why? Because the behaviour of many functions is affected by the presence of \texttt{NA}s. Things get confusing if we don't understand that behaviour. We will see some examples of this in the next few chapters.

\hypertarget{why-dplyr}{%
\section{\texorpdfstring{Introducing \textbf{dplyr}}{Introducing dplyr}}\label{why-dplyr}}

The \textbf{dplyr} package has been carefully designed to make it easy to manipulate `rectangular data', such as data frames. \textbf{dplyr} is very consistent in the way its functions work. For example, the first argument of the main \textbf{dplyr} functions is always an object containing our data. This consistency makes it very easy to get to grips with each of the main \textbf{dplyr} functions---it's often possible to understand how one works by seeing one or two examples of its use.

Another reason for using \textbf{dplyr} is that it is orientated around a few core functions, each designed to do one thing well. These \textbf{dplyr} functions are sometimes referred to as its `verbs' to reflect the fact that they `do something' to data. For example:

\begin{itemize}
\tightlist
\item
  \texttt{select} is obtains a subset of variables,
\item
  \texttt{mutate} is constructs new variables,
\item
  \texttt{filter} is obtains a subset of rows,
\item
  \texttt{arrange} is reorders rows, and
\item
  \texttt{summarise} is calculates information about groups.
\end{itemize}

Notice that the names are chosen to reflect what each verb/function does to the input data. We'll cover each of these verbs in detail in later chapters, as well as a few additional ones, such as \texttt{rename} and \texttt{group\_by}.

Apart from being easy to use, \textbf{dplyr} is also fast. This doesn't matter for small data sets but can be important when working with data sets with hundreds of thousands of rows. The \textbf{dplyr} package also allows us to work with data stored in different ways, for example, by interacting directly with several database systems. We're going to focus on using it with data frames and tibbles. But remember---once you know how to use \textbf{dplyr} with data frames its easy to use it for work with other kinds of data sources.

\begin{infobox}{information}

\hypertarget{a-dplyr-cheat-sheet}{%
\subsubsection*{\texorpdfstring{A \textbf{dplyr} cheat sheet}{A dplyr cheat sheet}}\label{a-dplyr-cheat-sheet}}
\addcontentsline{toc}{subsubsection}{A \textbf{dplyr} cheat sheet}

The developers of RStudio have produced a very usable \href{http://www.rstudio.com/resources/cheatsheets/}{cheat sheat} that summarises the main data wrangling tools provided by \textbf{dplyr}.

\begin{center}\includegraphics{images/data-transformation} \end{center}

Our advice is to download this, print out a copy, and refer to it often as you start working with \textbf{dplyr}.

\end{infobox}

\hypertarget{more-dplyr}{%
\subsection{\texorpdfstring{A first look at \textbf{dplyr}}{A first look at dplyr}}\label{more-dplyr}}

Let's take a preliminary look at the \textbf{dplyr} package. The package is not part of the base R installation, so we have to have installed it first. Remember, once installed, there is no need to install the package every time we need to use it. We do have to use \texttt{library} to load and attach the package every time we want to use it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's look at one handy \textbf{dplyr} function now. Sometimes we just need a quick, compact summary of a data frame or tibble. This is the job of the \texttt{glimpse} function from \textbf{dplyr}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{glimpse}\NormalTok{(penguins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 344
## Columns: 8
## $ species           <chr> "Adelie", "Adelie", "Adelie", "Adelie", "Adelie", "A~
## $ island            <chr> "Torgersen", "Torgersen", "Torgersen", "Torgersen", ~
## $ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ~
## $ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ~
## $ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186~
## $ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ~
## $ sex               <chr> "male", "female", "female", NA, "female", "male", "f~
## $ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007~
\end{verbatim}

The function takes one argument: the name of a data frame or tibble. It then tells us how many rows it has, how many columns there are, what these columns are called, and what type of data is associated with them. This function is useful when we need a quick overview of what's inside our data set. Some advice---use this function on any new data set before trying to do anything with it.

\hypertarget{dplyr-pseudocode}{%
\subsection{\texorpdfstring{\textbf{dplyr} pseudocode}{dplyr pseudocode}}\label{dplyr-pseudocode}}

We'll wrap-up this chapter with a quick mention of `pseudocode'. Pseudocode uses structural conventions of normal R code but is intended for us (humans) to read rather than the computer. We use it summarise how \textbf{dplyr} functions work. Here's an example you will encounter in the next chapter:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

\textbf{This is not an example we can run.} It is pseudocode that serves as a template for using the \textbf{dplyr} \texttt{select} function. The words surrounded by `angle brackets' (\texttt{\textless{}\ \textgreater{}}) are placeholders. If we want to turn this pseudocode into real R code we have to \textbf{replace those placeholders}. For example, \texttt{\textless{}data\textgreater{}} is a placeholder for the name of a data set. We would replace that with the word \texttt{penguins} if we want to use select on our example data set (we'd also have to do something with the other placeholders (e.g.~\texttt{\textless{}variable-1\textgreater{}})---we'll get to that later).

That's enough about pseudocode and \textbf{dplyr} templates. We'll see plenty of these in the next few chapters.

\hypertarget{working-with-variables}{%
\chapter{Working with variables}\label{working-with-variables}}

\hypertarget{introduction-3}{%
\section{Introduction}\label{introduction-3}}

This chapter will explore the \textbf{dplyr} \texttt{select} and \texttt{mutate} verbs, and the closely related \texttt{rename} and \texttt{transmute} verbs. We consider these functions together because they operate on the variables (i.e.~the columns) of a data frame or tibble:

\begin{itemize}
\tightlist
\item
  The \texttt{select} function selects a subset of variables to retain and (optionally) renames them in the process.
\item
  The \texttt{mutate} function creates new variables from pre-existing ones and retains the original variables.
\item
  The \texttt{rename} function renames one or more variables while keeping the remaining variable names unchanged.
\item
  The \texttt{transmute} function creates new variables from pre-existing ones and drops the original variables.
\end{itemize}

\hypertarget{getting-ready}{%
\subsection{Getting ready}\label{getting-ready}}

Obviously, we need to have first installed \textbf{dplyr} package to use it. Assuming that's been done, we need to load and attach the package in the current session:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We will use the Palmer penguins data to illustrate the ideas in this chapter. Remember---the \protect\hyperlink{penguins-data-overview}{previous chapter} described this data set and explained where to find it. The examples below assume it was read into R as a tibble with the name \texttt{penguins}.

\hypertarget{subset-variables-with-select}{%
\section{\texorpdfstring{Subset variables with \texttt{select}}{Subset variables with select}}\label{subset-variables-with-select}}

We use \texttt{select} to \textbf{select variables} from a data frame or tibble. This is used when we have a data set with many variables but only need to work with a subset of these. Basic usage of \texttt{select} looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

Remember---this is not an example we can run. This is a pseudocode designed to provide a generic description of how we use \texttt{select}. Let's look at the arguments of select:

\begin{itemize}
\tightlist
\item
  The first argument, \texttt{\textless{}data\textgreater{}}, must be the name of the object containing our data (usually a data frame or tibble). This is not optional---\textbf{dplyr} functions only exist to manipulate data.
\item
  We then include a series of one or more additional arguments, where each one is the name of a variable in \texttt{\textless{}data\textgreater{}}. We've expressed this as \texttt{\textless{}variable-1\textgreater{},\ \textless{}variable-2\textgreater{},\ ...}, where \texttt{\textless{}variable-1\textgreater{}} and \texttt{\textless{}variable-2\textgreater{}} are names of the first two variables. The \texttt{...} is acting as a placeholder for the remaining variables. There could be any number of these.
\end{itemize}

It's easiest to understand how a function like \texttt{select} works by seeing it in action. We select the \texttt{species}, \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm} variables from \texttt{penguins} like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, species, bill\_length\_mm, bill\_depth\_mm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 3
##    species bill_length_mm bill_depth_mm
##    <chr>            <dbl>         <dbl>
##  1 Adelie            39.1          18.7
##  2 Adelie            39.5          17.4
##  3 Adelie            40.3          18  
##  4 Adelie            NA            NA  
##  5 Adelie            36.7          19.3
##  6 Adelie            39.3          20.6
##  7 Adelie            38.9          17.8
##  8 Adelie            39.2          19.6
##  9 Adelie            34.1          18.1
## 10 Adelie            42            20.2
## # ... with 334 more rows
\end{verbatim}

Hopefully, nothing about this example is too surprising. However, there are a few subtleties buried in that example:

\begin{itemize}
\tightlist
\item
  The \texttt{select} function is designed to work in a non-standard way which means variable names should \textbf{not} be surrounded by quotes. The one exception is when a name has a space in it. Under those circumstances, it has to be quoted with backticks, e.g.~\texttt{\textasciigrave{}variable\ 1\textasciigrave{}}.
\item
  The \texttt{select} function does not have `side effects'. This means is that it does not change the original \texttt{penguins} object. We printed the result produced by \texttt{select} to the Console, so we can't access the modified data set. If we need to use the result, we have to assign it a name using \texttt{\textless{}-}.
\item
  The order of variables (i.e.~the column order) in the resulting object is the same as the order in which they were supplied to the argument list. This means we can reorder variables at the same time as selecting them if we need to.
\item
  The \texttt{select} function will return the same kind of data object we give it to work on. It returns a data frame if our data was in a data frame and a tibble if it was a tibble. In this example, R prints a tibble because \texttt{penguins} was a tibble.
\end{itemize}

That second point is important---we have to remember to assign the result a name using \texttt{\textless{}-} if we want to keep it and use it later. For example, we might call the result of that last example \texttt{penguins\_bill}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_bill }\OtherTok{\textless{}{-}} \FunctionTok{select}\NormalTok{(penguins, species, bill\_length\_mm, bill\_depth\_mm)}
\end{Highlighting}
\end{Shaded}

Now that we've named the new data set created by \texttt{select} we can refer to it by that name whenever we need it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_bill}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 3
##    species bill_length_mm bill_depth_mm
##    <chr>            <dbl>         <dbl>
##  1 Adelie            39.1          18.7
##  2 Adelie            39.5          17.4
##  3 Adelie            40.3          18  
##  4 Adelie            NA            NA  
##  5 Adelie            36.7          19.3
##  6 Adelie            39.3          20.6
##  7 Adelie            38.9          17.8
##  8 Adelie            39.2          19.6
##  9 Adelie            34.1          18.1
## 10 Adelie            42            20.2
## # ... with 334 more rows
\end{verbatim}

Remember---the original \texttt{penguins} data is completely unchanged:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

\hypertarget{alternative-ways-to-identify-variables-with-select}{%
\subsection{\texorpdfstring{Alternative ways to identify variables with \texttt{select}}{Alternative ways to identify variables with select}}\label{alternative-ways-to-identify-variables-with-select}}

It's sometimes more convenient to use \texttt{select} to subset variables by specifying those we do \textbf{not} need, rather than specifying of the ones to keep. We can use the \texttt{!} operator to indicate that certain variables should be dropped. For example, to get rid of the \texttt{bill\_depth\_mm} and \texttt{bill\_length\_mm} columns, we could use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, }\SpecialCharTok{!}\NormalTok{bill\_depth\_mm, }\SpecialCharTok{!}\NormalTok{bill\_length\_mm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island    bill_length_mm flipper_length_mm body_mass_g sex     year
##    <chr>   <chr>              <dbl>             <int>       <int> <chr>  <int>
##  1 Adelie  Torgersen           39.1               181        3750 male    2007
##  2 Adelie  Torgersen           39.5               186        3800 female  2007
##  3 Adelie  Torgersen           40.3               195        3250 female  2007
##  4 Adelie  Torgersen           NA                  NA          NA <NA>    2007
##  5 Adelie  Torgersen           36.7               193        3450 female  2007
##  6 Adelie  Torgersen           39.3               190        3650 male    2007
##  7 Adelie  Torgersen           38.9               181        3625 female  2007
##  8 Adelie  Torgersen           39.2               195        4675 male    2007
##  9 Adelie  Torgersen           34.1               193        3475 <NA>    2007
## 10 Adelie  Torgersen           42                 190        4250 <NA>    2007
## # ... with 334 more rows, and 1 more variable: bill_depth_mm <dbl>
\end{verbatim}

This returns a tibble with all the other variables: \texttt{species}, \texttt{island}, \texttt{flipper\_length\_mm}, \texttt{body\_mass\_g}, \texttt{sex} and \texttt{year}.

The \texttt{select} function can also be used to grab (or drop) a set of variables that occur in a sequence next to one another. We specify a series of adjacent variables using the \texttt{:} operator. We use this with two variable names, one on the left-hand side and one on the right. When we use \texttt{:} like this, \texttt{select} will subset both those two variables along with any others that fall in between them.

For example, if we want only the morphometric variables (\texttt{bill\_length\_mm}, \texttt{bill\_depth\_mm}, \texttt{flipper\_length\_mm} and \texttt{body\_mass\_g}) we could use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, bill\_length\_mm}\SpecialCharTok{:}\NormalTok{body\_mass\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 4
##    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##             <dbl>         <dbl>             <int>       <int>
##  1           39.1          18.7               181        3750
##  2           39.5          17.4               186        3800
##  3           40.3          18                 195        3250
##  4           NA            NA                  NA          NA
##  5           36.7          19.3               193        3450
##  6           39.3          20.6               190        3650
##  7           38.9          17.8               181        3625
##  8           39.2          19.6               195        4675
##  9           34.1          18.1               193        3475
## 10           42            20.2               190        4250
## # ... with 334 more rows
\end{verbatim}

The \texttt{:} operator can also be combined with \texttt{!} if we need to drop a series of variables according to their position in a data frame or tibble. For example, we can use this trick to get the complement of the previous example, i.e.~throw away the morphometric variables:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, }\SpecialCharTok{!}\NormalTok{bill\_length\_mm}\SpecialCharTok{:}\NormalTok{body\_mass\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 4
##    species island    sex     year
##    <chr>   <chr>     <chr>  <int>
##  1 Adelie  Torgersen male    2007
##  2 Adelie  Torgersen female  2007
##  3 Adelie  Torgersen female  2007
##  4 Adelie  Torgersen <NA>    2007
##  5 Adelie  Torgersen female  2007
##  6 Adelie  Torgersen male    2007
##  7 Adelie  Torgersen female  2007
##  8 Adelie  Torgersen male    2007
##  9 Adelie  Torgersen <NA>    2007
## 10 Adelie  Torgersen <NA>    2007
## # ... with 334 more rows
\end{verbatim}

\hypertarget{renaming-variables-with-select-and-rename}{%
\subsection{\texorpdfstring{Renaming variables with \texttt{select} and \texttt{rename}}{Renaming variables with select and rename}}\label{renaming-variables-with-select-and-rename}}

The \texttt{select} function can also rename variables at the same time as selecting them. To do this, we name the arguments using the \texttt{name\ =\ value} construct, where the name of the selected variable is placed on the right-hand side (\texttt{value}), and the new name goes on the left-hand side (\texttt{name}).

For example, to select the\texttt{species}, \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm} variables from \texttt{penguins}, and in the process, rename \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm} to \texttt{BillLength} and \texttt{BillDepth}, use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, species, }\AttributeTok{BillLength =}\NormalTok{ bill\_length\_mm, }\AttributeTok{BillDepth =}\NormalTok{ bill\_depth\_mm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 3
##    species BillLength BillDepth
##    <chr>        <dbl>     <dbl>
##  1 Adelie        39.1      18.7
##  2 Adelie        39.5      17.4
##  3 Adelie        40.3      18  
##  4 Adelie        NA        NA  
##  5 Adelie        36.7      19.3
##  6 Adelie        39.3      20.6
##  7 Adelie        38.9      17.8
##  8 Adelie        39.2      19.6
##  9 Adelie        34.1      18.1
## 10 Adelie        42        20.2
## # ... with 334 more rows
\end{verbatim}

Renaming the variables is a common task. What should we do if the only thing we want to achieve is to rename variables, rather than rename \emph{and} select them? \textbf{dplyr} provides an additional function called \texttt{rename} for exactly this purpose. This function renames some variables while retaining all others. It works like \texttt{select}. For example, to rename \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm} to \texttt{BillLength} and \texttt{BillDepth} but keep all the variables, use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rename}\NormalTok{(penguins, }\AttributeTok{BillLength =}\NormalTok{ bill\_length\_mm, }\AttributeTok{BillDepth =}\NormalTok{ bill\_depth\_mm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island  BillLength BillDepth flipper_length_~ body_mass_g sex    year
##    <chr>   <chr>        <dbl>     <dbl>            <int>       <int> <chr> <int>
##  1 Adelie  Torger~       39.1      18.7              181        3750 male   2007
##  2 Adelie  Torger~       39.5      17.4              186        3800 fema~  2007
##  3 Adelie  Torger~       40.3      18                195        3250 fema~  2007
##  4 Adelie  Torger~       NA        NA                 NA          NA <NA>   2007
##  5 Adelie  Torger~       36.7      19.3              193        3450 fema~  2007
##  6 Adelie  Torger~       39.3      20.6              190        3650 male   2007
##  7 Adelie  Torger~       38.9      17.8              181        3625 fema~  2007
##  8 Adelie  Torger~       39.2      19.6              195        4675 male   2007
##  9 Adelie  Torger~       34.1      18.1              193        3475 <NA>   2007
## 10 Adelie  Torger~       42        20.2              190        4250 <NA>   2007
## # ... with 334 more rows
\end{verbatim}

Notice \texttt{rename} also preserves the order of the variables found in the original data.

\hypertarget{creating-variables-with-mutate}{%
\section{\texorpdfstring{Creating variables with \texttt{mutate}}{Creating variables with mutate}}\label{creating-variables-with-mutate}}

We use \texttt{mutate} to \textbf{add new variables} to a data frame or tibble. This is useful if we need to construct one or more derived variables to support an analysis. Basic usage of \texttt{mutate} looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{expression}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{expression}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

Again, this is not an example we can run---it's pseudocode highlighting how to use \texttt{mutate} in abstract terms.

The first argument, \texttt{\textless{}data\textgreater{}}, must be the name of the object containing our data. We then include a series of one or more additional arguments, where each of these is a valid R expression involving one or more variables in \texttt{\textless{}data\textgreater{}}. We've have expressed these as \texttt{\textless{}expression-1\textgreater{},\ \textless{}expression-2\textgreater{}}, where \texttt{\textless{}expression-1\textgreater{}} and \texttt{\textless{}expression-2\textgreater{}} represent the first two expressions, and the \texttt{...} is acting as a placeholder for the remaining expressions. These can be any valid R code that refers to variables in \texttt{\textless{}data\textgreater{}}. This is often a simple calculation (e.g.~involving arithmetic), but it can be arbitrarily complex.

To see \texttt{mutate} in action, let's construct a new version of \texttt{penguins} that contains one extra variable---body mass measured in kilograms:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(penguins, body\_mass\_g }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 9
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 3 more variables: sex <chr>, year <int>,
## #   body_mass_g/1000 <dbl>
\end{verbatim}

This creates a copy of \texttt{penguins} with a new column called \texttt{body\_mass\_g/1000} (look at the bottom of the printed output). That is not a very good name but do not worry---we will improve on it in a moment. Most of the rules that apply to \texttt{select} also apply to \texttt{mutate}:

\begin{itemize}
\tightlist
\item
  Quotes must not be placed around an expression that performs a calculation.~ This makes sense because the expression is meant to be evaluated so that it ``does something''. It is not a value.
\item
  The \texttt{mutate} function does not have side effects, meaning it does not change the original \texttt{penguins} in any way. In the example, we printed the result produced by \texttt{mutate} rather than assigning it a name using \texttt{\textless{}-}, which means we have no way to access the result.
\item
  The \texttt{mutate} function returns the same kind of object as the one it is working on: a data frame if our data was originally in a data frame, a tibble if it was a tibble.
\end{itemize}

Creating a variable called something like \texttt{body\_mass\_g/1000} is not ideal because that is a difficult name to work with. Fortunately, the \texttt{mutate} function can name new variables at the same time as it creates them. We just name the arguments using \texttt{=}, placing the name on the left-hand side. Look at how to use this construct to name the new area variable \texttt{body\_mass\_kg}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(penguins, }\AttributeTok{body\_mass\_kg =}\NormalTok{ body\_mass\_g }\SpecialCharTok{/} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 9
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 3 more variables: sex <chr>, year <int>,
## #   body_mass_kg <dbl>
\end{verbatim}

We can create more than one variable by supplying \texttt{mutate} multiple (named) arguments:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mutate}\NormalTok{(penguins, }
       \AttributeTok{bill\_size =}\NormalTok{ bill\_depth\_mm }\SpecialCharTok{*}\NormalTok{ bill\_length\_mm,}
       \AttributeTok{scaled\_bill\_size =}\NormalTok{ bill\_size }\SpecialCharTok{/}\NormalTok{ body\_mass\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 10
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 4 more variables: sex <chr>, year <int>,
## #   bill_size <dbl>, scaled_bill_size <dbl>
\end{verbatim}

Notice that we placed each calculation on a new line, remembering to use a comma to separate arguments. We can do this because R ignores white space. Splitting long a function call across multiple lines in this way is helpful because it makes it easier to read and understand the sequence of calculations.

This last example reveals a nice feature of \texttt{mutate}---we can use newly created variables in further calculations. Here we constructed a synthetic bill size variable, and used that to calculate a second variable representing the ratio of bill size to body mass.

\hypertarget{transforming-and-dropping-variables}{%
\subsection{Transforming and dropping variables}\label{transforming-and-dropping-variables}}

Occasionally we need to construct one or more new variables and then drop all the other ones in the original dataset. The \texttt{transmute} function is designed to do this. It works exactly like \texttt{mutate}, but it has a slightly different behaviour:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{transmute}\NormalTok{(penguins, }
          \AttributeTok{bill\_size =}\NormalTok{ bill\_depth\_mm }\SpecialCharTok{*}\NormalTok{ bill\_length\_mm,}
          \AttributeTok{scaled\_bill\_size =}\NormalTok{ bill\_size }\SpecialCharTok{/}\NormalTok{ body\_mass\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 2
##    bill_size scaled_bill_size
##        <dbl>            <dbl>
##  1      731.            0.195
##  2      687.            0.181
##  3      725.            0.223
##  4       NA            NA    
##  5      708.            0.205
##  6      810.            0.222
##  7      692.            0.191
##  8      768.            0.164
##  9      617.            0.178
## 10      848.            0.200
## # ... with 334 more rows
\end{verbatim}

Here we repeated the previous example, but now only the new variables were retained in the resulting tibble. If we also want to retain additional variables without altering them, we can pass them as unnamed arguments. For example, to retain \texttt{species} identity in the output, use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{transmute}\NormalTok{(penguins,}
\NormalTok{          species,}
          \AttributeTok{bill\_size =}\NormalTok{ bill\_depth\_mm }\SpecialCharTok{*}\NormalTok{ bill\_length\_mm,}
          \AttributeTok{scaled\_bill\_size =}\NormalTok{ bill\_size }\SpecialCharTok{/}\NormalTok{ body\_mass\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 3
##    species bill_size scaled_bill_size
##    <chr>       <dbl>            <dbl>
##  1 Adelie       731.            0.195
##  2 Adelie       687.            0.181
##  3 Adelie       725.            0.223
##  4 Adelie        NA            NA    
##  5 Adelie       708.            0.205
##  6 Adelie       810.            0.222
##  7 Adelie       692.            0.191
##  8 Adelie       768.            0.164
##  9 Adelie       617.            0.178
## 10 Adelie       848.            0.200
## # ... with 334 more rows
\end{verbatim}

\hypertarget{working-with-observations}{%
\chapter{Working with observations}\label{working-with-observations}}

\hypertarget{introduction-4}{%
\section{Introduction}\label{introduction-4}}

This chapter will explore the \texttt{filter} and \texttt{arrange} verbs. We discuss these functions together because they manipulate observations (i.e.~rows) of a data frame or tibble:

\begin{itemize}
\tightlist
\item
  The \texttt{filter} function extracts a subset of observations based on supplied criteria.
\item
  The \texttt{arrange} function reorders the rows according to the values in one or more variables.
\end{itemize}

\hypertarget{getting-ready-1}{%
\subsection{Getting ready}\label{getting-ready-1}}

We'll be using the \textbf{dplyr} package, so we need to remember to load and attach the package in the current session:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We'll use the Palmer penguins data again to illustrate the ideas in this chapter. The examples below assume those data been read into R as a tibble with the name \texttt{penguins}.

\hypertarget{relational-and-logical-operators}{%
\section{Relational and logical operators}\label{relational-and-logical-operators}}

Most \texttt{filter} operations rely on some combination of \textbf{relational and logical operators}. Relational operators allow us to ask questions like, ``are the values of `x' greater than those of `y': \texttt{x\ \textgreater{}\ y}''. These sorts of comparisons are used by R to express whether or not a particular condition is met (because they generate a logical vector of TRUE/FALSE values). Logical operators allow us to combine such conditions, thereby building up complex conditions from simpler ones.

This is best understood by example. We'll do that in a moment. For now, simply make a mental note of the different relational and logical operators:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Use \textbf{relational operators} to make comparisons between a pair of variables on the basis of conditions like `less than' or `equal to':

  \begin{itemize}
  \tightlist
  \item
    \texttt{x\ \textless{}\ y}: is x less than y?
  \item
    \texttt{x\ \textgreater{}\ y}: is x greater than y?
  \item
    \texttt{x\ \textless{}=\ y}: is x less than or equal to y?
  \item
    \texttt{x\ \textgreater{}=\ y}: is x greater than or equal to y?
  \item
    \texttt{x\ ==\ y}: is x equal to y?
  \item
    \texttt{x\ !=\ y}: is x not equal to y?
  \end{itemize}
\item
  Use \textbf{logical operators} to connect two or more comparisons to arrive at a single overall criterion:

  \begin{itemize}
  \tightlist
  \item
    \texttt{x\ \&\ y}: are both x AND y true?
  \item
    \texttt{x\ \textbar{}\ y}: is x OR y true?
  \end{itemize}
\end{enumerate}

\begin{infobox}{warning}

\hypertarget{double-or-single}{%
\subsubsection*{\texorpdfstring{Double \texttt{==} or single \texttt{=}?}{Double == or single =?}}\label{double-or-single}}
\addcontentsline{toc}{subsubsection}{Double \texttt{==} or single \texttt{=}?}

Remember to use `double equals' \texttt{==} when testing for equivalence between \texttt{x} and \texttt{y}. We all forget this from time to time and use `single equals' \texttt{=} instead. This will lead to an error. \textbf{dplyr} is pretty good at spotting this mistake these days and will warn you in its error message that you used \texttt{=} when you meant to use \texttt{==}. Of course, if you don't read the error messages, you won't benefit from this helpful behaviour.

\end{infobox}

\hypertarget{subset-observations-with-filter}{%
\section{\texorpdfstring{Subset observations with \texttt{filter}}{Subset observations with filter}}\label{subset-observations-with-filter}}

We use \texttt{filter} to \textbf{subset observations} in a data frame or tibble containing our data. This is useful when we want to limit an analysis to a particular group of observations. Basic usage of \texttt{filter} looks something like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{expression}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{expression}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

Yes, this is pseudocode again. Let's review the arguments:

\begin{itemize}
\tightlist
\item
  The first argument, \texttt{\textless{}data\textgreater{}}, must be the name of the object (usually a data frame or tibble) containing our data. As with all \textbf{dplyr} verbs, this is not optional.
\item
  We then include one or more additional arguments. Each of these is a valid R expression involving one or more variables in \texttt{\textless{}data\textgreater{}} that returns a logical vector. We've expressed these as \texttt{\textless{}expression-1\textgreater{},\ \textless{}expression-2\textgreater{},\ ...}, where \texttt{\textless{}expression-1\textgreater{}} and \texttt{\textless{}expression-2\textgreater{}} represent the first two expressions, and the \texttt{...} is acting as placeholder for the remaining expressions.
\end{itemize}

To see \texttt{filter} in action, we'll use it to subset observations in the \texttt{penguins} dataset, based on two relational criteria:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(penguins, bill\_length\_mm }\SpecialCharTok{\textgreater{}} \DecValTok{45}\NormalTok{, bill\_depth\_mm }\SpecialCharTok{\textgreater{}} \DecValTok{18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 44 x 8
##    species   island    bill_length_mm bill_depth_mm flipper_length_~ body_mass_g
##    <chr>     <chr>              <dbl>         <dbl>            <int>       <int>
##  1 Adelie    Torgersen           46            21.5              194        4200
##  2 Adelie    Torgersen           45.8          18.9              197        4150
##  3 Adelie    Biscoe              45.6          20.3              191        4600
##  4 Chinstrap Dream               50            19.5              196        3900
##  5 Chinstrap Dream               51.3          19.2              193        3650
##  6 Chinstrap Dream               45.4          18.7              188        3525
##  7 Chinstrap Dream               52.7          19.8              197        3725
##  8 Chinstrap Dream               46.1          18.2              178        3250
##  9 Chinstrap Dream               51.3          18.2              197        3750
## 10 Chinstrap Dream               46            18.9              195        4150
## # ... with 34 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

In this example, we've created a subset of \texttt{penguins} that only includes observations where the \texttt{bill\_length\_mm} variable is greater than 45 \textbf{and} the \texttt{bill\_depth\_mm} variable is greater than 45, i.e.~both conditions must be met for an observation to be retained. This is probably starting to feel repetitious, but there are a few features of \texttt{filter} that we should be aware of:

\begin{itemize}
\tightlist
\item
  We do not surround each expression with quotes. The expression is meant to be evaluated---it is not 'a value.
\item
  The result produced by \texttt{filter} was printed to the Console in the example. The \texttt{filter} function did not change the original \texttt{penguins} in any way (no side effects!).
\item
  The \texttt{filter} function will return the same kind of data object it is working on: it returns a data frame if our data was originally in a data frame, and a tibble if it was a tibble.
\end{itemize}

Notice that including are two conditions separated by a comma means both conditions have to be met. There is another way to achieve the exact same result:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(penguins, bill\_length\_mm }\SpecialCharTok{\textgreater{}} \DecValTok{45} \SpecialCharTok{\&}\NormalTok{ bill\_depth\_mm }\SpecialCharTok{\textgreater{}} \DecValTok{18}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 44 x 8
##    species   island    bill_length_mm bill_depth_mm flipper_length_~ body_mass_g
##    <chr>     <chr>              <dbl>         <dbl>            <int>       <int>
##  1 Adelie    Torgersen           46            21.5              194        4200
##  2 Adelie    Torgersen           45.8          18.9              197        4150
##  3 Adelie    Biscoe              45.6          20.3              191        4600
##  4 Chinstrap Dream               50            19.5              196        3900
##  5 Chinstrap Dream               51.3          19.2              193        3650
##  6 Chinstrap Dream               45.4          18.7              188        3525
##  7 Chinstrap Dream               52.7          19.8              197        3725
##  8 Chinstrap Dream               46.1          18.2              178        3250
##  9 Chinstrap Dream               51.3          18.2              197        3750
## 10 Chinstrap Dream               46            18.9              195        4150
## # ... with 34 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

This version links the two parts with the logical \texttt{\&} operator. That is, rather than supplying \texttt{bill\_length\_mm\ \textgreater{}\ 45} and \texttt{bill\_depth\_mm\ \textgreater{}\ 18} as two arguments, we used a single R expression, combining them with the \texttt{\&}.

We're pointing this out because we sometimes need to create filtering criteria that cannot be expressed as `condition 1' \textbf{and} `condition 2' \textbf{and} `condition 3'\ldots{} etc. Under those conditions we have to use logical operators to connect conditions. A simple instance of this situation is where we need to subset on an \textbf{either/or} basis. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(penguins, bill\_length\_mm }\SpecialCharTok{\textless{}} \DecValTok{36} \SpecialCharTok{|}\NormalTok{ bill\_length\_mm }\SpecialCharTok{\textgreater{}} \DecValTok{54}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 29 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           34.1          18.1               193        3475
##  2 Adelie  Torgersen           34.6          21.1               198        4400
##  3 Adelie  Torgersen           34.4          18.4               184        3325
##  4 Adelie  Biscoe              35.9          19.2               189        3800
##  5 Adelie  Biscoe              35.3          18.9               187        3800
##  6 Adelie  Biscoe              35            17.9               190        3450
##  7 Adelie  Biscoe              34.5          18.1               187        2900
##  8 Adelie  Biscoe              35.7          16.9               185        3150
##  9 Adelie  Biscoe              35.5          16.2               195        3350
## 10 Adelie  Torgersen           35.9          16.6               190        3050
## # ... with 19 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

This creates a subset of \texttt{penguins} that only includes observation where \texttt{bill\_length\_mm} is less than 36 \textbf{or} (\texttt{\textbar{}}) greater than 54. This creates a subset of the data associated with the more `extreme' values of bill length (unusually small or large).

We're not limited to using relational and logical operators when working with \texttt{filter}. The conditions specified in the \texttt{filter} function can be any expression that returns a logical vector. The only constraint is that the output vector's length has to equal its input's length, or be a single logical values (\texttt{TRUE} or \texttt{FALSE}).

Here's an example. The \textbf{dplyr} \texttt{between} function is used to determine whether the values of a numeric vector fall in a specified range. It has three arguments: the numeric vector to filter on and the lower and upper and boundary values. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(penguins, }\FunctionTok{between}\NormalTok{(bill\_length\_mm, }\DecValTok{36}\NormalTok{, }\DecValTok{54}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 313 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           36.7          19.3               193        3450
##  5 Adelie  Torgersen           39.3          20.6               190        3650
##  6 Adelie  Torgersen           38.9          17.8               181        3625
##  7 Adelie  Torgersen           39.2          19.6               195        4675
##  8 Adelie  Torgersen           42            20.2               190        4250
##  9 Adelie  Torgersen           37.8          17.1               186        3300
## 10 Adelie  Torgersen           37.8          17.3               180        3700
## # ... with 303 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

\hypertarget{reordering-observations-with-arrange}{%
\section{\texorpdfstring{Reordering observations with \texttt{arrange}}{Reordering observations with arrange}}\label{reordering-observations-with-arrange}}

We use \texttt{arrange} to \textbf{reorder the rows} of a data frame or tibble. Basic usage of \texttt{arrange} looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{arrange}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

Yes, this is pseudocode. As always, the first argument, \texttt{\textless{}data\textgreater{}}, is the name of the object containing our data. We then include a series of one or more additional arguments, where each of these is the name of a variable in \texttt{\textless{}data\textgreater{}}: \texttt{\textless{}variable-1\textgreater{}} and \texttt{\textless{}variable-2\textgreater{}} are names of the first two ordering variables, and the \texttt{...} is acting as a placeholder for the remaining variables.

To see \texttt{arrange} in action, let's construct a new version of \texttt{penguins} where the rows have been reordered first by \texttt{flipper\_length\_mm}, and then by \texttt{body\_mass\_g}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{arrange}\NormalTok{(penguins, flipper\_length\_mm, body\_mass\_g)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species   island    bill_length_mm bill_depth_mm flipper_length_~ body_mass_g
##    <chr>     <chr>              <dbl>         <dbl>            <int>       <int>
##  1 Adelie    Biscoe              37.9          18.6              172        3150
##  2 Adelie    Biscoe              37.8          18.3              174        3400
##  3 Adelie    Torgersen           40.2          17                176        3450
##  4 Adelie    Dream               33.1          16.1              178        2900
##  5 Adelie    Dream               39.5          16.7              178        3250
##  6 Chinstrap Dream               46.1          18.2              178        3250
##  7 Adelie    Dream               37.2          18.1              178        3900
##  8 Adelie    Dream               37.5          18.9              179        2975
##  9 Adelie    Dream               42.2          18.5              180        3550
## 10 Adelie    Biscoe              37.7          18.7              180        3600
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

This creates a new version of \texttt{penguins} where the rows are sorted according to the values of by \texttt{flipper\_length\_mm} and \texttt{body\_mass\_g} in ascending order -- i.e.~from smallest to largest. Look at the cases where flipper length is 178 mm. What do these show? Since \texttt{flipper\_length\_mm} was placed before \texttt{body\_mass\_g} in the arguments, the values of \texttt{body\_mass\_g} are only used to break ties within any particular value of \texttt{flipper\_length\_mm}.

For the sake of avoiding doubt about how \texttt{arrange} works, we will quickly review its behaviour. It works the same as every other \textbf{dplyr} verb we have looked at:

\begin{itemize}
\tightlist
\item
  The variable names used as arguments of \texttt{arrange} are not surrounded by quotes.
\item
  The \texttt{arrange} function did not change the original \texttt{penguins} in any way.
\item
  The \texttt{arrange} function will return the same kind of data object it is working on.
\end{itemize}

\texttt{arrange} sorts variables in ascending order by default. If we need it to sort a variable in descending order, we wrap the variable name in the \textbf{dplyr} \texttt{desc} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{arrange}\NormalTok{(penguins, flipper\_length\_mm, }\FunctionTok{desc}\NormalTok{(body\_mass\_g))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species   island    bill_length_mm bill_depth_mm flipper_length_~ body_mass_g
##    <chr>     <chr>              <dbl>         <dbl>            <int>       <int>
##  1 Adelie    Biscoe              37.9          18.6              172        3150
##  2 Adelie    Biscoe              37.8          18.3              174        3400
##  3 Adelie    Torgersen           40.2          17                176        3450
##  4 Adelie    Dream               37.2          18.1              178        3900
##  5 Adelie    Dream               39.5          16.7              178        3250
##  6 Chinstrap Dream               46.1          18.2              178        3250
##  7 Adelie    Dream               33.1          16.1              178        2900
##  8 Adelie    Dream               37.5          18.9              179        2975
##  9 Adelie    Biscoe              40.5          18.9              180        3950
## 10 Adelie    Biscoe              38.8          17.2              180        3800
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

This creates a new version of \texttt{penguins} where the rows are sorted according to the values of \texttt{flipper\_length\_mm} and \texttt{body\_mass\_g}, in ascending and descending order, respectively. Look carefully at the values in the \texttt{flipper\_length\_mm} and \texttt{body\_mass\_g} columns to see the difference between this example and the previous one.

\hypertarget{summarising-and-grouping}{%
\chapter{Summarising and grouping}\label{summarising-and-grouping}}

This chapter will explore the \texttt{summarise} and \texttt{group\_by} verbs. We consider together because they are often used in combination. Their usage is also a bit different from the other \textbf{dplyr} verbs we've encountered. Here's a quick summary of what they do:

\begin{itemize}
\item
  The \texttt{group\_by} function adds information to its input (a data frame or tibble), which makes subsequent calculations happen on a group-specific basis.
\item
  The \texttt{summarise} function is a data reduction function that calculates single-number summaries of one or more variables, respecting the group structure if present.
\end{itemize}

We illustrate these ideas using the Paler penguins data set, which we assume has been read into a tibble called \texttt{peguins}.

\hypertarget{summarising-variables-with-summarise}{%
\section{\texorpdfstring{Summarising variables with \texttt{summarise}}{Summarising variables with summarise}}\label{summarising-variables-with-summarise}}

We use \texttt{summarise} to \textbf{calculate summaries of variables} in an object containing our data. We do this kind of calculation all the time when analysing data. In terms of pseudo-code, usage of \texttt{summarise} looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{expression}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{expression}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

The first argument, \texttt{\textless{}data\textgreater{}}, must be the name of the data frame or tibble containing our data. We then include a series of one or more additional arguments; each of these is a valid R expression involving at least one variable in \texttt{\textless{}data\textgreater{}}. These are given by the pseudo-code placeholder \texttt{\textless{}expression-1\textgreater{},\ \textless{}expression-2\textgreater{},\ ...}, where \texttt{\textless{}expression-1\textgreater{}} and \texttt{\textless{}expression-2\textgreater{}} represent the first two expressions, and the \texttt{...} is acting as placeholder for the remaining expressions. These expressions can be any calculation involving R functions that returns a vector of some kind.

The \texttt{summarise} function seems to work a lot like \texttt{mutate}. The main difference is that the expressions \texttt{mutate} uses have to all return a vector of the same length as their inputs. In contrast, \texttt{summarise} expressions used all have to produce the same length output, but those outputs can be any length. They often return a single value because they are \textbf{summarising} the data in some way, but they don't have to.

The \texttt{summarise} verb is best understood by example. The \textbf{dplyr} function \texttt{n\_distinct} takes a calculates the number of distinct (i.e.~unique) cases in a vector. We can use \texttt{n\_distinct} with \texttt{summarise} to calculate the number of unique vales of the \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm} variables like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins, }\FunctionTok{n\_distinct}\NormalTok{(bill\_length\_mm), }\FunctionTok{n\_distinct}\NormalTok{(bill\_depth\_mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   `n_distinct(bill_length_mm)` `n_distinct(bill_depth_mm)`
##                          <int>                       <int>
## 1                          165                          81
\end{verbatim}

Notice what kind of object \texttt{summarise} returns---it's a tibble with one row and two columns: two columns because we calculated two counts, and one row containing because we only one set of counts. There are a few other things to note about how \texttt{summarise} works:

\begin{itemize}
\tightlist
\item
  The expression that performs each calculation is not surrounded by quotes because it's an expression that it `does a calculation'.
\item
  The order of the columns in the output is the same as the order in which they were created in the \texttt{\textless{}expression-1\textgreater{},\ \textless{}expression-2\textgreater{},\ ...} list.
\item
  \texttt{summarise} returns the same kind of data object as its input---it returns a data frame if our data was originally in a data frame, or a tibble if it was in a tibble.
\item
  If we don't specify a name \texttt{summarise} uses the actual R expression to name the columns of its output (e.g.~\texttt{n\_distinct(bill\_length\_mm)}\textbf{)}
\end{itemize}

Variable names based on the calculation (e.g.~\texttt{n\_distinct(bill\_length\_mm)}) are not ideal because they are long and contain special reserved characters like \texttt{(}. This makes it difficult refer to columns in the output because we have to remember to place back ticks (\texttt{\textasciigrave{}}) around their name whenever we want to refer to them.

Fortunately, the \texttt{summarise} function can name the new variables at the same time as they are created (just like \texttt{mutate}). We do this by naming the arguments using \texttt{=}, placing the name we require on the left hand side. For example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins, }
          \AttributeTok{n\_bill\_length =} \FunctionTok{n\_distinct}\NormalTok{(bill\_length\_mm), }
          \AttributeTok{n\_bill\_depth  =} \FunctionTok{n\_distinct}\NormalTok{(bill\_depth\_mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   n_bill_length n_bill_depth
##           <int>        <int>
## 1           165           81
\end{verbatim}

This time we end up with summary data set that has reasonable column names. Notice how we organised that example---we placed each calculation on a new line. We don't have to do this, but since R doesn't care about white space, we can use newlines and spaces to keep everything more human-readable. It pays to organise \texttt{summarise} calculations like this when they become longer.

\hypertarget{more-complicated-calculations-with-summarise}{%
\subsection{\texorpdfstring{More complicated calculations with \texttt{summarise}}{More complicated calculations with summarise}}\label{more-complicated-calculations-with-summarise}}

Many useful base R functions can be used with \texttt{summarise}. Of particular value are those that calculate various summaries of numeric variables are, such as:

\begin{itemize}
\tightlist
\item
  \texttt{min} and \texttt{max} calculate the minimum and maximum values,
\item
  \texttt{mean} and \texttt{median} calculate the mean and median, and
\item
  \texttt{sd} and \texttt{var} calculate the standard deviation and variance.
\end{itemize}

We do need to pay attention when using base R functions with \textbf{dplyr}. Take a look at this attempt to use summarise to calculate the mean of \texttt{bill\_length\_mm} and \texttt{bill\_length\_mm}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins, }
          \AttributeTok{n\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm), }
          \AttributeTok{n\_bill\_depth  =} \FunctionTok{mean}\NormalTok{(bill\_depth\_mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   n_bill_length n_bill_depth
##           <dbl>        <dbl>
## 1            NA           NA
\end{verbatim}

No numbers---just a pair of \texttt{NA}s. We forgot about the presence of missing values in the \texttt{penguins} data. Both \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm} contain missing values. When the \texttt{mean} function encounters even one missing value in its input its default behaviour is to spit out \texttt{NA}. It is possible to change that behaviour by setting the \texttt{na.rm} argument of \texttt{mean}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins, }
          \AttributeTok{n\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), }
          \AttributeTok{n\_bill\_depth  =} \FunctionTok{mean}\NormalTok{(bill\_depth\_mm,  }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   n_bill_length n_bill_depth
##           <dbl>        <dbl>
## 1          43.9         17.2
\end{verbatim}

This example demonstrates something important---the functions we use within \texttt{summarise} often have their own arguments, and we sometimes need to set those arguments to perform the calculation we want.

Almost any R code can be used as \texttt{summarise} expressions. This means we can combine more than one function to build up arbitrarily complicated calculations. For example, if we need to know the ratio of the mean bill length and mean bill width in \texttt{penguins}, we would use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins,}
  \AttributeTok{ratio =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(bill\_depth\_mm,  }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   ratio
##   <dbl>
## 1  2.56
\end{verbatim}

The ability to work with arbitrary expressions makes \texttt{summarise} (and \texttt{mutate}) very powerful.

\hypertarget{grouped-operations-using-group_by}{%
\section{\texorpdfstring{Grouped operations using \texttt{group\_by}}{Grouped operations using group\_by}}\label{grouped-operations-using-group_by}}

Performing a calculation with one or more variables using the whole data set can be useful. However, we often need to carry out calculations on different subsets of our data. For example, it's more useful to know how the mean bill length and depth vary among the different species in the \texttt{penguins} data set, rather than knowing the overall mean of these traits. We could calculate separate means by using \texttt{filter} to create different subsets of \texttt{penguins}, and then use \texttt{summary} on each of these to calculate the means. This would get the job done, but it's inefficient and quickly becomes tiresome if we have to work with many groups.

The \texttt{group\_by} function provides an elegant solution to this kind of problem. All the \texttt{group\_by} function does is add a bit of information to a tibble or data frame. In effect, it defines subsets of data based on one or more \textbf{grouping variables}. That's all it does.

The magic happens when the grouped object is used with a \textbf{dplyr} verb like \texttt{summarise} or \texttt{mutate}. Once a the data has been tagged with grouping information, operations that involve \textbf{dplyr} verbs are carried out on separate subsets of the data---defined by the values of the grouping variable(s)---and then combined.

Basic usage of \texttt{group\_by} looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{group\_by}\NormalTok{(}\SpecialCharTok{\textless{}}\NormalTok{data}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}1}\SpecialCharTok{\textgreater{}}\NormalTok{, }\SpecialCharTok{\textless{}}\NormalTok{variable}\DecValTok{{-}2}\SpecialCharTok{\textgreater{}}\NormalTok{, ...)}
\end{Highlighting}
\end{Shaded}

The first argument, \texttt{\textless{}data\textgreater{}}, must be the name of the object containing our data. We then have to include one or more additional arguments, where each one is the name of a variable in \texttt{\textless{}data\textgreater{}}. We have expressed this as \texttt{\textless{}variable-1\textgreater{},\ \textless{}variable-2\textgreater{},\ ...}, where \texttt{\textless{}variable-1\textgreater{}} and \texttt{\textless{}variable-2\textgreater{}} are names of the first two variables, and the \texttt{...} is acting as a placeholder for the remaining variables.

We'll illustrate \texttt{group\_by} by using it alongside \texttt{summarise}. We're aiming to calculate the mean bill length for each species in \texttt{penguins}. This is a two-step process. The first step uses \texttt{group\_by} to add grouping information to \texttt{penguins}. Take a look at what we end up with when we do that:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{group\_by}\NormalTok{(penguins, species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
## # Groups:   species [3]
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

Compare this to the output produced when we print the original \texttt{penguins} data set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

There is very little difference---\texttt{group\_by} really doesn't do much on its own. The main change is that printing the tibble resulting from the \texttt{group\_by} operation shows a bit of additional information at the top: \texttt{Groups:\ species\ {[}3{]}}. This tells us that the tibble is now grouped by the \texttt{species} variable. The \texttt{{[}3{]}} part tells us that there are three different groups (i.e.~species of penguin). The \textbf{only} thing \texttt{group\_by} did was add this grouping information to a copy of \texttt{penguins}.

The original \texttt{penguins} object was not altered in any way. If we want to do anything useful with the grouped tibble we need to assign it a name so that we can work with it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_by\_species }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(penguins, species)}
\end{Highlighting}
\end{Shaded}

Now we have a grouped tibble called \texttt{penguins\_by\_species} in which the value of \texttt{species} define the different groups---any row where \texttt{species} is equal to `Adelie' is assigned to the first group, any row where \texttt{species} is equal to `Chinstrap' is assigned to a second group, and any row where \texttt{species} is equal to `Gentoo' is assigned to a third group.

\textbf{dplyr} operations on this tibble will now be performed on a `by group' basis. To see this in action, we use \texttt{summarise} to calculate the mean bill length:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins\_by\_species, }
          \AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species   mean_bill_length
##   <chr>                <dbl>
## 1 Adelie                38.8
## 2 Chinstrap             48.8
## 3 Gentoo                47.5
\end{verbatim}

This is part two of the two-step process mentioned above. When we used \texttt{summarise} on an ungrouped object, the result was a tibble with one row---the overall global mean. Now the resulting tibble has three rows, one for each species in the data set. The \texttt{mean\_bill\_length} column shows the mean bill lengths for each species. The \texttt{species} column tells us what species each mean belongs to. Notice that \texttt{summarise} also printed an (un)helpful message:

\begin{verbatim}
`summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

There's no need to worry about this. It is simply saying that \texttt{summarise} has removed the grouping information from the resulting tibble.

We can also carry out multiple calculations with grouped data if we need to. For example, if we need to calculate the mean bill length and mean bill depth for each species, we would use the grouped version of \texttt{penguins} like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins\_by\_species, }
          \AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
          \AttributeTok{mean\_bill\_depth  =} \FunctionTok{mean}\NormalTok{(bill\_depth\_mm,  }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##   species   mean_bill_length mean_bill_depth
##   <chr>                <dbl>           <dbl>
## 1 Adelie                38.8            18.3
## 2 Chinstrap             48.8            18.4
## 3 Gentoo                47.5            15.0
\end{verbatim}

\hypertarget{more-than-one-grouping-variable}{%
\subsection{More than one grouping variable}\label{more-than-one-grouping-variable}}

What if we need to calculate summaries using more than one grouping variable? The workflow is unchanged. Assume we need to know the mean body mass of males and females of each penguin species. First, we make a grouped copy of \texttt{penguins} using the appropriate grouping variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_by\_species\_sex }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(penguins, species, sex)}
\end{Highlighting}
\end{Shaded}

We called the grouped tibble \texttt{penguins\_by\_species\_sex}. Look at what happens when we print this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_by\_species\_sex}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
## # Groups:   species, sex [8]
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

We see \texttt{Groups:\ species,\ sex\ {[}8{]}} near the top, which tells us that the tibble is grouped by two variables (\texttt{species} and \texttt{sex}) with eight unique combinations of values. That seems odd at first---there are three species and two sexes represented in this dataset, which gives six possible combinations at most.

The reason for the discrepancy becomes clear when we move on to calculate the mean body mass for each sex-species combination:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins\_by\_species\_sex, }
          \AttributeTok{body\_mass\_g =} \FunctionTok{mean}\NormalTok{(body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'species'. You can override using the `.groups` argument.
\end{verbatim}

\begin{verbatim}
## # A tibble: 8 x 3
## # Groups:   species [3]
##   species   sex    body_mass_g
##   <chr>     <chr>        <dbl>
## 1 Adelie    female       3369.
## 2 Adelie    male         4043.
## 3 Adelie    <NA>         3540 
## 4 Chinstrap female       3527.
## 5 Chinstrap male         3939.
## 6 Gentoo    female       4680.
## 7 Gentoo    male         5485.
## 8 Gentoo    <NA>         4588.
\end{verbatim}

This shows mean body mass for each unique combination of \texttt{species} and \texttt{sex}. The first line shows that the mean body mass associated with female Adelie penguins is 3369; the second line shows us the mean body mass associated with male Adelie penguins is 4043. The third line shows us the mean body mass of Adelie penguins where \textbf{sex is missing} (\texttt{NA}). That explains why we ended up with more groups than unique combinations of \texttt{species} and \texttt{sex} --- missing values create extra groups.

\hypertarget{using-group_by-with-other-verbs}{%
\subsection{\texorpdfstring{Using \texttt{group\_by} with other verbs}{Using group\_by with other verbs}}\label{using-group_by-with-other-verbs}}

The \texttt{summarise} function is the \textbf{dplyr} verb that is most often used with grouped data. However, all the main \textbf{dplyr} verbs will alter their behaviour to respect group information when it is present. For example, when \texttt{mutate} or \texttt{transmute} are used with a grouped object the calculation of new variables occur ``by group''. Here's an example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create a data set \textquotesingle{}mean centred\textquotesingle{} bill length variable}
\FunctionTok{transmute}\NormalTok{(penguins\_by\_species\_sex,}
          \AttributeTok{body\_mass\_cen =}\NormalTok{ body\_mass\_g }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 3
## # Groups:   species, sex [8]
##    species sex    body_mass_cen
##    <chr>   <chr>          <dbl>
##  1 Adelie  male          -293. 
##  2 Adelie  female         431. 
##  3 Adelie  female        -119. 
##  4 Adelie  <NA>            NA  
##  5 Adelie  female          81.2
##  6 Adelie  male          -393. 
##  7 Adelie  female         256. 
##  8 Adelie  male           632. 
##  9 Adelie  <NA>           -65  
## 10 Adelie  <NA>           710  
## # ... with 334 more rows
\end{verbatim}

This calculated a standardised measure of body mass. The new \texttt{body\_mass\_cen} variable contains the difference between the original body mass and its mean in the appropriate species-sex group (rather than the overall mean).

\hypertarget{removing-grouping-information}{%
\section{Removing grouping information}\label{removing-grouping-information}}

On occasion, it's necessary to remove grouping information and revert to operating on the whole data set. The \texttt{ungroup} function removes grouping information:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ungroup}\NormalTok{(penguins\_by\_species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.1          18.7               181        3750
##  2 Adelie  Torgersen           39.5          17.4               186        3800
##  3 Adelie  Torgersen           40.3          18                 195        3250
##  4 Adelie  Torgersen           NA            NA                  NA          NA
##  5 Adelie  Torgersen           36.7          19.3               193        3450
##  6 Adelie  Torgersen           39.3          20.6               190        3650
##  7 Adelie  Torgersen           38.9          17.8               181        3625
##  8 Adelie  Torgersen           39.2          19.6               195        4675
##  9 Adelie  Torgersen           34.1          18.1               193        3475
## 10 Adelie  Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

Looking at the top right of the printed summary, we can see that the \texttt{Group:} part is now gone---the \texttt{ungroup} function effectively recreated the original \texttt{penguins} tibble.

\hypertarget{building-pipelines}{%
\chapter{Building pipelines}\label{building-pipelines}}

We don't often use the various \textbf{dplyr} verbs in isolation. Instead, they are combined in a sequence to prepare the data for further analysis. For example, we might create a new variable or two with \texttt{mutate} and then use \texttt{group\_by} and \texttt{summarise} to calculate some numerical summaries. This chapter will introduce something called the pipe operator: \texttt{\%\textgreater{}\%}. The pipe operator's job is to allow us to represent a sequence of such steps in a transparent, readable manner.

\hypertarget{why-do-we-need-pipes}{%
\section{Why do we need `pipes'?}\label{why-do-we-need-pipes}}

We've seen that carrying out calculations on a per-group basis can be achieved by grouping a tibble, assigning this a name, and then applying the \texttt{summarise} function to the new tibble. For example, in the previous chapter we saw that to calculate the mean bill length for each species in the Palmer penguins data set, \texttt{penguins}, we first create a grouped version of it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_by\_species }\OtherTok{\textless{}{-}} \FunctionTok{group\_by}\NormalTok{(penguins, species)}
\end{Highlighting}
\end{Shaded}

Then we use \texttt{summarise} with the grouped version to calculate the mean bill length in each group:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins\_by\_species, }
          \AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species   mean_bill_length
##   <chr>                <dbl>
## 1 Adelie                38.8
## 2 Chinstrap             48.8
## 3 Gentoo                47.5
\end{verbatim}

There's nothing wrong with this way of doing things. However, building up an analysis this was is quite lengthy because we have to keep storing intermediate steps. This is especially true if an analysis involves more than a couple of steps. It also tends to clutter the global environment with many intermediate objects we don't need to keep.

One way to make things more concise is to use \protect\hyperlink{combining-functions}{function nesting}, like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(}\FunctionTok{group\_by}\NormalTok{(penguins, species), }
          \AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species   mean_bill_length
##   <chr>                <dbl>
## 1 Adelie                38.8
## 2 Chinstrap             48.8
## 3 Gentoo                47.5
\end{verbatim}

In this version, we placed the \texttt{group\_by} function call inside the list of arguments to \texttt{summarise}. Remember---we have to read nested function calls from the inside out to understand what they are doing. This is exactly equivalent to the previous example, but now we get the result without having to store intermediate data.

However, there are a couple of very good reasons why this approach is not advised:

\begin{itemize}
\item
  Experienced R users might not mind this approach because they're used to it. Nonetheless, no reasonable person would argue that nesting functions inside one another is intuitive. Reading outward from the inside of a large number of nested functions is hard work.
\item
  Using function nesting is an error-prone approach. For example, it's very easy to accidentally put an argument on the wrong side of a closing \texttt{)}. If we're lucky, this will produce an error and we'll catch the problem. If we're not, we may end up with complete nonsense in the output.
\end{itemize}

\hypertarget{using-pipes}{%
\section{\texorpdfstring{Using pipes (\texttt{\%\textgreater{}\%})}{Using pipes (\%\textgreater\%)}}\label{using-pipes}}

There is a better way to combing \textbf{dplyr} functions, which has the dual benefit of keeping our code concise and readable while avoiding the need to clutter the global environment with intermediate objects. This third approach involves the `pipe operator': \texttt{\%\textgreater{}\%}. Notice there are no spaces between the three characters that make up the pipe---spaces are not allowed (e.g.~\texttt{\%\ \textgreater{}\ \%} will not be recognised as the pipe).

The pipe operator isn't part of base R. Instead, \textbf{dplyr} imports it from another package and makes it available for us to use.

The pipe has become very popular in recent years. The main reason for this is because it allows us to specify a chain of function calls in a (reasonably) human readable format. Here's how we write the previous example using the pipe operator \texttt{\%\textgreater{}\%}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{group\_by}\NormalTok{(., species) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarise}\NormalTok{(., }\AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species   mean_bill_length
##   <chr>                <dbl>
## 1 Adelie                38.8
## 2 Chinstrap             48.8
## 3 Gentoo                47.5
\end{verbatim}

How do we make sense of this? Every time we see the \texttt{\%\textgreater{}\%} operator it means the following: take whatever is produced by the left-hand expression and use it as an argument in the function on the right-hand side. The \texttt{.} serves as a placeholder for the location of the corresponding argument. A sequence of calculations can then be read from left to right, just as we would read the words in a book. This example says, take the \texttt{penguins} data, group it by \texttt{species}, then take that grouped tibble and apply the \texttt{summarise} function to it to calculate the mean of \texttt{mean\_bill\_length}.

This is exactly the same calculation we did above.

When using the pipe operator we can often leave out the \texttt{.} placeholder. Remember, this signifies the argument of the function on the right of \texttt{\%\textgreater{}\%} that is associated with the result from the left of \texttt{\%\textgreater{}\%}. If we choose to leave out the \texttt{.}, the pipe operator assumes we meant to slot it into the first argument. This means we can simplify our example even more:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{group\_by}\NormalTok{(species) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species   mean_bill_length
##   <chr>                <dbl>
## 1 Adelie                38.8
## 2 Chinstrap             48.8
## 3 Gentoo                47.5
\end{verbatim}

\textbf{This is why the first argument of a dplyr verb is always the data}. Adopting this convention ensures we can use \texttt{\%\textgreater{}\%} without explicitly specifying the argument to pipe into. Data goes into the pipe; data comes out of the pipe.

Remember, R does not care about white space, which means we can break a piped set of functions over several lines to make our code more readable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(species) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species   mean_bill_length
##   <chr>                <dbl>
## 1 Adelie                38.8
## 2 Chinstrap             48.8
## 3 Gentoo                47.5
\end{verbatim}

Now each step in the pipeline is on its own line. Most \textbf{dplyr} users use this formatting convention to improve the readability of their R code.

Finally, we do have to remember to assign the result of a chain of piped functions a name if we want to capture the result and use it later. We have to break the left to right rule a bit to do this, placing the assignment at the beginning\footnote{Actually, there is a rightward assignment operator, \texttt{-\textgreater{}}, but let's pretend that does not exist.}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bill\_length\_means }\OtherTok{\textless{}{-}} 
\NormalTok{  penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(species) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_bill\_length =} \FunctionTok{mean}\NormalTok{(bill\_length\_mm, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{infobox}{information}

\hypertarget{why-is-called-the-pipe-operator}{%
\subsubsection*{\texorpdfstring{Why is \texttt{\%\textgreater{}\%} called the `pipe' operator?}{Why is \%\textgreater\% called the `pipe' operator?}}\label{why-is-called-the-pipe-operator}}
\addcontentsline{toc}{subsubsection}{Why is \texttt{\%\textgreater{}\%} called the `pipe' operator?}

The \texttt{\%\textgreater{}\%} operator takes the output from one function and ``pipes it'' to another as the input. It's called `the pipe' for the simple reason that it allows us to create an analysis `pipeline' from a series of function calls. Incidentally, if you Google the phrase ``magrittr pipe'' you'll see why \textbf{magrittr} is a clever name for an R package.

\end{infobox}

One final piece of advice---make an effort to learn how to use the \texttt{\%\textgreater{}\%} method of piping together functions. Why? Because it's the simplest and cleanest method for doing this, many of the examples in the \textbf{dplyr} help files and on the web use it, and the majority of people carrying out real-world data wrangling with \textbf{dplyr} rely on piping.

\hypertarget{helper-functions}{%
\chapter{Helper functions}\label{helper-functions}}

\hypertarget{introduction-5}{%
\section{Introduction}\label{introduction-5}}

In addition to the main \textbf{dplyr} verbs, the package provides quite a few \textbf{helper functions}. Helper functions are used in conjunction with the main verbs to make specific tasks and calculations a bit easier. Many of these are summarised in the \textbf{dplyr} \href{https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf}{cheat sheat} (under \emph{Manipulate Variables}, \emph{Vector Functions} and \emph{Summary Functions}). We are not going to review every single one of them in this chapter. Instead, we aim to point out where helper functions tend to be used and highlight a few of the more useful ones.

\hypertarget{working-with-select}{%
\section{\texorpdfstring{Working with \texttt{select}}{Working with select}}\label{working-with-select}}

There are a few helper functions that can be used with \texttt{select}. Their job is to make it easier to match variable names according to various criteria. We'll look at the three simplest of these---look at the examples in the help file for \texttt{select} and the \href{https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf}{cheat sheat} to see what else is available.

We can select variables according to the sequence of characters used at the start of their name with the \texttt{starts\_with} function. For example, to select all the variables in \texttt{penguins} that begin with the word ``bill'', we use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"Bill"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 2
##    bill_length_mm bill_depth_mm
##             <dbl>         <dbl>
##  1           39.1          18.7
##  2           39.5          17.4
##  3           40.3          18  
##  4           NA            NA  
##  5           36.7          19.3
##  6           39.3          20.6
##  7           38.9          17.8
##  8           39.2          19.6
##  9           34.1          18.1
## 10           42            20.2
## # ... with 334 more rows
\end{verbatim}

This returns a tibble containing just \texttt{bill\_length\_mm} and \texttt{bill\_depth\_mm}. There is also a helper function to select variables according to characters used at the end of their name---the \texttt{ends\_with} function (no surprises there).

Notice that we quote the name we want to match against because \texttt{starts\_with} expects a literal character value. This is not optional. Unusually, \texttt{starts\_with} and \texttt{ends\_with} are not case sensitive by default. For example, we passed \texttt{starts\_with} the argument \texttt{"Bill"} instead of \texttt{"bill"}, yet it still selected variables beginning with the character string \texttt{"bill"}. If we want to select variables on a case-sensitive basis, we need to set an argument \texttt{ignore.case} to \texttt{FALSE} in \texttt{starts\_with} and \texttt{ends\_with}.

The last \texttt{select} helper function we'll look at is called \texttt{contains}. This one allows us to select variables based on a partial match \textbf{anywhere} in their name. Look at what happens if we pass \texttt{contains} the argument \texttt{"length"}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, }\FunctionTok{contains}\NormalTok{(}\StringTok{"length"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 2
##    bill_length_mm flipper_length_mm
##             <dbl>             <int>
##  1           39.1               181
##  2           39.5               186
##  3           40.3               195
##  4           NA                  NA
##  5           36.7               193
##  6           39.3               190
##  7           38.9               181
##  8           39.2               195
##  9           34.1               193
## 10           42                 190
## # ... with 334 more rows
\end{verbatim}

This selects all the variables with the word `length' in their name.

There is nothing to stop us combining the different variable selection methods. For example, we can use this approach to select all the variables that have some units at the end of their names (millimetres or grams):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{select}\NormalTok{(penguins, }\FunctionTok{ends\_with}\NormalTok{(}\StringTok{"\_mm"}\NormalTok{), }\FunctionTok{ends\_with}\NormalTok{(}\StringTok{"\_g"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 4
##    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##             <dbl>         <dbl>             <int>       <int>
##  1           39.1          18.7               181        3750
##  2           39.5          17.4               186        3800
##  3           40.3          18                 195        3250
##  4           NA            NA                  NA          NA
##  5           36.7          19.3               193        3450
##  6           39.3          20.6               190        3650
##  7           38.9          17.8               181        3625
##  8           39.2          19.6               195        4675
##  9           34.1          18.1               193        3475
## 10           42            20.2               190        4250
## # ... with 334 more rows
\end{verbatim}

When we apply more than one selection criteria like this, the \texttt{select} function returns the variables that match any criteria, rather than the set that meets all of them.

\hypertarget{working-with-mutate-and-transmute}{%
\section{\texorpdfstring{Working with \texttt{mutate} and \texttt{transmute}}{Working with mutate and transmute}}\label{working-with-mutate-and-transmute}}

There are quite a few \textbf{helper functions} that can be used with \texttt{mutate}. These make it easier to carry out certain calculations that aren't easy to do with base R. We won't explore these here as they tend to be needed only in quite specific circumstances. However, in situations where we need to construct an unusual variable, it's worth looking at that \href{https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf}{handy cheat sheat} to see what options might be available.

We will look at one particularly useful helper function that's used a lot when we need to recode a particular variable using \texttt{mutate}. The function is called \texttt{case\_when}. It works by setting up a series of paired matching criteria and replacement values. For example, imagine that we want to replace the names in \texttt{species} with three-letter shortcodes for each species. This is how to achieve that using \texttt{case\_when} with \texttt{mutate}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{species =} \FunctionTok{case\_when}\NormalTok{(}
\NormalTok{           species }\SpecialCharTok{==} \StringTok{"Adelie"}    \SpecialCharTok{\textasciitilde{}} \StringTok{"ADL"}\NormalTok{,}
\NormalTok{           species }\SpecialCharTok{==} \StringTok{"Gentoo"}    \SpecialCharTok{\textasciitilde{}} \StringTok{"GEN"}\NormalTok{,}
\NormalTok{           species }\SpecialCharTok{==} \StringTok{"Chinstrap"} \SpecialCharTok{\textasciitilde{}} \StringTok{"CHN"}\NormalTok{,}
           \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \StringTok{"UNKNOWN"}
\NormalTok{         )) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 344 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 ADL     Torgersen           39.1          18.7               181        3750
##  2 ADL     Torgersen           39.5          17.4               186        3800
##  3 ADL     Torgersen           40.3          18                 195        3250
##  4 ADL     Torgersen           NA            NA                  NA          NA
##  5 ADL     Torgersen           36.7          19.3               193        3450
##  6 ADL     Torgersen           39.3          20.6               190        3650
##  7 ADL     Torgersen           38.9          17.8               181        3625
##  8 ADL     Torgersen           39.2          19.6               195        4675
##  9 ADL     Torgersen           34.1          18.1               193        3475
## 10 ADL     Torgersen           42            20.2               190        4250
## # ... with 334 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

The \texttt{mutate} bit of this is not new. Look at the \texttt{case\_when} component---there are four criteria. The first of these is \texttt{species\ ==\ "Adelie"\ \ \ \ \textasciitilde{}\ "ADL"} . The way to read this is, ``look for cases where the value of \texttt{species} is equal to \texttt{"Adelie"}, and where that is true spit out the value \texttt{"ADL"}''. \texttt{case\_when} steps through each criterion like this in turn, trying to find a match. The last one \texttt{TRUE\ \textasciitilde{}\ "UNKNOWN"} acts as a catch-all for the non-matches.

This looks confusing at first but it does make sense with a bit of practise, and recoding variables using \texttt{case\_when} is a lot easier than going through a spreadsheet by hand.

\hypertarget{working-with-filter}{%
\section{\texorpdfstring{Working with \texttt{filter}}{Working with filter}}\label{working-with-filter}}

There aren't that many \textbf{dplyr} helper function that works with \texttt{filter}. In fact, we've already looked at the most useful one: the \texttt{between} function. This is used to identify cases where the values of a numeric variable lie inside a defined range. For example, if we want all the individuals that had a body mass in the 4-5kg range, we could use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(penguins, }\FunctionTok{between}\NormalTok{(body\_mass\_g, }\DecValTok{4000}\NormalTok{, }\DecValTok{5000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 116 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.2          19.6               195        4675
##  2 Adelie  Torgersen           42            20.2               190        4250
##  3 Adelie  Torgersen           34.6          21.1               198        4400
##  4 Adelie  Torgersen           42.5          20.7               197        4500
##  5 Adelie  Torgersen           46            21.5               194        4200
##  6 Adelie  Dream               39.2          21.1               196        4150
##  7 Adelie  Dream               39.8          19.1               184        4650
##  8 Adelie  Dream               44.1          19.7               196        4400
##  9 Adelie  Dream               39.6          18.8               190        4600
## 10 Adelie  Dream               42.3          21.2               191        4150
## # ... with 106 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

\hypertarget{working-with-summarise}{%
\section{\texorpdfstring{Working with \texttt{summarise}}{Working with summarise}}\label{working-with-summarise}}

There are a small number \textbf{dplyr} helper functions that can be used with \texttt{summarise}. These generally provide summaries that aren't available directly using base R functions. For example, we've already seen the \texttt{n\_distinct} function in action. This can be used to calculate the number of distinct values of a variable:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarise}\NormalTok{(penguins, }
          \AttributeTok{num\_species =} \FunctionTok{n\_distinct}\NormalTok{(species),}
          \AttributeTok{num\_island  =} \FunctionTok{n\_distinct}\NormalTok{(island ))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 2
##   num_species num_island
##         <int>      <int>
## 1           3          3
\end{verbatim}

This confirms what we already knew---that there are three unique species and three unique islands in the \texttt{penguins} data set.

\hypertarget{part-exporing-data}{%
\part{Exporing Data}\label{part-exporing-data}}

\hypertarget{exploratory-data-analysis}{%
\chapter{Exploratory data analysis}\label{exploratory-data-analysis}}

\hypertarget{introduction-6}{%
\section{Introduction}\label{introduction-6}}

Exploratory data analysis (EDA) was promoted by the statistician John Tukey in his 1977 book, ``Exploratory Data Analysis''. The broad goal of EDA is to help us formulate and refine hypotheses that lead to informative analyses or further data collection. The core objectives of EDA are:

\begin{itemize}
\tightlist
\item
  to suggest hypotheses about the causes of observed phenomena,
\item
  to guide the selection of appropriate statistical tools and techniques,
\item
  to assess the assumptions on which statistical analysis will be based,
\item
  to provide a foundation for further data collection.
\end{itemize}

EDA involves a mix of numerical and visual methods of analysis. Statistical methods are sometimes used to supplement EDA. However, the main purpose of EDA is to facilitate understanding before carrying out formal statistical modelling. Even if we already know what kind of analysis we plan to pursue, it's always a good idea to \textbf{explore a data set before diving into that analysis}. At the very least, this will help determine whether or not our plans are sensible. Very often, it uncovers new patterns and insights.

In this chapter, we're going to examine some basic concepts that underpin EDA. We will:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  see how to classify different \textbf{types of variables},
\item
  distinguish between \textbf{populations and samples}, and
\item
  review some key \textbf{descriptive statistics}.
\end{enumerate}

This will provide a conceptual foundation and vocabulary for learning how to explore data in later chapters.

\hypertarget{variables}{%
\section{Statistical variables and data}\label{variables}}

In the \protect\hyperlink{chapter-data-frames}{Data frames} chapter, we pointed out that the word `variable' can mean one of two things. In programming, a variable is a name-value association that we create when we run some code. Statisticians use the word differently. To them, a variable is any characteristic or quantity that can be measured, classified or experimentally controlled. Much of statistics is about quantifying and explaining the variation in such quantities as best we can.

Species richness, relative abundance, infection status, enzyme activity, gene frequency, and blood glucose concentration are examples of statistical variables we encounter in the biological sciences. These as statistical variables because their values vary between different observations. For instance, `annual fitness'---measured as the number of offspring produced---is a variable that differs both among the organisms in a population and over the life cycle of a given individual.

There are different ways to describe statistical variables according to how they can be analysed, measured, or presented. It's important to be clear about what kind of variables we're dealing with because this determines how we should visualise the data, and later, how we might analyse it statistically. There are many different ways to go about classifying variables. However, we only need to be aware of two fairly simple classification schemes in this book: numeric vs categorical variables and ratio vs interval scales.

\hypertarget{numeric-vs-categorical-variables}{%
\subsection{Numeric vs categorical variables}\label{numeric-vs-categorical-variables}}

\textbf{Numeric variables} have values that describe a measurable quantity like `how many' or `how much' as a number. Numeric variables are also called quantitative variables; the data collected containing numeric variables are called quantitative data. Numeric variables may be classified as either continuous or discrete:

\begin{itemize}
\item
  \textbf{Continuous numeric variable}: Observations can take any value in a set of real numbers, i.e.~numbers represented with decimals. Examples of continuous variables include concentration, mass, age, time, and temperature. The set of numbers a continuous variable takes is typically either `every possible number' or `just positive numbers'. For example, a concentration may be very large or very small, but it is strictly positive, whereas a change in concentration can be positive or negative.
\item
  \textbf{Discrete numeric variable}: Observations can take a value based on a count from a set of whole values, e.g.~1, 2, 3, 4, 5, and so on. A discrete variable cannot take the value of a fraction between one value and the next closest value. Examples of discrete variables include the number of individuals in a population, the number of offspring produced (`reproductive fitness'), and the number of infected individuals in an experiment. All of these are measured as whole units.
\end{itemize}

\textbf{Categorical variables} take values that describe a characteristic of a data unit, like `what type' or `which category'. Categorical variables fall into mutually exclusive (in one category or in another) and exhaustive (include all possible options) categories. Categorical variables are qualitative variables and tend to be represented by a non-numeric value; the data collected for a categorical variable are called qualitative data. Categorical variables may be further described as ordinal or nominal:

\begin{itemize}
\item
  \textbf{Ordinal variable}: Categories can be logically ordered or ranked. The categories associated with ordinal variables can be ranked higher or lower than another but do not necessarily establish a numeric difference between each category. Examples of ordinal categorical variables include academic grades (e.g.~A, B, C) and size classes (e.g.~small, medium, large).
\item
  \textbf{Nominal variable}: Categories cannot be organised into a logical sequence. Examples of nominal categorical variables include sex (see \emph{C. elegans} example), human blood group (A, B, AB and O), genotype (e.g.~AA, Aa, aa), experimental conditions (e.g.~control vs enhanced nutrition), and mortality status (alive vs dead).
\end{itemize}

\begin{infobox}{warning}

\hypertarget{do-not-use-numbers-to-classify-categorical-variables}{%
\subsubsection*{Do not use numbers to classify categorical variables}\label{do-not-use-numbers-to-classify-categorical-variables}}
\addcontentsline{toc}{subsubsection}{Do not use numbers to classify categorical variables}

Be careful when classifying variables. It can be dangerous to assume that just because a numerical scheme has been used to describe a variable, it must not be categorical. There is nothing to stop someone from using numbers to describe a categorical variable (e.g.~\emph{C. elegans} sex: Male = 1, Hermaphrodite = 2). That said, although we can use numbers to describe categories, it does not mean we should. Using numbers gets confusing and can lead to mistakes. It is much clearer to use a non-numeric recording scheme based on words or acronyms to record categorical variables (e.g.~\emph{C. elegans} sex: Male = ``Male'', Hermaphrodite = ``Herm'').

\end{infobox}

\hypertarget{ratio-vs-interval-scales}{%
\subsection{Ratio vs interval scales}\label{ratio-vs-interval-scales}}

A second way of classifying numeric variables (\textbf{not} categorical variables) relates to the scale they are measured on. The measurement scale is important because it determines how we interpret things like differences, ratios, and variability.

\begin{itemize}
\item
  \textbf{Ratio scale}: This scale does possess a meaningful zero value. It gets its name from the fact that a measurement on this scale represents a ratio between a measure of the magnitude of a quantity and a unit of the same kind. What this means in simple terms is that it is meaningful to say that something is ``twice as \ldots{}'' as something else when working with a variable measured on a ratio scales. Ratio scales most often appear when we work with physical quantities. For example, we can say that one tree is twice as big as another or that one elephant has twice the mass of another because length and mass are measured on ratio scales.
\item
  \textbf{Interval scale}: This allows for the degree of difference between measurements, but not the ratio between them. This kind of scale does not have a unique, non-arbitrary zero value. A good example of an interval scale is the date, which we measure relative to an arbitrary epoch (e.g.~AD). It makes no sense to say that 2000 AD is twice as long as 1000 AD. However, we can compare ratios of differences on an interval scale. For example, it does make sense to talk about the amount of time between two dates, i.e.~we can to say that twice as much time has passed since the epoch in 2000 AD versus 1000 AD.
\end{itemize}

Keep in mind that the distinction between ratio and interval scales is a property of the measurement scale, not the thing being measured. For example, when we measure temperature in º C we're working on an interval scale defined relative to the freezing and boiling temperatures of water under standard conditions. It doesn't make any sense to say that 30º C is twice as hot as 15º C. However, if we measured the same two temperatures on the Kelvin scale, it is meaningful to say that 303.2K is 1.05 times hotter than 288.2K. This is because the Kelvin scale is relative to a true zero (absolute zero).

\hypertarget{populations-samples}{%
\section{Populations and samples}\label{populations-samples}}

Whenever we collect data, we are almost always working with a sample drawn from a wider population. We might want to know something about that population, but since it is impossible to study the whole population, we study the properties of one or more samples instead. For example, a physiologist might want to know how exercise affects lung function. Since they obviously can't study every person on the planet, they have to study a small sample of people.

We mention the distinction between populations and samples because EDA is concerned with exploring the properties of samples. EDA aims to characterise a sample without trying to infer too much about the wider population from which it is derived. Learning about populations is the basis of much of statistics. That topic is best dealt with in a dedicated statistics book---not this one.

\hypertarget{sample-distributions}{%
\subsection{Sample distributions}\label{sample-distributions}}

When we say that `EDA is concerned with exploring the properties samples,' we actually mean that EDA is concerned with the properties of \textbf{variables} in one or more samples. We can be even more precise---the property we are alluding to is the variable's \textbf{sample distribution}. The distribution of a variable describes the relative frequency with which different values occur. This is best understood by example\ldots{}

Imagine we took a sample of undergraduates and measured their height. The majority of students would be around about 1.7m tall, even though there would be plenty of variation among students. Men would tend to be slightly taller than women, and very small or very tall people would be rare. We know from experience that no one in this sample would be over 3 meters tall. These are all statements about a hypothetical sample distribution of undergraduate heights.

\hypertarget{associations}{%
\subsection{Associations}\label{associations}}

We've been talking about statistical variables as though we study them one at a time. However, most interesting samples involve more than one variable, and the goal of the ensuing data analysis is to understand associations among those variables. These associations might involve the same (e.g.~numeric vs numeric) or different (e.g.~numeric vs categorical) types of variable. Whatever the details, the aim of EDA is often to understand how each variable in a sample relates to the others.

\hypertarget{types-of-eda}{%
\section{Types of EDA}\label{types-of-eda}}

Exploratory data analysis involves questions such as:

\begin{itemize}
\tightlist
\item
  \emph{What are the most common values of the variable}?
\item
  \emph{How much do observations differ from one another}?
\item
  \emph{Is one variable associated with another}?
\end{itemize}

Rather than describe the answers to such questions in purely verbal terms, as we did above, EDA relies on descriptive statistics and graphical summaries:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Descriptive statistics}. Descriptive statistics are used to quantify the basic features of a sample distribution. They provide numerical summaries about the sample that can be used to make comparisons and draw preliminary conclusions. For example, we often use the mean to summarise the `most likely' values of a variable.
\item
  \textbf{Graphical summaries}. Descriptive statistics are not much use on their own---a few numbers can't capture every aspect of a distribution. Graphical summaries are a powerful complement to descriptive statistics because they capture a lot of information about a sample in a way that is easy for people to understand.
\end{enumerate}

Descriptive statistics are important, but they are not the main focus of this book. The next few chapters will set out how to construct a range of useful graphical data summaries. Indeed, this book's overarching goal is to demonstrate a workflow that starts with raw data and ends in one or more exploratory plots. We do need to know a bit about descriptive statistics to understand some of those plots. To that end, we'll finish this chapter with a quick survey of descriptive statistics that will pop up later.

\hypertarget{a-primer-of-descriptive-statistics}{%
\section{A primer of descriptive statistics}\label{a-primer-of-descriptive-statistics}}

\hypertarget{numeric-variables}{%
\subsection{Numeric variables}\label{numeric-variables}}

So far, we've only mentioned the properties of sample distributions in very general terms---using phrases like `most common values' and `the range of the data'---without really saying what we mean. Statisticians have devised a set of terms to describe distributions and various descriptive statistics to quantify these. The two that matter most for numeric variables are the \textbf{central tendency} and the \textbf{dispersion}:

\begin{itemize}
\item
  A measure of \textbf{central tendency} describes a typical value of a distribution. Most people know at least one measure of central tendency. The ``average'' that they calculated at school is the arithmetic mean of a sample. There are many different measures of central tendency, each with its own pros and cons. Take a look at the \href{http://en.wikipedia.org/wiki/Central_tendency}{Wikipedia} page to see the most common ones. Among these, the median is the one that is used most often in exploratory analyses.
\item
  A measure of \textbf{dispersion} describes how spread out a distribution is. Dispersion measures quantify the variability or scatter of a variable. If one distribution is more dispersed than another, it means that it encompasses a wider range of values. What this means in practice depends on the kind of measure we're working with. We tend to focus on the variance, the standard deviation, and the interquartile range. There \href{http://en.wikipedia.org/wiki/Statistical_dispersion}{are many others}, though.
\end{itemize}

\begin{infobox}{information}

\hypertarget{beyond-central-tendency-and-dispersion}{%
\subsubsection*{Beyond central tendency and dispersion}\label{beyond-central-tendency-and-dispersion}}
\addcontentsline{toc}{subsubsection}{Beyond central tendency and dispersion}

Another important aspect of a distribution is its \textbf{skewness} (a.k.a. `skew'). There are many different ways to quantify skewness. Unfortunately, these are quite difficult to make sense of. For now, we only need to understand what skewness means in qualitative terms. Skewness refers to the (a)symmetry of a distribution. When we talk about distributions with high skew, we mean they are very asymmetric.

\end{infobox}

\hypertarget{central-tendency}{%
\subsubsection{Central tendency}\label{central-tendency}}

The central tendency of a numeric variable's sample distribution is typically described using either the arithmetic mean or the median\textbf{.} The \textbf{arithmetic mean} of a sample is `the mean' that everyone learns at school\footnote{People often just say `the mean' when referring to the arithmetic sample mean. This is fine, but keep in mind that there are other kinds of mean , such as the harmonic mean and the geometric mean.}. Most people have calculated the mean by hand at some point. As R users, we can use the \texttt{mean} function to calculate the arithmetic mean if we need it. For example, this will calculate the mean body mass in the \texttt{penguins} data set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4201.754
\end{verbatim}

Remember---we used \texttt{na.rm\ =\ TRUE} here because \texttt{body\_mass\_g} contains a small number of missing (\texttt{NA}) values. This calculation tells us the arithmetic mean of body mass is 4202 grams, i.e.~in some sense, the most common body mass is about 4202 grams.

One limitation of the arithmetic mean is that it is affected by the shape of a distribution. This is why, for example, it does not make much sense to look at the mean income of workers to get a sense of what a `typical' person earns. Income distribution are highly skewed, such that a few people receive very large salaries compared to the vast majority of the population. Those few who earn very good salaries tend to shift the mean well past anything that is really `typical'.

Because the sample mean is sensitive to the shape of a distribution in this way, we often prefer to use a more robust measure of central tendency---the \textbf{sample median}. The median of a sample is the value that separates the upper half from the lower half. We can find the sample median with the \texttt{median} function in R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{median}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4050
\end{verbatim}

This tells us that the arithmetic mean of body mass in the \texttt{penguins} data is 4050 grams. This is less than the mean, reflecting the fact that the body mass distribution is somewhat asymmetric.

\begin{infobox}{information}

\hypertarget{what-about-the-mode}{%
\subsubsection*{What about `the mode'?}\label{what-about-the-mode}}
\addcontentsline{toc}{subsubsection}{What about `the mode'?}

The \textbf{mode} of a variable's distribution is simply the value that is most likely to occur. This is a simple idea. Unfortunately, it is often difficult to estimate the mode from a sample. Nonetheless, it is important to know what the mode represents, because the concept is useful even when the actual value is hard to estimate.

\end{infobox}

\hypertarget{dispersion}{%
\subsubsection{Dispersion}\label{dispersion}}

There are many ways to quantify the dispersion of a sample distribution. The most important quantities from the standpoint of statistics are the sample \textbf{variance} and \textbf{standard deviation}. The sample variance (\(s^2\)) is the average squared deviations of each point from the mean. Variances are non-negative. The larger the variance, the more observations are spread out around the mean. A variance of zero only occurs if all values are identical.

We won't waste time showing the formula because we'll never actually need to use it directly. As usual, R can calculate the sample variance if we need it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{var}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 643131.1
\end{verbatim}

That's a big number. What does it mean? Is it `big' or is it `small'? No idea. That's the problem with variances---they are difficult to interpret because their calculation involves squared deviations. The variance is an important quantity in statistics because many common tools use changes in the variance as a basis for statistical tests. However, variances seldom feature in EDA because they are so hard to interpret.

A somewhat better descriptive statistic is to describe sample dispersion is a closely related quantity called the \textbf{standard deviation} of the sample, usually denoted \(s\). The standard deviation is equal to the square root of the variance. We calculate it using the \texttt{sd} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 801.9545
\end{verbatim}

Why do we prefer the standard deviation over the variance? Because it is the square root of the variance, it operates on the same scale as the variable it summarises. This means it reflects the dispersion we perceive in the data. The sample standard deviation is not without problems, though. Like the sample mean, it is sensitive to the shape of a distribution and the presence of outliers.

A measure of dispersion that is robust to these kinds of problems is the \textbf{interquartile range}. The interquartile range (IQR) is defined as the difference between the third and first quartile (see box). The IQR contains the middle 50\% of the values of a variable. The more spread out the data, the larger the IQR. People prefer IQR to measure dispersion for exploratory work because it only depends on the `middle' of a distribution. This makes it robust to the presence of outliers.

We can use the \texttt{IQR} function to find the interquartile range of the body mass variable:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{IQR}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1200
\end{verbatim}

The IQR is used as the basis for a useful data summary plot called a `box and whiskers' plot. We'll see how to construct this later.

\begin{infobox}{information}

\hypertarget{what-are-quartiles}{%
\subsubsection*{What are quartiles?}\label{what-are-quartiles}}
\addcontentsline{toc}{subsubsection}{What are quartiles?}

We need to know what a quartile is to understand the interquartile range. Three quartiles are defined for any sample. These divide the data into four equal-sized groups, from the set of smallest numbers up to the set of largest numbers. The second quartile (\(Q_2\)) is the median, i.e.~it divides the data into an upper and lower half. The first quartile (\(Q_1\)) is the number that divides the lower 50\% of values into two equal-sized groups. The third quartile (\(Q_3\)) is the number that divides the upper 50\% of values into two equal-sized groups.

\end{infobox}

\hypertarget{categorical-variables}{%
\subsection{Categorical variables}\label{categorical-variables}}

Descriptive statistics of categorical variables aim to quantify specific features of their sample distribution, just as with numeric variables. The general question we need to address is, what are the relative frequencies of different categories? Because categorical variables take a finite number of values, the simplest thing we can do is tabulate the number of occurrences of each type. We can use the \textbf{dplyr} \texttt{count} function to do this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{count}\NormalTok{(species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species       n
##   <chr>     <int>
## 1 Adelie      152
## 2 Chinstrap    68
## 3 Gentoo      124
\end{verbatim}

This prints that the number of observations associated with each species in \texttt{penguins}. The summary reveals that the most common species in the data set is the Adelie penguin, followed by the Gentoo and Chinstrap.

Can we quantify the central tendency of a categorical sample distribution? Various measures exist. We can certainly find the \textbf{sample mode} of a categorical variable easily enough. This is just the most common category. In the case of the above \texttt{species} variable, the mode is obviously Adelie. It is also possible to calculate a \textbf{sample median} of a categorical variable, but only when it is ordinal. Since the median value is the one that lies in the middle of an ordered set of values, it makes no sense to talk about the middle of a set of nominal values that have no inherent order.

What about dispersion? Well, measures of dispersion for categorical variables do exist, but they are not very easy to interpret. They seldom get used in exploratory data analysis so let's not worry about them here.

\hypertarget{associations-1}{%
\subsection{Associations}\label{associations-1}}

Statisticians have devised different ways to quantify an association between variables. The common measures calculate some kind of \textbf{correlation coefficient}. The terms `association' and `correlation' are closely related, so they are often used interchangeably. Strictly speaking, correlation has a narrower definition: a correlation is defined by a metric (the `correlation coefficient') that quantifies the degree to which an association tends to a certain pattern.

\hypertarget{pairs-of-numeric-variables}{%
\subsubsection{Pairs of numeric variables}\label{pairs-of-numeric-variables}}

A widely used measure of correlation for pairs of numeric variables is \textbf{Pearson's correlation coefficient} (a.k.a. Pearson product-moment correlation coefficient, or Pearson's \(r\)). Remember, a correlation coefficient quantifies the degree to which an association tends to a certain pattern. Pearson's correlation coefficient is designed to summarise the strength of a \textbf{linear} (i.e.~straight line) association.

Pearson's correlation coefficient takes a value of 0 if two variables are not linearly associated and a value of +1 or -1 if they are perfectly related and represent a straight line. A positive value indicates that high values in one variable are associated with high values of the second; a negative value indicates that high values of one variable is associated with low values of the second. High values are those that are greater than the mean; low values are those that are less than the mean.

We can use the \texttt{cor} function to calculate Pearson's correlation coefficient. For example, the Pearson correlation coefficient between flipper length and body mass is given by:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{flipper\_length\_mm, penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\AttributeTok{use =} \StringTok{"complete.obs"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8712018
\end{verbatim}

This is positive, indicating flipper length tends to increase with body mass. It is also quite close to +1, indicating the association is strong. We should interpret Pearson's correlation coefficient with care. Because it is designed to summarise the strength of a \textbf{linear} relationship, Pearson's correlation coefficient will mislead when this relationship is curved. If that statement does not make immediate sense, take a look at the famous \href{https://en.wikipedia.org/wiki/Anscombe\%27s_quartet}{Anscombe's quartet}.

\begin{infobox}{warning}

\hypertarget{other-measures-of-correlation}{%
\subsubsection*{Other measures of correlation}\label{other-measures-of-correlation}}
\addcontentsline{toc}{subsubsection}{Other measures of correlation}

What should we do if we think the relationship between two variables is non-linear? Calculate something called a \textbf{rank correlation}. The idea is quite simple. Instead of working with the actual values of each variable, we rank them by value, i.e.~sort each variable from lowest to highest and the assign the labels 1\textsuperscript{st} , 2\textsuperscript{nd}, 3\textsuperscript{rd}, \ldots{} to observations. Rank correlations are based on the association among the ranks of two variables.

The two most popular rank correlation coefficients are Spearman's \(\rho\) (`rho') and Kendall's \(\tau\) (`tau'). The differences are minimal:

\begin{itemize}
\tightlist
\item
  Spearman's \(\rho\) is a bit more sensitive to outliers in the data.
\item
  Kendall's \(\tau\) can be slow to calculate for large data sets.
\end{itemize}

We can either coefficient using the \texttt{cor} function, setting the \texttt{method} argument to the appropriate value: \texttt{method\ =\ "kendall"} or \texttt{method\ =\ "spearman"}. A rank correlation coefficient is interpreted in the same way as Pearson's correlation coefficient. It takes a value of 0 if the ranks are uncorrelated and +/- 1 if they are perfectly associated (though not necessarily as a straight line). The sign tells us about the direction of the association.

\end{infobox}

\hypertarget{pairs-of-categorical-variables}{%
\subsubsection{Pairs of categorical variables}\label{pairs-of-categorical-variables}}

Quantifying associations between pairs of categorical variables is not as simple as the numeric case. The general question is, ``do different \textbf{combinations} of categories seem to be under- or over-represented?'' We need to understand which combinations are common and which are rare. The simplest thing we can do is `cross-tabulate' the number of occurrences (i.e.~the `frequencies') of each combination. The resulting table is called a \textbf{contingency table}.

The \texttt{xtabs} function (= `cross-tabulation') can do this. For example, the frequencies of each penguin species and island combination is given by:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{xtabs}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ species }\SpecialCharTok{+}\NormalTok{ island, }\AttributeTok{data =}\NormalTok{ penguins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            island
## species     Biscoe Dream Torgersen
##   Adelie        44    56        52
##   Chinstrap      0    68         0
##   Gentoo       124     0         0
\end{verbatim}

The first argument sets the variables to cross-tabulate. \texttt{xtabs} uses R's special formula language, which means we must include that \texttt{\textasciitilde{}} symbol at the beginning. After the \texttt{\textasciitilde{}}, we provide the list of variables to cross-tabulate, separated by the \texttt{+} sign. The second argument tells the function which data set to use.

The table above shows us how many observations are associated with each combination of the \texttt{species} and \texttt{island} categories. This particular case represents a fairly extreme example of (dis)association; the Chinstrap and Gentoo species simply don't occur on certain islands (or perhaps they weren't sampled on those islands for some reason).

What about measures of association such as correlation coefficients? Spearman's \(\rho\) and Kendall's \(\tau\) are designed for numeric variables, but these can also be used to measure the correlation between ordinal variables (Kendall's \(\tau\) is best). Various measures of association have been constructed for pairs of nominal variables (e.g.~\href{https://en.wikipedia.org/wiki/Cram\%C3\%A9r\%27s_V}{Cramér's V}). However, none of these are widely used in exploratory data analyses---people tend to stick with graphical tools for categorical data.

\hypertarget{chapter-ggplot2-intro}{%
\chapter{\texorpdfstring{Introduction to \textbf{ggplot2}}{Introduction to ggplot2}}\label{chapter-ggplot2-intro}}

One of the main reasons data analysts turn to R is for its strong data visualisation capabilities. The R ecosystem includes many different packages that support data visualisation. The three most widely used are: 1) the base graphics system, which uses the \textbf{graphics} package; 2) the \textbf{lattice} package; and 3) the \textbf{ggplot2} package. Each system has its own strengths and weaknesses:

\begin{itemize}
\item
  Base graphics is part of base R, which means it's always available. It's very flexible and allows us to construct more or less any plot we like. This flexibility comes at a cost, though. While it is certainly easy to get up and running with base graphics---there are specialised functions making common plots---building complex figures quickly becomes time-consuming. We have to write a lot of code to prepare even moderately complex plots, there are many graphical parameters to learn, and many of the standard plotting functions are inconsistent in how they work.
\item
  Deepayan Sarkar developed the \textbf{lattice} package to implement the ideas of Bill Cleveland in his 1993 book, Visualizing Data. The package implements something called Trellis graphics, a very useful approach for graphical exploratory data analysis. Trellis graphics are designed to help us visualise complicated, multiple variable relationships. The \textbf{lattice} package has many ``high level'' functions to make this process easy. The \textbf{lattice} package is very powerful, but it is hard to master.
\item
  Hadley Wickham developed the \textbf{ggplot2} package to implement the ideas in a book called The Grammar of Graphics by Wilkinson (2005). It produces Trellis-like graphics but is quite different from \textbf{lattice} in the way it goes about this. It uses its own mini-language to define graphical objects, adopting the language of Wilkinson's book to define these. It takes a little while to learn the basics, but once these have been mastered, it's very easy to produce sophisticated plots with very little R code. The downside of working with \textbf{ggplot2} is that it isn't as flexible as base graphics.
\end{itemize}

We are not going to survey all these plotting systems. It's entirely possible to meet most data visualisation needs by becoming proficient with just one of them. This book focuses on the \textbf{ggplot2} package. In many ways, \textbf{ggplot2} hits the `sweet spot' between base graphics and \textbf{lattice}. It enables complex visualisations without the need to write many lines of R code, but remains flexible enough to allow the kind of customisation required to produce publication-quality figures.

\hypertarget{anatomy}{%
\section{The anatomy of ggplot2}\label{anatomy}}

The easiest way to learn \textbf{ggplot2} is by using it. However, before we dive into \textbf{ggplot2} code, we need to review the essential features of its `grammar'---the rules of how to specify a graph. This grammar is fairly abstract and won't make much sense on first reading. That is fine. Ideas like `aesthetic mappings' and `geoms' will start to make sense as we work through various examples.

The design of \textbf{ggplot2} reflects Wilkinson's grammar of graphics. A complete \textbf{ggplot2} object is defined by a combination of:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  one or more \textbf{layers},
\item
  a set of \textbf{scales} (one for each `aesthetic mapping'),
\item
  a \textbf{coordinate system} (one per plot),
\item
  a \textbf{facet} specification (if using a multi-panel plot).
\end{enumerate}

The underlying idea is that we construct a visualisation by defining one or more layers. Each layer is associated with some data and a set of rules for how to display the data. Let's review these components before moving onto the business of actually using \textbf{ggplot2}.

\hypertarget{layers}{%
\subsection{Layers}\label{layers}}

Each layer in a \textbf{ggplot2} plot has five different components, though we don't necessarily have to specify all of these because most have some kind of default setting:

\begin{itemize}
\item
  The \textbf{data}. At a minimum, every plot needs some data. Unlike base R graphics, \textbf{ggplot2} always accepts data in one format, an R data frame (or tibble). Each layer can be associated with its own data set. We don't have to add data to each layer explicitly. If we choose not to specify the data set for a layer, \textbf{ggplot2} will use the default data (if defined).
\item
  A set of \textbf{aesthetic mappings}. These describe how variables in the data are associated with the aesthetic properties of the layer. Aesthetic properties include things we perceive, such as position, colour, and size of the points. Each layer can be associated with its own unique aesthetic mappings. When we choose not to specify these for a layer \textbf{ggplot2} will use the defaults (if defined).
\item
  A \textbf{geometric object} (a.k.a. `geom'). The geom part of layer tells \textbf{ggplot2} how to represent the information---i.e.~it refers to the objects we see on a plot, such as points, lines, bars or even text. Each geom only works with a particular subset of aesthetic mappings. We always have to define a geom when specifying a layer.
\item
  A \textbf{statistical transformation} (a.k.a. `stat'). A stat takes the raw data and transforms it in some way. A stat allows us to plot useful summaries of our raw data. We won't explicitly use them in this book because we prefer to produce summary figures by first processing the data with \textbf{dplyr}. Nonetheless, the stat facility is often doing useful work in the background for some kinds of plots.
\item
  A \textbf{position adjustment}. These apply small tweaks to the position of layer elements. These are typically used when we need to define how the information for different categories are separated. For example, when making a bar plot, we may need to specify whether bars should be stacked on top of one another (the default) or plotted side-by-side.
\end{itemize}

\hypertarget{scales}{%
\subsection{Scales}\label{scales}}

The scale part of a \textbf{ggplot2} object controls how the information in a variable is mapped to the aesthetic properties. A scale takes the data and converts it into variation we can perceive, such as an x/y location or the colour and size of points in a plot. The two most important things to understand about scales are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  A scale must be defined for every aesthetic in a plot. It doesn't make sense to define an aesthetic mapping without a scale because there is no way for \textbf{ggplot2} to know how to go from the data to the aesthetics without one.
\item
  When we include two or more layers, they all have to use the same scale for any shared aesthetic mappings. This behaviour is necessary to ensure information is displayed consistently.
\end{enumerate}

If we choose not to explicitly define a scale for an aesthetic \textbf{ggplot2} will use a default. This will often be a `sensible' choice, which means we can get quite a long way with \textbf{ggplot2} without ever really understanding scales. We will take a brief look at a few of the more common options, though.

\hypertarget{coordinate-system}{%
\subsection{Coordinate system}\label{coordinate-system}}

A \textbf{ggplot2} coordinate system takes the position of objects (e.g.~points and lines) and maps them onto the 2d plane a plot lives on. Most people are already very familiar with the most common coordinate system (even if they didn't realise it). That's the Cartesian coordinate system. This is the one we've all been using since we first constructed a graph with paper and pencil at school. All the most common statistical plots use this coordinate system, so we won't consider any others in this book.

\hypertarget{faceting}{%
\subsection{Faceting}\label{faceting}}

The idea behind faceting is very simple. Faceting allows us to break a data set up into subsets according to the unique values of one or more variables and then produce a separate plot for each subset. The result is a multi-panel plot where each panel shares the same layers, scales, etc. The data is the only thing that varies from panel to panel. The result is a kind of `Trellis plot', similar to those produced by the \textbf{lattice} package. Faceting is a very powerful tool that allows us to slice up our data in different ways and understand the relationship between different variables.

\hypertarget{quick}{%
\section{A quick introduction to ggplot2}\label{quick}}

Now that we've briefly reviewed the \textbf{ggplot2} grammar, we can start learning how to use it. The package uses this grammar as the basis of a sort of mini-language within R. It uses functions to specify components like aesthetic mappings and geoms, which are combined with data to define a \textbf{ggplot2} graphics object. Once we've constructed a suitable object, we can use it to display our graphic on the computer screen or save it using a common graphics format (e.g.~PDF, PNG or JPEG).

Rather than orientating this introduction around each of the key functions, we're going to develop a simple example to help us see how \textbf{ggplot2} works. Many of the key ideas about how \textbf{ggplot2} works can be taken away from this one example. Hence, it's worth investing the time to understand it---i.e.~use the example to understand how the different \textbf{ggplot2} functions are related to the grammar outlined above.

Our goal is to produce a simple scatter plot. The scatter plot is one of the most commonly used visualisation tools in the EDA toolbox. A scatter plot uses horizontal and vertical positions (the `x' and `y' axes) to visualise pairs of related observations as a series of points in two dimensions. It's designed to show how one numeric variable is associated with another. We'll use the \texttt{penguins} data to construct the scatter plot. The questions we want to explore are:

\begin{itemize}
\tightlist
\item
  what is the relationship between bill depth and bill length, and
\item
  how does this vary in relation to other variables?
\end{itemize}

\hypertarget{making-a-start}{%
\subsection{Making a start}\label{making-a-start}}

We will begin our work with \textbf{ggplot2} by setting up a minimal \textbf{graphical object}. That's a job for the \texttt{ggplot} function. Using \texttt{ggplot} without any arguments builds an empty graphical object:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# construct empty ggplot2 graphical object}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This constructs the skeleton object and assigns it a name, \texttt{plot\_obj}. We can use the \texttt{summary} function to inspect the object to find out a bit more about it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print summary of empty graphical object}
\FunctionTok{summary}\NormalTok{(plot\_obj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## data: [x]
## faceting: <ggproto object: Class FacetNull, Facet, gg>
##     compute_layout: function
##     draw_back: function
##     draw_front: function
##     draw_labels: function
##     draw_panels: function
##     finish_data: function
##     init_scales: function
##     map_data: function
##     params: list
##     setup_data: function
##     setup_params: function
##     shrink: TRUE
##     train_scales: function
##     vars: function
##     super:  <ggproto object: Class FacetNull, Facet, gg>
\end{verbatim}

The output of \texttt{summary} is quite verbose, but the important parts are near the top, just before the \texttt{faceting:} section. In this case, the `important part' is basically empty. All we did was set up an empty graphical object---there are no data, aesthetic mapping, layers, etc associated with \texttt{plot\_obj}.

It is not necessary to inspect the insides of every \textbf{ggplot2} object with \texttt{summary}. However, it can be instructive to do this when first learning about the package.

\begin{infobox}{information}

\hypertarget{ggplot2-vs.-ggplot}{%
\subsubsection*{\texorpdfstring{\textbf{ggplot2} vs.~\texttt{ggplot}}{ggplot2 vs.~ggplot}}\label{ggplot2-vs.-ggplot}}
\addcontentsline{toc}{subsubsection}{\textbf{ggplot2} vs.~\texttt{ggplot}}

Notice that the package is called \textbf{ggplot2}, but the actual function that does the work of setting up the graphical object is called \texttt{ggplot}. Try not to mix the names up---this is a common source of errors.

\end{infobox}

How can we improve on this? We could add a default data set. This is easy. We do it by passing the name of a data frame or tibble to \texttt{ggplot}. Let's try doing this with \texttt{penguins}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# construct ggplot2 graphical object with data}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(penguins)}
\end{Highlighting}
\end{Shaded}

Then print out the summary of the updated \texttt{plot\_obj}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print summary of updated graphical object}
\FunctionTok{summary}\NormalTok{(plot\_obj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## data: species, island, bill_length_mm, bill_depth_mm,
##   flipper_length_mm, body_mass_g, sex, year [344x8]
## faceting: <ggproto object: Class FacetNull, Facet, gg>
##   ...facet summary suppressed...
\end{verbatim}

We suppressed the facet information this time because it takes up a lot of space and we're not interested in it. The important point is that the \texttt{plot\_obj} summary now contains some information related to the data. The variables from \texttt{penguins} now comprise the data associated with the \texttt{plot\_obj} object.

The next step is to add a default aesthetic mapping to the graphical object. Remember, this describes how variables in the data are mapped to the aesthetic properties of the layer(s).

One way to think about aesthetic mappings is they define what kind of relationships the plot will describe. Since we're making a scatter plot, we need to define mappings for positions on the `x' and `y' axes. We want to investigate how bill depth depends on bill length, so we need to associate\texttt{bill\_length\_mm} with the x position and \texttt{bill\_depth\_mm} with the y position.

We define an aesthetic mapping with the \texttt{aes} function. One way to use \texttt{aes} is like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# add aesthetic mappings to graphical object}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}}\NormalTok{ plot\_obj }\SpecialCharTok{+} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)}
\end{Highlighting}
\end{Shaded}

This little snippet of R code looks odd at first glance. There are a couple of things to take away from this:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We can `add' the aesthetic mapping to the \texttt{plot\_obj} object using the \texttt{+} operator. This has nothing to do with arithmetic. The \textbf{ggplot2} package uses some clever programming tricks to redefine the way \texttt{+} works so that it can be used to combine graphical objects. It takes a bit of getting used to but this is useful because it makes building a plot from the components of the grammar very natural.
\item
  The second thing to notice is that an aesthetic mapping is defined by one or more name-value pairs, specified as arguments of \texttt{aes}. The names on the left-hand side of each \texttt{=} refer to the properties of our graphical object (e.g.~the `x' and `y' positions). The values on right-hand side refer to variable names in the data we want to associate with these properties.
\end{enumerate}

Notice that we overwrote the original \texttt{plot\_obj} object with the updated version using the assignment operator. We could have created a distinct object, but there's usually no need to do this.

Once again, we can inspect the result using \texttt{summary}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print summary of updated graphical object}
\FunctionTok{summary}\NormalTok{(plot\_obj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## data: species, island, bill_length_mm, bill_depth_mm,
##   flipper_length_mm, body_mass_g, sex, year [344x8]
## mapping:  x = ~bill_length_mm, y = ~bill_depth_mm
## faceting: <ggproto object: Class FacetNull, Facet, gg>
##   ...facet summary suppressed...
\end{verbatim}

The data (\texttt{data:}) from the original \texttt{plot\_obj} are still there, but now we can also see that two default mappings (\texttt{mapping:}) have been defined for the x- and y-axis positions. We have successfully used the \texttt{ggplot} and \texttt{aes} functions to set up a graphical object with both default data and aesthetic mappings.

\textbf{Any layers that we now add will use these data and mappings unless we choose to override them by specifying different options.}

We now need to specify a layer to tell \textbf{ggplot2} how to visualise the data. Remember, each layer has five components: data, aesthetic mappings, a geom, a stat and a position adjustment. Since we have already set up the default data and aesthetic mappings, there's no need to define these again---\textbf{ggplot2} will use the defaults if we leave them out of the layer definition. This leaves the geom, stat and position adjustment.

What kind of geom do we need? A scatter plot allows us to explore a relationship as a series of points. That means we need to add a layer that uses the `point' geom. Simple.

What about the stat and position? Not so simple. These are difficult to explain without drilling down into how \textbf{ggplot2} works. A key insight is that both the stat and the position adjustment change the data somehow before plotting it. When we want to stop \textbf{ggplot2} from doing anything to our data, the keyword is `identity'. We use this value whenever we want \textbf{ggplot2} to plot the data without modification.

We will examine the easy way to add a layer in a moment. However, we'll use the long-winded approach first because this reveals what happens whenever we build a \textbf{ggplot2} object. The general function for adding a layer is simply called \texttt{layer}. Here's how it works in its most basic usage:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# add layer to graphical object {-}{-} using points geom}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}}\NormalTok{ plot\_obj }\SpecialCharTok{+} \FunctionTok{layer}\NormalTok{(}\AttributeTok{geom =} \StringTok{"point"}\NormalTok{, }\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This adds a layer to the existing \texttt{plot\_obj} object with the \texttt{layer} function and overwrites the old version. Again, we add the new component using the \texttt{+} symbol. We set three arguments of the \texttt{layer} function:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  define the \textbf{geom}: the name of this argument was \texttt{geom} and the value assigned to it was \texttt{"point"}.
\item
  define the \textbf{stat}: the name of this argument was \texttt{stat} and the value assigned to it was \texttt{"identity"}.
\item
  define the \textbf{position adjustment} : the name of this argument was \texttt{position} and the value assigned to it was \texttt{"identity"}.
\end{enumerate}

Let's review the structure of the resulting graphical object one last time to see what we've achieved:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print summary of updated graphical object}
\FunctionTok{summary}\NormalTok{(plot\_obj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## data: species, island, bill_length_mm, bill_depth_mm,
##   flipper_length_mm, body_mass_g, sex, year [344x8]
## mapping:  x = ~bill_length_mm, y = ~bill_depth_mm
## faceting: <ggproto object: Class FacetNull, Facet, gg>
##   ...facet summary suppressed...
## -----------------------------------
## geom_point: na.rm = FALSE
## stat_identity: na.rm = FALSE
## position_identity
\end{verbatim}

The text above the \texttt{-\/-\/-\/-\/-} line is the same as before. It summarises the default data and the aesthetic mapping. The text below it summarises the layer we just added. This tells us that layer uses the points geom (\texttt{geom\_point}), the identity stat (\texttt{stat\_identity}), and the identity position adjustment (\texttt{position\_identity}).

Now \texttt{plot\_obj} has everything it needs to render a figure. How do we do this? Simply `print' the graphical object:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# \textquotesingle{}print\textquotesingle{} graphical object to show it}
\FunctionTok{print}\NormalTok{(plot\_obj)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 2 rows containing missing values (geom_point).
\end{verbatim}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-184-1} \end{center}

That's it! We have produced a scatter plot showing how bill depth is associated with bill length. It seems a little odd to show a plot by `printing' it but that's just how \textbf{ggplot2} works. It soon starts to feel natural with practise.

Notice that \textbf{ggplot2} printed a warning. That is nothing to worry about. It is just letting us know a couple of rows in the data were ignored because they contained missing values. We will suppress that message from now on because it gets a bit irritating.

Here's a quick summary of what we did, all in one place:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# step 1. set up the skeleton graphical object with a default data set}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(penguins)}
\CommentTok{\# step 2. add the default aesthetic mappings}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}}\NormalTok{ plot\_obj }\SpecialCharTok{+} \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)}
\CommentTok{\# step 3. specify the layer we want to use}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}}\NormalTok{ plot\_obj }\SpecialCharTok{+} \FunctionTok{layer}\NormalTok{(}\AttributeTok{geom =} \StringTok{"point"}\NormalTok{, }\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{position =} \StringTok{"identity"}\NormalTok{)}
\CommentTok{\# step 4. show the plot}
\FunctionTok{print}\NormalTok{(plot\_obj)}
\end{Highlighting}
\end{Shaded}

\begin{infobox}{warning}

\hypertarget{dont-use-this-workflow}{%
\subsubsection*{Don't use this workflow!}\label{dont-use-this-workflow}}
\addcontentsline{toc}{subsubsection}{Don't use this workflow!}

It's possible to construct any \textbf{ggplot2} visualisation using the workflow outlined in this subsection, but \textbf{this is not the recommended approach}. The workflow we adopted here was used to reveal how the grammar works, rather than its efficiency. A more concise, standard approach to using \textbf{ggplot2} is outlined next. Use that for real-world analysis.

\end{infobox}

\hypertarget{a-standard-way-of-using-ggplot2}{%
\section{\texorpdfstring{A standard way of using \textbf{ggplot2}}{A standard way of using ggplot2}}\label{a-standard-way-of-using-ggplot2}}

The \textbf{ggplot2} package is quite flexible, which means we can specify a visualisation in more than one way. To keep life simple, we're going to adopt a consistent workflow from now on. This won't reveal the full array of \textbf{ggplot2} tricks, but it is sufficient to construct a wide range of standard visualisations. Let's make the same bill depth vs.~bill length scatter plot again to see the workflow in action.

We began building our \textbf{ggplot2} object by setting up a skeleton object with a default data set and then added the default aesthetic mappings. There is a more concise way to achieve the same result:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create graphical object with data and aesthetic mappings}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm))}
\end{Highlighting}
\end{Shaded}

In this form, the \texttt{aes} function appears inside \texttt{ggplot} as a second argument. This sets up a graphical object with default data and aesthetic mappings in a single step. We will always use this approach from now on.

The next step adds a layer. We saw that the \texttt{layer} function could be used to construct one from its component parts. However, \textbf{ggplot2} provides many convenience functions that construct layers according to the type of geom they need. They all look like this: \texttt{geom\_TYPE}, where \texttt{TYPE} stands for the name of the geom we want to use. For example, a point geom is specified using \texttt{geom\_point}. Using this function, an alternative to the last line of the example is therefore:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use geom\_point to add a points layer to graphical object}
\NormalTok{plot\_obj }\OtherTok{\textless{}{-}}\NormalTok{ plot\_obj }\SpecialCharTok{+} \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

We didn't have to specify the stat or the position adjustment components of the layer because the \texttt{geom\_TYPE} functions all use reasonable defaults. These can be overridden if needed, but most of the time, there's no need to do this. This way of defining a layer is much simpler and less error-prone than the manual \texttt{layer} method. We will always use the \texttt{geom\_TYPE} method from now on.

There's one last trick we need to learn to use \textbf{ggplot2} efficiently. We've been building a plot object in several steps, giving the intermediates the name \texttt{plot\_obj}, and then manually printing the object to display it when it's ready. This is useful if we want to make different versions of the same plot. However, we very often just want to build the plot and display it in one go. This is done by combining everything with \texttt{+} and printing the resulting object directly:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot **in one step**}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

That code builds the \textbf{ggplot2} graphical object and renders it in one go. We didn't even have to use \texttt{print} to generate the output. There is a lot is going on in the background, but this small snippet of R code contains everything \textbf{ggplot2} needs to construct and display a simple scatter plot.

What does this scatter plot actually tell us about penguin bill morphology? It seems to suggest there isn't much of a relationship between bill depth and bill length. Does that seem sensible? Maybe we need a more informative plot.

\begin{infobox}{information}

\hypertarget{plotting-incomplete-ggplot2-objects}{%
\subsubsection*{\texorpdfstring{Plotting incomplete \textbf{ggplot2} objects}{Plotting incomplete ggplot2 objects}}\label{plotting-incomplete-ggplot2-objects}}
\addcontentsline{toc}{subsubsection}{Plotting incomplete \textbf{ggplot2} objects}

It is instructive to see what happens when we render an incomplete graphical object. The four panels below show the output produced by a) an empty \textbf{ggplot2} object, b) a partially complete \textbf{ggplot2} object with only data, c) a partially complete \textbf{ggplot2} object with data and aesthetics, and d) a complete \textbf{ggplot2} object with data, aesthetics and a geom. The actual code to make each one is shown in the title area.

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-190-1} \end{center}

We can see that \textbf{ggplot2} will try to plot something with the information it has, but we only end up with an informative plot when we specify data, aesthetic mappings, and a geom. That is the minimum we need to specify to arrive at a useful plot.

\end{infobox}

\hypertarget{how-should-we-format-ggplot2-code}{%
\subsection{\texorpdfstring{How should we format \textbf{ggplot2} code?}{How should we format ggplot2 code?}}\label{how-should-we-format-ggplot2-code}}

Take another look at that last example. We split the \textbf{ggplot2} definition over two lines, placing each function on its own line. R doesn't care about those extra newlines. As long as we put a \texttt{+} at the end of a line R will assume the next line is part of the same plot definition. Splitting the different parts of a graphical object definition across lines like this makes everything more readable and helps us spot errors.

Once we split the definition across lines we can place comments between the lines of \textbf{ggplot2} code. For example, we could add comments to state what the \texttt{aes} and \texttt{geom\_point} parts are doing:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

It's a very good idea to format and document \textbf{ggplot2} code in this way. That way, when we come back to it after a while, we can remember what we were trying to achieve! We will always use these conventions from now on.

\hypertarget{increasing-the-information-density}{%
\section{Increasing the information density\ldots{}}\label{increasing-the-information-density}}

One of the great strengths of \textbf{ggplot2} is the ease with which it allows us to incorporate information from several variables into a single plot. So far, we have made a simple two-variable scatter plot to examine bill morphology---the bill depth-length relationship. There are clearly other variables in the \texttt{penguins} data set that might influence this relationship. In this section, we will highlight three approaches for including additional variables in a visualisation. That is, we will see how to increase the \textbf{information density} of a plot.

\hypertarget{via-aesthetic-mappings}{%
\subsection{\ldots via aesthetic mappings}\label{via-aesthetic-mappings}}

The most straightforward way to increase the information in a plot is by mapping a new variable to an unused aesthetic. For example, how might we learn whether the bill depth-length relationship varies by penguin species? We need to include information in the \texttt{species} variable in our scatter plot somehow. One option is to map the \texttt{species} to the colour aesthetic, so that the colour of the points correspond to different species. We do this by altering the \texttt{aes} part of the plot specification:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-192-1} \end{center}

Individual points are now coloured according to the species they belong to. Notice \textbf{ggplot2} also adds a legend. This plot shows that bill morphology is reasonably species-specific. Separating things by species suggests a (mild) positive association between bill length and bill depth \emph{within species}. This was not apparent before because it was hidden by the \emph{among species} pattern.

We put the \texttt{aes} argument on a new line in this example because the first line was getting a bit long. This is only a readability thing---the \texttt{aes} part still belongs to \texttt{ggplot}.

We could certainly improve this visualisation. Nonetheless, it illustrates an important concept: we can add information to a plot by mapping additional variables to new aesthetics. There is nothing to stop us from using different aesthetics if we wanted to squeeze even more information into this plot. For example, we could map the sex variable (\texttt{sex}) to the point shape using \texttt{shape\ =\ sex} inside \texttt{aes}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour) + sex (shape)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species, }\AttributeTok{shape =}\NormalTok{ sex)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-193-1} \end{center}

\hypertarget{via-facets}{%
\subsection{\ldots via facets}\label{via-facets}}

A second way to increase the amount of information on display is by making separate plots for meaningful subsets of the data. We can use the \textbf{faceting} facility of \textbf{ggplot2} to do this. Faceting allows us to define subsets of data according to the values of one or more variables and produce a separate plot for each subset, all without having to write much R code.

Faceting operates on the whole figure, which means we can't apply it by changing the properties of a layer. Instead, we have to use a new function to add the faceting information. There are two different ways to facet in \textbf{ggplot2}:

\begin{itemize}
\tightlist
\item
  \texttt{facet\_wrap} forms a matrix of panels by wrapping the 1d sequence of panels into a 2d matrix with rows and columns. It is typically used with a single categorical faceting variable (though it works with two or more faceting variables).
\item
  \texttt{facet\_grid} forms a 2d matrix of panels defined by row and column variables. It is typically used when we have two or more categorical variables, and all combinations of the variables exist in the data.
\end{itemize}

This is best understood by example. What if we want to see how the bill morphology varies across islands? Here's how we split things up by \texttt{island} using the \texttt{facet\_wrap} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display facetted bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# species info via colour aesthetic}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \CommentTok{\# island info via facets}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(island))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-194-1} \end{center}

That first \texttt{vars(island)} argument of \texttt{facet\_wrap} says to split up the data set according to the values of island. Simple. Notice that the panels share the same scales for the `x' and `y' axes. Using a common scale makes it easy to compare bill morphology across islands, but this can also be changed if necessary. For example, setting \texttt{scales\ =\ "free"} would ensure each panel uses its own x/y scale.

The plot indicates that bill morphology is roughly invariant across the three islands. It also inadvertently reveals something else about these penguins---the Gentoo and Chinstrap species are only found on a single island, which is different for each one, whereas Adelie penguins are found on all three islands. That's one reason exploratory analysis is so important---it throws up unexpected findings.

\begin{infobox}{warning}

\hypertarget{dont-forget-the-vars-part}{%
\subsubsection*{\texorpdfstring{Don't forget the \texttt{vars} part!}{Don't forget the vars part!}}\label{dont-forget-the-vars-part}}
\addcontentsline{toc}{subsubsection}{Don't forget the \texttt{vars} part!}

We have to wrap the name of the faceting variable with the \texttt{vars} function in the \texttt{facet\_wrap} specification. Trust us, \texttt{facet\_wrap} won't work without it.

\end{infobox}

\hypertarget{via-multiple-layers}{%
\subsection{\ldots via multiple layers}\label{via-multiple-layers}}

A third way to add additional information to a plot is by including multiple layers. So far, we have only seen examples with a single layer---only one \texttt{geom\_} function is involved in creating the plot. There is no reason we can't add multiple layers to a plot by `adding' two or more \texttt{geom\_} functions. We're not yet in a position to demonstrate how to make such multi-layer plots because they require additional skills covered in later chapters. However, as a taster, here is an example of the kind of thing we can do with this idea (we have deliberately hidden the code):

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-195-1} \end{center}

This shows how bill morphology varies by penguin species and sex, but now these relationships are summarised in two points layers. The first layer displays the raw data (small transparent points). The second layer adds the species/sex-specific means (large solid points). This places the average differences in the context of the overall variation in the raw data. Nice!

\hypertarget{chapter-customise-ggplot2}{%
\chapter{Customising plots}\label{chapter-customise-ggplot2}}

The default formatting used by \textbf{ggplot2} has been carefully chosen to ensure the information in a plot is easy to discern. For example, by default, plots include a pale grey background and include grid lines. This is designed to emphasise the data while supporting comparisons. The grey highlights colour differences and ensures the grid lines have little visual impact beyond aiding in the assessment of position. Perfect for exploratory analysis!

Although we can justify these sorts of choices on the grounds they improve the readability of a plot, the fact remains they are somewhat unconventional and not much-loved by many users. For this reason, we often need to change the appearance of a plot before we include it in a document or presentation---e.g.~most published figures use a white, rather than grey, background.

This chapter will demonstrate how to customise \textbf{ggplot2} plots. We are not going to cover every possible permutation. That would need its \href{https://ggplot2-book.org/}{own book}. Instead, we will explore the main routes to customisation so that we can use these as we review different visualisations later. Using the \texttt{penguins} data once again, we'll work on improving the following scatter plot from the \protect\hyperlink{chapter-ggplot2-intro}{Introduction to \textbf{ggplot2}} chapter:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-198-1} \end{center}

\hypertarget{geom-properties}{%
\section{Geom properties}\label{geom-properties}}

One common way to change a plot's appearance is by altering the properties of one or more geometric objects, such as points, lines, bars or polygons. How do we change the properties of the geom associated with a particular layer? We set those properties by specifying the appropriate arguments in the defining \texttt{geom\_NAME} function.

For example, how might we change properties like the size or shape of points in our scatter plot? We used the \texttt{geom\_point} function to add points to the scatter plot, which means we have to set the arguments of \texttt{geom\_point} to change the point properties. We can use this idea to rebuild the example scatter plot, setting the shape, size and transparency of points:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-199-1} \end{center}

The point shape is set with the \texttt{shape} argument. There are a few different ways to specify point shapes in R. We used the numeric coding system in this example (17 = triangle). Unfortunately, the numeric codes aren't at all intuitive. Here are the more common ones:

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-200-1} \end{center}

The point size is specified by the \texttt{size} argument. This has a baseline default value of 1. We assigned \texttt{size} a value of 1.5, thereby increasing the point size relative to the default. We could make the points smaller by using a value less than 1.

We made the points semi-transparent by setting the value of the \texttt{alpha} argument to be less than 1. In graphical systems, the `alpha channel' specifies transparency---a value of 0 is taken to mean `completely invisible', and a value of 1 means `completely opaque'.

There are other arguments---such as \texttt{fill} and \texttt{colour}---that can also be used to adjust the way the points are rendered. We'll look at these later.

The key message to take away from this customisation example is this---if we need to alter the properties of a geometric object (points, lines, ect), we do so by specifying the appropriate arguments in the \texttt{geom\_NAME} function that defines the layer it belongs to.

\hypertarget{relationship-between-aesthetic-mappings-and-geom-properties}{%
\subsection{Relationship between aesthetic mappings and geom properties}\label{relationship-between-aesthetic-mappings-and-geom-properties}}

In the previous chapter, we saw that we could introduce information into a plot by setting aesthetic mappings in the \texttt{aes} part of its specification. In the scatter plot example, we included information about species identity by mapping the \texttt{species} variable to the colour aesthetic. What happens if we also try to set the colour within the \texttt{geom\_point} part?

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour) + sex (shape)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points (including colour)}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{colour =} \StringTok{"skyblue"}\NormalTok{, }\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-201-1} \end{center}

All the points are now one colour (`sky blue') which means we have lost the species information. What does this example demonstrate? When we set the properties of a geom, this will override any aesthetic mappings that conflict with our choice of customisation. Try to remember that---failing to do so is a good way to become frustrated.

\begin{infobox}{information}

\hypertarget{built-in-colours-in-r}{%
\subsubsection*{Built-in colours in R}\label{built-in-colours-in-r}}
\addcontentsline{toc}{subsubsection}{Built-in colours in R}

There is nothing special about `skyblue' other than the fact that it is colour name known to R. There are over 650 built-in colour names. To see them, use a function called \texttt{colours} to print them all to the Console. Here are 25 selected at random:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(}\FunctionTok{colours}\NormalTok{(), }\AttributeTok{size =} \DecValTok{25}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "slateblue3"    "lavender"      "gray8"         "pink"         
##  [5] "turquoise3"    "slategray3"    "hotpink"       "gray15"       
##  [9] "tomato4"       "grey50"        "khaki1"        "grey65"       
## [13] "darkslategray" "royalblue"     "gray29"        "grey64"       
## [17] "grey6"         "palegreen3"    "lightyellow"   "firebrick1"   
## [21] "gray81"        "darkorange1"   "darkorchid1"   "goldenrod1"   
## [25] "violetred2"
\end{verbatim}

\end{infobox}

\hypertarget{plot-scales}{%
\section{Plot scales}\label{plot-scales}}

Setting the arguments of a \texttt{geom\_} function applies changes in a layer-specific manner. Other kinds of customisation affect every layer in a plot. Remember what we said about \textbf{scales} in the previous chapter:

\begin{quote}
The scale part of a \textbf{ggplot2} object controls how the information in a variable is mapped to the aesthetic properties. A scale takes the data and converts it into variation we can perceive, such as an x/y location or the colour and size of points in a plot.
\end{quote}

Every aesthetic mapping has a scale associated with it. We adjust `how the information in a variable is mapped to the aesthetic properties' by changing its corresponding scale.

As always, this kind of thing is best understood by example. Let's adjust the scale associated with the y-axis aesthetic by increasing the number of the horizontal lines and their accompanying labels (the `guides').

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise y{-}axis grid line and label locations}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-204-1} \end{center}

What's going on here?

\begin{itemize}
\item
  The aesthetic we wanted to alter was the y-axis position. The y-axis in this particular plot is associated with a continuous scale because \texttt{bill\_depth\_mm} is a numeric variable. This means we have to apply the \texttt{scale\_y\_continuous} function to tweak the position of the y-axis guides.
\item
  The \texttt{breaks} argument of \texttt{scale\_y\_continuous} takes a numeric vector to specify where the guides should be drawn. We used the base R \texttt{seq} function to set up a numeric vector containing the sequence: 14, 16, 18 and 20. That tells \textbf{gglot2} to place the guides at 14, 16, 18 and 20 on the y-axis.
\end{itemize}

The functions that adjust a scale all have the general form \texttt{scale\_AES\_TYP}, where:

\begin{itemize}
\tightlist
\item
  the \texttt{AES} bit in the name refers to the relevant aesthetic, and
\item
  the \texttt{TYP} part refers to the type of scale we want to apply.
\end{itemize}

Each kind of \texttt{scale\_AES\_TYP} function has its own set of arguments to control how the scale works. For example, the \texttt{breaks} argument of \texttt{scale\_y\_continuous} uses a numeric vector to specify where the guides should be drawn. We can do much fancier things if we want to. For example, the \texttt{trans} argument can be used to apply a particular transformation to an axis, such as a logarithm.

Predictably, there is also a \texttt{scale\_x\_continuous} function. We can use this in exactly the same way to control where the guides on the x-axis appear:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise x{-} and y{-}axis grid line and label locations}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{34}\NormalTok{, }\DecValTok{62}\NormalTok{, }\AttributeTok{by =} \DecValTok{4}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-205-1} \end{center}

The key message to take away from this is that every aesthetic mapping has a scale associated with it. If we want to change how the information associated with an aesthetic mapping is displayed we have to change the corresponding scale. That suggests we can change the way point colours are associated with the \texttt{species} variable in our example by using one of the \texttt{scale\_colour\_YY} functions. That is correct:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise x{-} and y{-}axis grid line and label locations}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{34}\NormalTok{, }\DecValTok{62}\NormalTok{, }\AttributeTok{by =} \DecValTok{4}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# customise the species colours (\textquotesingle{}value\textquotesingle{}) and labels}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}
    \AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\StringTok{"Chinstrap"}\NormalTok{, }\StringTok{"Gentoo"}\NormalTok{, }\StringTok{"Adelie"}\NormalTok{),}
    \AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"cornflowerblue"}\NormalTok{, }\StringTok{"seagreen"}\NormalTok{, }\StringTok{"orangered3"}\NormalTok{),}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\AttributeTok{Chinstrap =} \StringTok{"P. antarcticus"}\NormalTok{, }\AttributeTok{Gentoo =} \StringTok{"P. papua"}\NormalTok{, }\AttributeTok{Adelie =} \StringTok{"P. adeliae"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-206-1} \end{center}

This uses \texttt{scale\_color\_manual} to achieve three things:

\begin{itemize}
\tightlist
\item
  it defines the order to display the three species in the legend via \texttt{limits},
\item
  it sets up a custom colour palette via \texttt{values}, and
\item
  it alters the category labels via \texttt{labels} (so that their scientific names are used).
\end{itemize}

Scales are one of the hardest aspects of \textbf{ggplot2} to master. There are many different scales, each controlled by its own unique set of arguments. Fortunately, the defaults used by \textbf{ggplot2} are often good enough to arrive at a reasonable plot without having to manipulate the scales.

\hypertarget{labels}{%
\section{Labels}\label{labels}}

What else might we like to tweak? Look at the x and y-axis labels. These are the names of the variables used in the x/y aesthetic mappings. These labels aren't too bad, but they could be nicer to look at. We know `bill\_depth\_mm' stands for `bill depth (measured in mm)', so why not use an axis label more like that?

The axes labels are a feature of the whole plot---i.e.~they do not belong to a particular layer. This means we can't alter axis labels by passing arguments to the function that built a layer (\texttt{geom\_point}). We have to use the labelling function: \texttt{labs}. This sets the label of any mapped aesthetics. For example, to set the labels of the x and y axes and the label associated with the colour mapping (i.e.~the \texttt{species} legend title), use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise x{-} and y{-}axis grid line and label locations}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{34}\NormalTok{, }\DecValTok{62}\NormalTok{, }\AttributeTok{by =} \DecValTok{4}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# customise the species colours (\textquotesingle{}value\textquotesingle{}) and labels}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}
    \AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\StringTok{"Chinstrap"}\NormalTok{, }\StringTok{"Gentoo"}\NormalTok{, }\StringTok{"Adelie"}\NormalTok{),}
    \AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"cornflowerblue"}\NormalTok{, }\StringTok{"seagreen"}\NormalTok{, }\StringTok{"orangered3"}\NormalTok{),}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\AttributeTok{Chinstrap =} \StringTok{"P. antarcticus"}\NormalTok{, }\AttributeTok{Gentoo =} \StringTok{"P. papua"}\NormalTok{, }\AttributeTok{Adelie =} \StringTok{"P. adeliae"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \CommentTok{\# set the the x/y{-}axis labels and legend label using \textasciigrave{}labs\textasciigrave{}}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Bill length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Bill depth (mm)"}\NormalTok{, }\AttributeTok{colour =} \StringTok{"Penguin Species"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-207-1} \end{center}

Using \texttt{labs} is easy---if a mapping was set up in \texttt{aes} we can change its label via a `name = value' construct in \texttt{labs}. That's it.

Finally, another way to set the axis labels is via the \texttt{xlab} and \texttt{ylab}. We tend not to use these because \texttt{labs} deals with all our labelling needs on its own. Why waste effort remembering three things if you only need to remember one?

\hypertarget{themes}{%
\section{Themes}\label{themes}}

The final route to customisation happens via the `theme' of a plot. We haven't considered the \textbf{ggplot2} theme system at all yet. A \textbf{ggplot2} theme deals with all the visual elements of a plot that aren't directly handled by adjusting geom properties or scales. These are essentially the `non-data' parts of a plot---features such as the colour of the plotting region and the grid lines, whether or not those grid lines are even displayed, the position of labels, the font used in labels, and so on.

Here's a short example that adjusts the legend of the example plot:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise x{-} and y{-}axis grid line and label locations}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{34}\NormalTok{, }\DecValTok{62}\NormalTok{, }\AttributeTok{by =} \DecValTok{4}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# customise the species colours (\textquotesingle{}value\textquotesingle{}) and labels}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}
    \AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\StringTok{"Chinstrap"}\NormalTok{, }\StringTok{"Gentoo"}\NormalTok{, }\StringTok{"Adelie"}\NormalTok{),}
    \AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"cornflowerblue"}\NormalTok{, }\StringTok{"seagreen"}\NormalTok{, }\StringTok{"orangered3"}\NormalTok{),}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\AttributeTok{Chinstrap =} \StringTok{"P. antarcticus"}\NormalTok{, }\AttributeTok{Gentoo =} \StringTok{"P. papua"}\NormalTok{, }\AttributeTok{Adelie =} \StringTok{"P. adeliae"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \CommentTok{\# use \textasciigrave{}labs\textasciigrave{} to set x/y{-}axis labels and remove legend label}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Bill length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Bill depth (mm)"}\NormalTok{, }\AttributeTok{colour =} \StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# use theme to customise position and text formatting of the legend}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{face=}\StringTok{"italic"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-208-1} \end{center}

Changes to the theme are specified using\ldots{} the \texttt{theme} function. We used \texttt{theme} to move the legend to the top of the plot (via \texttt{legend.position}) and show the species labels in italics (via \texttt{legend.text}). We also got rid of the legend title by setting the colour label to empty character string in \texttt{labs}. We could do that via \texttt{theme} but using \texttt{labs} is simpler.

The \textbf{ggplot2} theme system is extremely powerful. Once we know how to use it, we can set up a custom theme and apply it with very little effort. However, that's not an entirely trivial thing to do because there are just so many components of every plot. Most people just google whatever adjustment they want to make when the time comes. Even then, tweaking each individual part of a theme can be very time consuming. Fortunately, there are a range of standard themes built into \textbf{ggplot2}. Here's how to apply a built-in theme:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# bill depth (y) vs bill length (x) by species (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# add points layer and customise appearance of points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{shape =} \DecValTok{17}\NormalTok{, }\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.85}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise x{-} and y{-}axis grid line and label locations}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{34}\NormalTok{, }\DecValTok{62}\NormalTok{, }\AttributeTok{by =} \DecValTok{4}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{20}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# customise the species colours (\textquotesingle{}value\textquotesingle{}) and labels}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}
    \AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"cornflowerblue"}\NormalTok{, }\StringTok{"seagreen"}\NormalTok{, }\StringTok{"orangered3"}\NormalTok{),}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\AttributeTok{Adelie =} \StringTok{"P. adeliae"}\NormalTok{, }\AttributeTok{Chinstrap =} \StringTok{"P. antarcticus"}\NormalTok{, }\AttributeTok{Gentoo =} \StringTok{"P. papua"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \CommentTok{\# use \textasciigrave{}labs\textasciigrave{} to set x/y{-}axis labels and remove legend label}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Bill length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Bill depth (mm)"}\NormalTok{, }\AttributeTok{colour =} \StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# apply \textquotesingle{}black and white\textquotesingle{} theme}
  \FunctionTok{theme\_bw}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{13}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# use theme to customise position and text formatting of the legend}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{legend.position =} \StringTok{"top"}\NormalTok{,}
    \AttributeTok{legend.text =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{face=}\StringTok{"italic"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-209-1} \end{center}

This uses \texttt{+} with the \texttt{theme\_bw} function to add the built-in `black and white' theme. This theme dispenses with the grey background that so many people dislike. There are a couple of things to note from this example:

\begin{itemize}
\item
  To apply the changes to the legend position, we had to place the \texttt{theme} part \textbf{after} we set the overall theme using \texttt{theme\_bw}. The \texttt{theme\_bw} function will override the \texttt{theme} changes if we try to do it the other way round.
\item
  We set the \texttt{base\_size} argument of \texttt{theme\_bw}. This rescales the text in a plot, leaving the relative size of the different elements unchanged. We did not have to do this, but it is worth showing off because it is such a useful trick.
\end{itemize}

There aren't that many themes built into \textbf{ggplot2}. Here's a quick look at them:

\includegraphics[width=0.333\linewidth]{intro-bio-data-book_files/figure-latex/unnamed-chunk-210-1} \includegraphics[width=0.333\linewidth]{intro-bio-data-book_files/figure-latex/unnamed-chunk-210-2} \includegraphics[width=0.333\linewidth]{intro-bio-data-book_files/figure-latex/unnamed-chunk-210-3} \includegraphics[width=0.333\linewidth]{intro-bio-data-book_files/figure-latex/unnamed-chunk-210-4} \includegraphics[width=0.333\linewidth]{intro-bio-data-book_files/figure-latex/unnamed-chunk-210-5} \includegraphics[width=0.333\linewidth]{intro-bio-data-book_files/figure-latex/unnamed-chunk-210-6}

\hypertarget{advice-for-making-plots}{%
\section{Advice for making plots}\label{advice-for-making-plots}}

We'll end this section with a bit of advice about making your own plots with \textbf{ggplot2}. Look at the code we ended up with for the final scatter plot above. It's complicated! However, we didn't make that in one go. We built up to it slowly, tweaking one thing at a time. That's the trick---\textbf{start with a basic skeleton and gradually increase the level of customisation.} Begin by getting the aesthetic mappings and the faceting correct so that all the relevant variables are represented. Then introduce one bit of customisation and review the plot to ensure it worked and everything looks right. Keep doing this, one bit of customisation at a time, until the plot looks right.

\hypertarget{exploring-one-variable}{%
\chapter{Exploring one variable}\label{exploring-one-variable}}

This chapter will consider how to go about exploring a single variable. Using the \texttt{penguins} data, we'll review some basic visualisations for exploring the sample distribution of numeric and categorical variables.

\hypertarget{explore-numeric}{%
\section{Exploring numerical variables}\label{explore-numeric}}

We'll work with flipper length (\texttt{flipper\_length\_mm}) and body mass (\texttt{body\_mass\_g}) to demonstrate how to explore numeric variables.

\hypertarget{what-kind-of-numeric-variable}{%
\subsection{What kind of numeric variable?}\label{what-kind-of-numeric-variable}}

The simplest way to explore data is to view it in its raw form. Take a quick look at the first 100 values of \texttt{flipper\_length\_mm} and \texttt{body\_mass\_g}. We can get these by extracting them with the \texttt{\$} operator and using the \texttt{head} function:

\textbf{flipper length} ---

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{flipper\_length\_mm, }\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 181 186 195  NA 193 190 181 195 193 190 186 180 182 191 198 185 195 197 184
## [20] 194 174 180 189 185 180 187 183 187 172 180 178 178 188 184 195 196 190 180
## [39] 181 184 182 195 186 196 185 190 182 179 190 191
\end{verbatim}

\textbf{body mass} ---

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{body\_mass\_g, }\DecValTok{50}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 3750 3800 3250   NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400
## [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950
## [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000
## [46] 4600 3425 2975 3450 4150
\end{verbatim}

These are clearly both numeric variables, but we can say a bit more:

\begin{itemize}
\tightlist
\item
  They are both measured on a ratio scale. Zero really is zero, meaning that it makes sense to say that a length of 200 millimetres is twice as long as 100 millimetres or that 6000 grams is twice the mass of 3000 grams.
\item
  They are continuous variables. Think about the possible values flipper length and body mass can take. A length of 200.52 millimetres and a mass of 3000.71 grams are both perfectly reasonable, so fundamentally, these are continuous variables.
\end{itemize}

Notice that even though body mass is a continuous variable \texttt{body\_mass\_g} looks discrete because body mass measurements have been taken to the nearest 25 grams. This reflects methodological limitations---presumably, weighing a live penguin to more than 25 grams precision in the field is challenging. This illustrates an important idea: we can't just look at the values a numeric variable takes to determine whether it is discrete or continuous.

Whether we treat a variable as continuous or discrete is sometimes an analysis decision. We have to decide based on knowledge of a variable's true nature and the measurement process. For example, if we were only able to measure body mass to the nearest 500 grams, we would only ``see'' a few different body mass categories. It might then be reasonable to treat the \texttt{body\_mass\_g} variable as an ordinal, categorical variable.

\hypertarget{histograms}{%
\subsection{Histograms}\label{histograms}}

We only looked at the first 50 values of the \texttt{flipper\_length\_mm} and \texttt{body\_mass\_g} variables because the \texttt{penguins} data set is a bit too big to view everything at once easily. It's hard to say much about the sample distribution of a numeric variable by looking at the raw data because there are so many unique values. Those first 50 are also not representative of the whole sample.

What else might we do? One useful tool is `binning'. The idea behind binning a numeric variable is very simple. It involves two steps.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Divide the number line into equal-sized, non-overlapping intervals. These are the `bins'. We pick the interval size to ensure bins (typically) include at least a few cases.
\item
  We then have to count up the number of times the variable falls inside each bin. The resulting set of counts summarises the sample distribution of the numeric variable.
\end{enumerate}

Binning is very tedious to do by hand. Fortunately, R can do this for us. This shows how to use the \texttt{cut} function with the \textbf{dplyr} \texttt{transmute} and \texttt{count} verbs to bin the \texttt{flipper\_length\_mm} variable into 5 mm intervals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{transmute}\NormalTok{(}\AttributeTok{bins =} \FunctionTok{cut}\NormalTok{(flipper\_length\_mm, }\AttributeTok{breaks =} \FunctionTok{seq}\NormalTok{(}\DecValTok{170}\NormalTok{, }\DecValTok{235}\NormalTok{, }\AttributeTok{by =} \DecValTok{5}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{(bins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 14 x 2
##    bins          n
##    <fct>     <int>
##  1 (170,175]     2
##  2 (175,180]    11
##  3 (180,185]    28
##  4 (185,190]    58
##  5 (190,195]    57
##  6 (195,200]    38
##  7 (200,205]    18
##  8 (205,210]    30
##  9 (210,215]    33
## 10 (215,220]    32
## 11 (220,225]    20
## 12 (225,230]    14
## 13 (230,235]     1
## 14 <NA>          2
\end{verbatim}

We won't explain how this works because we only need to understand the output. This is a small tibble where the \texttt{bins} column shows the intervals, and the \texttt{n} column gives the associated counts.

What does this tell us? It shows that the most common flipper length is around 190 mm. Values much below 190 mm are rare, but a range of values above this are possible, with higher values becoming less frequent. These binned data are telling us a lot about the sample distribution of \texttt{flipper\_length\_mm}.

It is still difficult to perceive distributional information when presented as a series of numbers. What we need is a visualisation based on the above numbers. This is what a \textbf{histogram} provides. Histograms summarise the sample distribution of a variable by showing the counts of binned data as a series of bars. The position and width of each bar correspond to an interval and the height shows the count. Here is a histogram based on the binned data we made:

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-216-1} \end{center}

This gives a clear summary of the sample distribution of body mass. It reveals:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the most common values, which are round about 190 mm;
\item
  the range of the data, which is about 60 mm; and
\item
  the shape of the distribution, which appears to be \textbf{bimodal}---it has two peaks.
\end{enumerate}

That last observation wasn't immediately obvious when looking at the raw counts in the binned summary.

We used \textbf{ggplot2} to make that histogram. We could have used \textbf{dplyr} to make the binned data set and then used this with \textbf{ggplot2} to construct the plot manually. However, there is a much easier way to make a histogram. We'll demonstrate this now. Rather than do it using one \textbf{ggplot2} expression, we will break the process up to demonstrate how it works.

The first step uses the \texttt{ggplot} function with \texttt{aes} to set up the default data and aesthetic mapping:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create graphical object with data and aesthetic mapping}
\NormalTok{plot\_hist }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flipper\_length\_mm))}
\end{Highlighting}
\end{Shaded}

This is no different than the scatter plot example we stepped through. The only difference is that a histogram requires only one aesthetic mapping. We supplied the argument \texttt{x\ =\ flipper\_length\_mm} to \texttt{aes} because we want to display the map intervals associated with \texttt{flipper\_length\_mm} to the x-axis. We don't need to supply an aesthetic mapping for the y-axis because \textbf{ggplot2} is going to handle this for us.

The second step adds a layer to the \texttt{plot\_hist} object. We need to find the right \texttt{geom\_XX} function to do this. This is called \texttt{geom\_histogram}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use geom\_histogram to add histogram layer}
\NormalTok{plot\_hist }\OtherTok{\textless{}{-}}\NormalTok{ plot\_hist }\SpecialCharTok{+} \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

It is instructive to look at the summary of the \textbf{ggplot2} object at this stage:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print summary of graphical object}
\FunctionTok{summary}\NormalTok{(plot\_hist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## data: species, island, bill_length_mm, bill_depth_mm,
##   flipper_length_mm, body_mass_g, sex, year [344x8]
## mapping:  x = ~flipper_length_mm
## faceting: <ggproto object: Class FacetNull, Facet, gg>
##     compute_layout: function
##     draw_back: function
##     draw_front: function
##     draw_labels: function
##     draw_panels: function
##     finish_data: function
##     init_scales: function
##     map_data: function
##     params: list
##     setup_data: function
##     setup_params: function
##     shrink: TRUE
##     train_scales: function
##     vars: function
##     super:  <ggproto object: Class FacetNull, Facet, gg>
## -----------------------------------
## geom_bar: na.rm = FALSE, orientation = NA
## stat_bin: binwidth = NULL, bins = NULL, na.rm = FALSE, orientation = NA, pad = FALSE
## position_stack
\end{verbatim}

Look at the text below the \texttt{-\/-\/-\/-}. This shows that \texttt{geom\_histogram} adds a `stat' to the layer: \texttt{stat\_bin}. This means \textbf{ggplot2} is going to take the raw \texttt{flipper\_length\_mm} data and bin it for us. Remember---the stat facility of \textbf{ggplot2} is its mechanism for creating summaries of data from the raw inputs. \texttt{stat\_bin} deals with the binning process for us.

Everything we need to plot a histogram is now set up. Here is the resulting plot:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# show the histogram}
\FunctionTok{print}\NormalTok{(plot\_hist)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-220-1} \end{center}

This is not quite the same as the example we saw above because it uses different bins. We can set the properties of the \texttt{geom\_histogram} to tweak this kind of thing---the \texttt{binwidth} argument adjusts the width of the bins used. Let's construct the histogram again with 5 mm wide bins, as well as adjust the colour scheme and axis labels a bit:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display flipper length histogram}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ flipper\_length\_mm)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_histogram to add histogram layer + customisation}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{5}\NormalTok{, }\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{colour=}\StringTok{"darkgrey"}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Flipper length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-221-1} \end{center}

Notice that the effect of increasing the bin width is to `smooth' the histogram, i.e.~this version looks less jagged than the last. Whether or not that colour scheme is an improvement is a matter of taste. Mostly we wanted to demonstrate how the \texttt{fill} and \texttt{colour} arguments change the output--- \texttt{fill} sets the fill colour of the bar and \texttt{colour} deals with the line around each bar.

\begin{infobox}{warning}

\hypertarget{choose-your-own-bin-widths}{%
\subsubsection*{Choose your own bin widths}\label{choose-your-own-bin-widths}}
\addcontentsline{toc}{subsubsection}{Choose your own bin widths}

It is good practice to experiment with \texttt{binwidth} because the value selected by \textbf{ggplot2} is seldom optimal. Finding a `good' value is as much art as science. One way of doing this is to start with a value that is probably too large and then refine it down. For example, we could work out the approximate range of the data by eye and then use 1/10\textsuperscript{th} of that range as an initial value for \texttt{binwidth}. Unless the data set is very small, this will result in a histogram that aggregates too much information. Once we have that rough starting value, we then reduce \texttt{binwidth} in small steps, re-rendering the plot each time until we end up with something that summarises the distribution well.

\end{infobox}

We can use pretty much the same R code to produce a histogram summarising the body mass sample distribution:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display body mass histogram}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_mass\_g)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_histogram to add histogram layer + customisation}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{250}\NormalTok{, }\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{colour=}\StringTok{"darkgrey"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Flipper length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-222-1} \end{center}

The only things that changed in this example were the aesthetic mapping and the bin width, which we set to 250 to reflect the range of observed body masses. The histogram reveals that the most common body mass (the mode) is around 3500 grams and the range of masses is also about 3500 grams. It also shows that the distribution is \textbf{skewed}, i.e.~it is asymmetric. We can say even more---the distribution is right-skewed (a.k.a. positive-skewed) because the tail on the right gets further away from the mode than the left tail.

We have to choose those bin widths carefully. Body mass is measured to the nearest 25 grams. This means we should choose a bin width that is some multiple of 25 to produce a meaningful histogram. Look what happens if we set the bin width to 25:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display body mass histogram}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_mass\_g)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_histogram to add histogram layer + customisation {-}{-} choose }
  \CommentTok{\# a sensible bin width}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{25}\NormalTok{, }\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{colour=}\StringTok{"darkgrey"}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Flipper length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-223-1} \end{center}

We end up with gaps in the histogram because many bins do not include any data. The take-home message is that we have to pay attention to our data to produce meaningful summaries.

\hypertarget{dot-plots}{%
\subsection{Dot plots}\label{dot-plots}}

Histograms are good for visualising sample distributions when we have a reasonably large sample size, e.g.~\textgreater100 observations. They are less effective when a sample is small. In this `small data' situation, it is better to use something called a \textbf{dot plot}\footnote{Not to be confused with the `Cleveland dot plot'. A standard dot plot summarises a sample distribution. The Cleveland dot plot is something quite different, which summarises the frequencies of a categorical variable. It's meant to serve as a simple alternative to bar charts and pie charts.}.

We have created subset of \texttt{penguins} that only retains female Adelie penguin observations from 2007, called \texttt{penguins\_small}. This is considerably smaller than the original:

\begin{verbatim}
## # A tibble: 22 x 8
##    species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
##    <chr>   <chr>              <dbl>         <dbl>             <int>       <int>
##  1 Adelie  Torgersen           39.5          17.4               186        3800
##  2 Adelie  Torgersen           40.3          18                 195        3250
##  3 Adelie  Torgersen           36.7          19.3               193        3450
##  4 Adelie  Torgersen           38.9          17.8               181        3625
##  5 Adelie  Torgersen           41.1          17.6               182        3200
##  6 Adelie  Torgersen           36.6          17.8               185        3700
##  7 Adelie  Torgersen           38.7          19                 195        3450
##  8 Adelie  Torgersen           34.4          18.4               184        3325
##  9 Adelie  Biscoe              37.8          18.3               174        3400
## 10 Adelie  Biscoe              35.9          19.2               189        3800
## # ... with 12 more rows, and 2 more variables: sex <chr>, year <int>
\end{verbatim}

This is about the right size for using a dot plot. Constructing a dot plot with \textbf{ggplot2} is easy once you understand the histogram case. The code is are very similar:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display body mass dot plot}
\FunctionTok{ggplot}\NormalTok{(penguins\_small, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_mass\_g)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_dotplot to add layer + choose a sensible bin width!}
  \FunctionTok{geom\_dotplot}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{100}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# set the the x{-}axis label and remove y{-}axis label}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Body mass (g)"}\NormalTok{, }\AttributeTok{y =} \StringTok{""}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# remove y{-}axis guides}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{(), }\AttributeTok{axis.ticks.y =} \FunctionTok{element\_blank}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-226-1} \end{center}

Each observation in the data adds one dot, and dots that fall into the same bin are stacked up on top of one another. Notice the bins are not evenly spaced, however. The resulting plot displays the same information as a histogram but tends to be more informative when there are few observations.

The \texttt{theme} part of that example is entirely optional.It removes the grid lines and y-axis labels because these are not meaningful when the number of stacked dots represents ' height'. It is unfortunate that \textbf{ggplot2} displays them. But then, no package is perfect.

\hypertarget{explore-categorical}{%
\section{Exploring categorical variables}\label{explore-categorical}}

We will work with the penguin species (\texttt{species}) and observation year (\texttt{year}) variables to demonstrate how to explore categorical variables.

\hypertarget{what-kind-of-categorical-variable}{%
\subsection{What kind of categorical variable?}\label{what-kind-of-categorical-variable}}

Exploring categorical variables is generally simpler than the numeric case. The simplest thing we can do is examine the set of categories. For example, we can print these by extracting a variable with the \texttt{\$} operator and using the \texttt{unique} function:

\textbf{species} ---

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{unique}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Adelie"    "Gentoo"    "Chinstrap"
\end{verbatim}

\textbf{observation year} ---

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{unique}\NormalTok{(penguins}\SpecialCharTok{$}\NormalTok{year)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2007 2008 2009
\end{verbatim}

These are obviously categorical---there are no numeric values associated with either variable. The obvious question to ask about each variable is, is it ordinal or nominal?

It is probably safe to assume that \texttt{species} should be treated as a nominal variable. There is no reasonable way to order the three species---i.e.~a statement such as `Adelie \textgreater{} Gentoo' is nonsense.

What about \texttt{year}? That's a bit more tricky. If we were interested in how some aspect of the data changes over time, we might consider treating year as a numeric variable, or perhaps, as an ordinal categorical variable. Alternatively, if the question is simply, `do the data vary from one year to the next' without any concern for trends, it's reasonable to treat year as a nominal categorical variable.

This once again illustrates an important idea---the classification of a variable sometimes depends on the analysis goals. The decision matters because it influences how we choose to summarise a variable, how we interpret its relationship with other variables, and whether a specific statistical model is appropriate for our data or not.

For now, let's assume it's fine to treat \texttt{year} as a nominal variable.

\hypertarget{bar-plots}{%
\subsection{Bar plots}\label{bar-plots}}

We can't say anything about the sample distribution of a categorical variable by just looking at the possible categories. We need to explore the relative frequency of those categories. There is no need to carry out anything as complicated as binning. Instead, we simply count up the number of times each category occurs in the data. The \textbf{dplyr} \texttt{count} verb will does this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{count}\NormalTok{(species)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   species       n
##   <chr>     <int>
## 1 Adelie      152
## 2 Chinstrap    68
## 3 Gentoo      124
\end{verbatim}

We saw this result earlier in the book---the most common species is Adelie, followed by the Gentoo and Chinstrap. Gentoo is roughly as common as Adelie, whereas Chinstrap is about half as frequent.

These numbers lead directly to an informative visualisation. The usual graphical tool for summarising categorical variables is the \textbf{bar chart}. A bar chart presents summaries of grouped data with rectangular bars. The lengths of each bar is proportional to the value it represents. When summarising categorical variables, the bar lengths show the raw counts or proportions of each category.

Constructing a bar graph to display category counts is easy with \textbf{ggplot2}. We'll do this for the \texttt{species} variable. As always, we start by using the \texttt{ggplot} function to construct a graphical object containing the default data and aesthetic mapping.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create graphical object with data and aesthetic mapping}
\NormalTok{plot\_bar }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species)) }
\end{Highlighting}
\end{Shaded}

We've called the object \texttt{plot\_bar} for the obvious reason. Notice that we only need to define one aesthetic mapping---we mapped \texttt{species} to the x-axis. This will produce a bar plot with vertical bars.

The next step is to add a layer using one of the \texttt{geom\_XX} functions. There are two functions we can use to create bar charts in ggplot, \texttt{geom\_bar} and \texttt{geom\_col}. By default, \texttt{geom\_col} counts the number of observations in each category, whereas \texttt{geom\_bar} plots the actual numbers we provide.

We want to show the counts of each \texttt{species} category, meaning we should use \texttt{geom\_bar}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use geom\_bar to add bar plot layer}
\NormalTok{plot\_bar }\OtherTok{\textless{}{-}}\NormalTok{ plot\_bar }\SpecialCharTok{+} \FunctionTok{geom\_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Now examine the summary of the \textbf{ggplot2} object:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# print summary of graphical object}
\FunctionTok{summary}\NormalTok{(plot\_bar) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## data: species, island, bill_length_mm, bill_depth_mm,
##   flipper_length_mm, body_mass_g, sex, year [344x8]
## mapping:  x = ~species
## faceting: <ggproto object: Class FacetNull, Facet, gg>
##     compute_layout: function
##     draw_back: function
##     draw_front: function
##     draw_labels: function
##     draw_panels: function
##     finish_data: function
##     init_scales: function
##     map_data: function
##     params: list
##     setup_data: function
##     setup_params: function
##     shrink: TRUE
##     train_scales: function
##     vars: function
##     super:  <ggproto object: Class FacetNull, Facet, gg>
## -----------------------------------
## geom_bar: width = NULL, na.rm = FALSE, orientation = NA
## stat_count: width = NULL, na.rm = FALSE, orientation = NA
## position_stack
\end{verbatim}

Look at the layer information below \texttt{-\/-\/-\/-}. The \texttt{geom\_bar} function uses \texttt{stat\_count}. This means \textbf{ggplot2} summed the number of observations associated with each category of \texttt{species}. Counting a categorical variable is analogous to binning a numeric variable. The only difference is that there is no need to specify bin widths because \texttt{species} is categorical. Here's the resulting figure:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# show the bar plot}
\FunctionTok{print}\NormalTok{(plot\_bar)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-233-1} \end{center}

This is exactly the same information produced by the \texttt{count} function, only now it's presented in graphical form. We can customise this bar graph with functions like \texttt{labs} and by setting various properties inside \texttt{geom\_bar}. For example:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_bar to add bar plot layer of **counts**}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"rosybrown4"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Number of Observations"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-234-1} \end{center}

The only new thing here is that we used the \texttt{width} argument of \texttt{geom\_bar} to make the bars a little narrower than the default. Notice that we use \texttt{fill} (not \texttt{colour}) to change the colour of the bars.

What might we like to change about this plot? The different species appear in alphabetical order. There's nothing particularly meaningful about that order. Perhaps it would make more sense to show them in frequency order from least to most common?

We need to customise the scale associated with the `x' aesthetic to achieve this. We can start by making a short character vector containing the species names, listing them in the order they need to be shown:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# character vector of species names **in required order**}
\NormalTok{ords }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Chinstrap"}\NormalTok{, }\StringTok{"Gentoo"}\NormalTok{, }\StringTok{"Adelie"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Keep an eye on the spelling---R is not forgiving of spelling errors. We can use this with the \texttt{limits} argument of the \texttt{scale\_x\_discrete} function to adjust the ordering:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_bar to add bar plot layer of **counts**}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"rosybrown4"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise order of x{-}axis (limits)}
  \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{limits =}\NormalTok{ ords) }\SpecialCharTok{+}
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Number of Observations"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-236-1} \end{center}

We had to use one of the \texttt{scale\_x\_YY} functions to change the way the `x' aesthetic appears. We use \texttt{scale\_x\_discrete} because `discrete' is \textbf{ggplot2}-speak for `categorical'.

Is there anything else we might want to change? Sometimes it is clearer to plot horizontal bars, particularly if the categorical axis labels are all bunched together (not really the case here). Flipping the x and y axes makes a horizontal bar chart, which we can achieve with the \texttt{coord\_flip} function (this is new):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_bar to add bar plot layer of **counts**}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"rosybrown4"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# customise order of x{-}axis (limits)}
  \FunctionTok{scale\_x\_discrete}\NormalTok{(}\AttributeTok{limits =}\NormalTok{ ords) }\SpecialCharTok{+}
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Number of Observations"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# flip x{-} and y{-}axes}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-237-1} \end{center}

We use very similar R code to produce a bar plot summarising the annual counts, i.e.~those associated with the \texttt{year} categories:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of year counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ year)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_bar to add bar plot layer of **counts**}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Year"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Number of Observations"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# flip x{-} and y{-}axes}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-238-1} \end{center}

To make this, we changed the aesthetic mapping, colour and the labels, and dropped the \texttt{scale\_x\_discrete} part because the default ordering is acceptable. The resulting plot shows that there are roughly equal numbers of penguins sampled in each year.

There is one small irritation. Look at the year axis labels and guides. These include non-existent `half years' (e.g.~2007.5) rather than being limited to only the observed years (2007, 2008 and 2009). This has happened because \textbf{ggplot2} doesn't know that \texttt{year} is meant to be treated as a categorical variable. It sees a number, and so it constructs a continuous numeric axis for \texttt{year}.

We need to force \textbf{ggplot2} to treat \texttt{year} as a categorical `thing' to avoid this behaviour. There is more than one way to do this. The simplest is to convert \texttt{year} into a character vector. The \texttt{as.character} function will do this. What's more, \textbf{ggplot2} will allow us to do this when we set up the aesthetic mappings within \texttt{aes}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of year counts}
\FunctionTok{ggplot}\NormalTok{(penguins,}
       \CommentTok{\# convert year to character when setting up mapping}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{as.character}\NormalTok{(year))) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_bar to add bar plot layer of **counts**}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{fill =} \StringTok{"steelblue"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# set the the x{-} and y{-}axis labels}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Year"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Number of Observations"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# flip x{-} and y{-}axes}
  \FunctionTok{coord\_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-239-1} \end{center}

That's better! This may seem like a bit of an edge case but it comes up often enough to be worth highlighting. More generally, this example demonstrates that our conception of a variable needs to matches the way it is interpreted by \textbf{ggplot2} to arrive at a sensible plot.

\hypertarget{exploring-associations}{%
\chapter{Exploring associations}\label{exploring-associations}}

A pair of variables are said to be associated when knowing the value of one variable gives us information about the possible values of another. This chapter's main goal is to show how to use visualisations to explore associations among different kinds of variables.

\hypertarget{numeric-association}{%
\section{Associations between numeric variables}\label{numeric-association}}

The standard graph for displaying an association among a pair of numeric variables is the scatter plot. This uses horizontal and vertical axes to show two variables as a series of points. We saw how to construct a scatter plot in the \protect\hyperlink{chapter-ggplot2-intro}{Introduction to ggplot2} chapter. Here is the initial plot we made to show the association between bill depth and bill length (ignoring species information):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins,}
       \CommentTok{\# aesthetic mappings: bill depth (y) vs bill length (x)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)) }\SpecialCharTok{+} 
  \CommentTok{\# geom\_point to add points layer}
  \FunctionTok{geom\_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-242-1} \end{center}

Most of the time, a scatter plot is exactly the right plot for visualising an association among numeric variables. One limitation of scatter plots is that they tend not to reveal associations when there is a lot of over-plotting happening. This occurs when:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  there is a lot of data (e.g.~1000s of data points), meaning the distance between points is very small; or
\item
  there are many identical pairs of values, typically because both variables are discrete or a continuous variable is measured on a coarse scale.
\end{enumerate}

In these circumstances, over-plotting of points tends to obscure the association. Sometimes we can mitigate this by making the points very small (problem \#1) or semi-transparent (problem \#1 or \#2). But what should we do when those sorts of tricks fail to improve a plot? Luckily, \textbf{ggplot2} provides alternative geoms for visualising numeric associations in situations where over-plotting is a problem.

Two options for dealing with large data sets (problem \#1) are the \texttt{geom\_bin\_2d} and \texttt{geom\_hex} functions. These work like histograms in two dimensions. The \texttt{geom\_bin\_2d} divides the plane into rectangles, counts the number of cases in each rectangle, and then uses the number of cases to assign the rectangle's fill colour. The \texttt{geom\_hex} function does essentially the same thing but instead divides the plane into regular hexagons.

Here's an example of \texttt{geom\_hex} in action (n.b.~\texttt{geom\_hex} relies on the \textbf{hexbin} package, so this need to be installed to use it):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins,}
       \CommentTok{\# aesthetic mappings: bill depth (y) vs bill length (x)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)) }\SpecialCharTok{+} 
  \CommentTok{\# add shaded hex bin layer}
  \FunctionTok{geom\_hex}\NormalTok{(}\AttributeTok{bins =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-243-1} \end{center}

The bins argument controls how many hexagonal bins to use when spanning each dimension. The \texttt{penguins} data set is a bit small for this kind of plot (a scatter plot is actually better), so we had to use relatively coarse binning by setting the number of bins to 12.

Notice how similar this looks to the \textbf{ggplot2} code for a scatter plot. We simply used \texttt{geom\_hex} in place of \texttt{geom\_point}. This reveals a powerful feature of \textbf{ggplot2}---once we have a working plot, we can often switch to a reasonable alternative by simply changing the type of geom. This makes it very quick to explore a data set in different ways.

What should we do if there are there are many identical pairs of values? For example, imagine that bill length had only been measured to the nearest 2 mm and bill depth had only been measured to the nearest 1 mm, like this:

\begin{verbatim}
## # A tibble: 344 x 2
##    bill_length_mm bill_depth_mm
##             <dbl>         <dbl>
##  1             40            19
##  2             40            17
##  3             40            18
##  4             NA            NA
##  5             36            19
##  6             40            21
##  7             38            18
##  8             40            20
##  9             34            18
## 10             42            20
## # ... with 334 more rows
\end{verbatim}

A scatter plot \texttt{bill\_depth\_mm} against \texttt{bill\_length\_mm} produced with those coarsened data would look like this:

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-245-1} \end{center}

This is not very informative because groups of points appear in exactly the same x/y location.

The \texttt{geom\_count} function solves this problem by producing a scatter plot where point sizes are scaled according to how many cases are associated with each point. For example, the following code produces a modified scatter plot using a coarsened bill morphology data set (called \texttt{penguins\_coarse}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display coarsened bill morphology scatter plot}
\FunctionTok{ggplot}\NormalTok{(penguins\_coarse,}
       \CommentTok{\# aesthetic mappings: bill depth (y) vs bill length (x)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_count to add sample size scaled points layer}
  \FunctionTok{geom\_count}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-246-1} \end{center}

Again, notice how similar this looks to the \textbf{ggplot2} code for a standard scatter plot. We simply used \texttt{geom\_count} in place of \texttt{geom\_point}.

\hypertarget{categorical-association}{%
\section{Associations between categorical variables}\label{categorical-association}}

Bar charts are often used to summarise associations between categorical variables. The basic idea is to produce a separate bar for \emph{each combination} of categories in the two variables. The lengths of each bar is proportional to the value it represents, which is either a raw count or the proportion in each category combination.

Using \textbf{ggplot2} to display this information is not very different from producing a bar graph to summarise a single categorical variable. Let's do this for the \texttt{species} and \texttt{year} variables in \texttt{penguins}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of year{-}species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# aesthetic mappings: year (x) by species (fill)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ year, }\AttributeTok{fill =}\NormalTok{ species)) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_bar to add bar plot layer  with stacked bars}
  \FunctionTok{geom\_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-247-1} \end{center}

We want to display information from two categorical variables, so we have to define two aesthetic mappings. We mapped the year variable (\texttt{year}) to the x axis and species (\texttt{species}) to the fill colour. Predictably, we construct the layer using \texttt{geom\_bar}.

This produced a \textbf{stacked bar chart}. Each year has its own bar (\texttt{x\ =\ year}), and each bar has been divided up into different coloured segments, the length of which is determined by the number of observations associated with each species in that year (\texttt{fill\ =\ species}).

We have all the right information in this graph, but it could be improved in a couple of ways:

\begin{itemize}
\tightlist
\item
  Look at the guides on the x axis. There are some pointless extra lines. We saw this issue in a different guise in the previous chapter. It occurs because \texttt{year} is stored as a numeric vector---\textbf{ggplot2} has no way of knowing we want to treat it as a non-numeric, categorical variable.
\item
  The ordering of the species in the stacks does not reflect the relative frequency of each species. Again, we saw this problem in the previous chapter---\textbf{ggplot2} treats does not `know' how we want to order the \texttt{species} categories, and so it uses alphabetical order.
\end{itemize}

We need to ensure \texttt{year} is interpreted as a categorical variable and provide information about the required category order of \texttt{species}. R has a special kind of vector, called a \textbf{factor}, that is designed to tackle these kinds of issues. Factors are used by R to represent categorical variables.

We need to convert \texttt{year} and \texttt{species} to factors. How do we convert a numeric or character vector into a factor? Use the \texttt{factor} function (this is the first time we've mentioned this function). This has an argument called \texttt{levels} that sets the allowed categories and their order.

One way to start is by setting up a character vector of species names \textbf{in the required order} (\texttt{species\_names}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# levels of new species factor **in required order**}
\NormalTok{species\_names }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"Chinstrap"}\NormalTok{, }\StringTok{"Gentoo"}\NormalTok{, }\StringTok{"Adelie"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We supplied the names in the order we want them to appear. Be careful with the spelling---the values of \texttt{species\_names} have to match those used in \texttt{species}. We can now remake the bar plot, this time converting \texttt{species} and \texttt{year} to factors `on the fly':

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of year{-}species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# aesthetic mappings: year (x) by species (fill) AND convert to factor}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(year), }\AttributeTok{fill =} \FunctionTok{factor}\NormalTok{(species, }\AttributeTok{levels =}\NormalTok{ species\_names))) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_bar to add bar plot layer with stacked bars}
  \FunctionTok{geom\_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-249-1} \end{center}

This uses \texttt{species\_names} to set the levels of \texttt{species} when we convert it to a factor. The stacking order of the bars then reflects their order in \texttt{species\_names}. There was no need to set the levels of \texttt{year} because R will use the numeric order by default. Yes\ldots{} the labels in that plot are ugly, but we could easily change these using \texttt{labs} function if we wanted to.

\begin{infobox}{warning}

\hypertarget{factors}{%
\subsubsection*{Factors}\label{factors}}
\addcontentsline{toc}{subsubsection}{Factors}

Factors are very useful and crop up all the time in R. A complete treatment of factors would require a whole new chapter. We've just shown one way to work with them via the \texttt{factor} function. This is enough to solve the reordering trick required to get \textbf{ggplot2} to work the way we want it to, but there's a lot more to learn about factors. There is even a package (\textbf{forcats}) that exists solely to make working with factors a bit easier.

One thing to be aware of is that it is sometimes simpler to convert variables to factors in a data set, rather than doing it every time we use them with \textbf{ggplot2}. For example, we could use \texttt{mutate} to create factor versions of \texttt{year} and \texttt{species}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# convert year and species to factors to ensure correct ordering }
\NormalTok{penguins }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{year    =} \FunctionTok{factor}\NormalTok{(year),}
         \AttributeTok{species =} \FunctionTok{factor}\NormalTok{(species, }\AttributeTok{levels =}\NormalTok{ species\_names)) }
\end{Highlighting}
\end{Shaded}

Any \textbf{ggplot2} code that uses the updated version of \texttt{penguins} would then automatically respect the intended categorical nature of \texttt{year} of and the \texttt{species} ordering we desire.

\end{infobox}

A stacked bar chart is the \texttt{geom\_bar} default. If we want to know how two categorical variables are associated it is sometimes better to plot all bars side-by-side. This is not hard to do. We switch to a side-by-side bar chart by assigning a value of \texttt{"dodge"} to the \texttt{position} argument of \texttt{geom\_bar}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of year{-}species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# aesthetic mappings: year (x) by species (fill) AND convert to factor}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(year), }\AttributeTok{fill =} \FunctionTok{factor}\NormalTok{(species, }\AttributeTok{levels =}\NormalTok{ species\_names))) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_bar to add bar plot layer with adjacent fill bars}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-251-1} \end{center}

The \texttt{position\ =\ "dodge"} argument says that we want the bars to `dodge' one another along the x axis. This slightly odd language is how \textbf{ggplot2} specifies the position of grouped items so they are displayed next to one another.

Remember---the customisation techniques introduced in the \protect\hyperlink{chapter-customise-ggplot2}{Customising plots} chapter are completely general. For example, we could improve the plot by using \texttt{labs} to set the labels, setting custom fill colours with \texttt{scale\_fill\_manual}, and applying a theme via \texttt{theme\_minimal}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of year{-}species counts}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# aesthetic mappings: year (x) by species (fill) AND convert to factor}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(year), }\AttributeTok{fill =} \FunctionTok{factor}\NormalTok{(species, }\AttributeTok{levels =}\NormalTok{ species\_names))) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_bar to add bar plot layer with fill bars next to one another}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# customise fill colour scale}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"cornflowerblue"}\NormalTok{, }\StringTok{"seagreen"}\NormalTok{, }\StringTok{"orangered3"}\NormalTok{)) }\SpecialCharTok{+}
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Year"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Number of cases"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Species"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# apply minimal theme}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-252-1} \end{center}

\hypertarget{cat-num-association}{%
\section{Categorical-numerical associations}\label{cat-num-association}}

The next obvious question is, ``How do we display the association between a categorical and numeric variable?'' As usual, there are a range of different options.

The most common is the `box and whiskers plot' (or just `box plot'). This is best understood by example. To construct a box and whiskers plot we need to set `x' and `y' axis aesthetics for the categorical and numeric variable; then use the \texttt{geom\_boxplot} function to add the appropriate layer. To examine the association between penguin species (\texttt{species}) and body mass measurements (\texttt{body\_mass\_g}), use:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display box and whiskers plot of body mass for each species}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# aesthetic mappings: body mass (y) vs species (x)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{y =}\NormalTok{ body\_mass\_g)) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_boxplot to add box plots layer}
  \FunctionTok{geom\_boxplot}\NormalTok{() }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for x{-} and y{-}axes}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Body mass (g)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-253-1} \end{center}

We can see why this is called a box and whiskers plot. There are four components of each box and whiskers:

\begin{itemize}
\item
  The horizontal line inside the box is the sample median of the numeric variable---a measure of its central tendency. This allows us to compare the most likely value of the numeric variable across the different categories.
\item
  The boxes display the interquartile range (IQR) of the numeric variable in each category, i.e.~the middle 50\% of each group. This allows us to compare the spread (=dispersion) of the numeric values across categories.
\item
  The vertical lines above and below each box are the ``whiskers''. The interpretation of these depends on which kind of box plot we are making. \textbf{ggplot2} produces a traditional Tukey box plot by default. Each whisker is drawn from each end of the box (the upper and lower quartiles) to a well-defined extreme point. To find where the upper whisker ends, we have to find the largest observation that is no more than 1.5 times the IQR above the upper quartile. The lower whisker ends at the most extreme point that is no more than 1.5 times the IQR below the lower quartile.
\item
  Any cases that do not fall inside the whiskers are plotted as an individual point. These may be outliers, although they could also be perfectly consistent with the wider distribution.
\end{itemize}

The resulting plot compactly summarises the distribution of the numeric variable within categories. It provides information about the central tendency, dispersion and skewness of each distribution. We also get a sense of whether there are potential outliers by noting the presence of individual points outside the whiskers.

What does the above plot tell us about body mass and species? It shows the body mass distributions of Chinstrap and Adelie penguins are very similar, in terms of both central tendency and dispersion. In contrast, Gentoo penguins are generally larger and exhibit great absolute variation. The Gentoo body mass distribution is also the only one that seems to display much skew.

\hypertarget{alternatives-to-box-and-whiskers-plots}{%
\subsection{Alternatives to box and whiskers plots}\label{alternatives-to-box-and-whiskers-plots}}

Box and whiskers plots are a good choice for exploring categorical-numerical associations. They provide a lot of information about how the distribution of the numeric variable changes across categories. Sometimes we may want to squeeze even more information about these distributions into a plot. One way to do this is to make multiple histograms.

We know how to make a histogram, and we have seen how aesthetic properties such as \texttt{colour} and \texttt{fill} are used to distinguish different categories of a variable. This suggests we could overlay more than one histogram on a single plot. Let's use this idea to see how the sample distribution of body mass differs among the species again:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display histogram of body mass for each species in one plot}
\FunctionTok{ggplot}\NormalTok{(penguins, }
       \CommentTok{\# aesthetic mappings: body mass (x) by species groups (fill)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_mass\_g, }\AttributeTok{fill =}\NormalTok{ species))  }\SpecialCharTok{+}
  \CommentTok{\# use geom\_histogram to add histogram layer with customisation}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{position =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.8}\NormalTok{, }\AttributeTok{binwidth =} \DecValTok{200}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Body mass (g)"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Species"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-254-1} \end{center}

We defined two mappings: the continuous variable (\texttt{body\_mass\_g}) was mapped to the x axis and the categorical variable (\texttt{species}) was mapped to the fill colour. Notice that we also set the \texttt{position} argument to \texttt{"identity"}. This tells \textbf{ggplot2} not to stack the histograms on top of one another. Instead, they are allowed to overlap. It's for this reason that we also made them semi-transparent by setting the \texttt{alpha} argument.

Plotting several histograms in one layer like this places a lot of information in one plot, but it can be hard to make sense of when the histograms overlap a lot. If the overlapping histograms are too difficult to interpret, we might consider producing a separate one for each category. We've already seen a quick way to do this. Faceting works well here:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display histogram of body mass for each species in separate panels}
\FunctionTok{ggplot}\NormalTok{(penguins,}
       \CommentTok{\# aesthetic mappings: body mass (x) (only one!)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ body\_mass\_g))  }\SpecialCharTok{+}
  \CommentTok{\# use geom\_histogram to add histogram layer with sensible bin width}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{200}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# specify label for x{-}axis}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Body mass (g)"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# facet by species to get one panel per species}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(species))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-255-1} \end{center}

The two histogram plots tell much the same story as the box and whiskers plot. The body mass distributions of Chinstrap and Adelie penguins are very similar, Gentoo penguins are generally a bit larger, but all three distributions overlap to some extent.

\hypertarget{multivariate}{%
\section{Multivariate associations}\label{multivariate}}

We have now examined several ways for summarising associations between two variables. How do we explore associations between more than two variables in a single graph? That is, how do we explore \textbf{multivariate associations}? It is difficult to give a concrete answer because it depends on the scientific question we're addressing, the kinds of variables we're working with, and to a large extent, our creativity and aptitude with a graphing framework like \textbf{ggplot2}.

We have already seen enough of \textbf{ggplot2} works to build some fairly sophisticated visualisations.The key point is that we don't really need to learn anything new to visualise multivariate associations. There are two ways to add additional information to a visualisation, both of which we have already reviewed:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Define aesthetic mappings to allow a layer's properties to depend on the values of one or more variables.
\item
  Use faceting to construct a multi-panel plot according to the values of categorical variables.
\end{enumerate}

Constructing a multivariate visualisation is a matter of combining these approaches to squeeze information from several variables into a single graph.

We saw these approaches used together in the \protect\hyperlink{chapter-ggplot2-intro}{Introduction to ggplot2} chapter. Let's look at one more example to cement the idea. We want to understand how the flipper length relates to body mass and how this numeric-numeric relationship varies by species, sex and island. That's five variables in one plot!

The obvious idea is to produce a multi-panel scatter plot, where each panel is associated with combinations of the categorical variables. We have already seen how to do this kind of thing with \texttt{facet\_wrap}. This time, we'll use the \texttt{facet\_grid} function to organise separate panels for each sex-species combination into a nice 2d grid:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# }
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{na.omit}\NormalTok{(penguins), }
       \CommentTok{\# aesthetic mappings}
       \FunctionTok{aes}\NormalTok{(}
         \CommentTok{\# flipper length (y) vs body mass (x)}
         \AttributeTok{x =}\NormalTok{ body\_mass\_g, }\AttributeTok{y =}\NormalTok{ flipper\_length\_mm, }
         \CommentTok{\# colour AND shape of points vary by island}
         \AttributeTok{colour =}\NormalTok{ island, }\AttributeTok{shape =}\NormalTok{ island)) }\SpecialCharTok{+}
  \CommentTok{\# geom\_point to add points layer}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for ALL mappings (both Island labels required)}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Body size (g)"}\NormalTok{, }
       \AttributeTok{y =} \StringTok{"Flipper length (mm)"}\NormalTok{,}
       \AttributeTok{colour =} \StringTok{"Island"}\NormalTok{, }\AttributeTok{shape =} \StringTok{"Island"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# facet on sex by species grid}
  \FunctionTok{facet\_grid}\NormalTok{(}\AttributeTok{rows =} \FunctionTok{vars}\NormalTok{(sex), }\AttributeTok{cols =} \FunctionTok{vars}\NormalTok{(species))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-256-1} \end{center}

Simple. We set some aesthetics and used faceting to squeeze the five variables into one plot. The \texttt{facet\_grid} function represents the values two or more categorical variables by row and column position, which means we have to set \texttt{rows} and \texttt{cols} arguments. The \texttt{vars(\ldots{})} bit is not optional by the way. We also took the opportunity to introduce a couple of new tricks:

\begin{itemize}
\tightlist
\item
  We used the base R \texttt{na.omit} function on penguins to strip out any rows with a missing value. This avoids introducing an `NA' category in the faceting. This trick can be a bit dangerous because \texttt{na.omit} removes every case where a value is missing.
\item
  We introduced some redundancy by mapping one variable (\texttt{island}) to two different aesthetics (\texttt{colour} and \texttt{shape}). This achieves two things. It makes it easier to differentiate the points, and it ensures a plot can be understood if printed in black and white.
\end{itemize}

There is lots of information in this plot---for example, the association between flipper length and body mass is weakly positive, sexual dimorphism in body size seems to be greatest in Gentoo penguins, and the Adelie species is the only one present on all three islands.

\hypertarget{doing-more-with-ggplot2}{%
\chapter{\texorpdfstring{Doing more with \textbf{ggplot2}}{Doing more with ggplot2}}\label{doing-more-with-ggplot2}}

We have now seen a range of different ways to visualise and explore data using \textbf{ggplot2}. This last chapter will cover a few bits of miscellanea that don't particularly fit anywhere else. That doesn't mean the ideas aren't important!

\hypertarget{summaries}{%
\section{Comparing descriptive statistics}\label{summaries}}

So far, we have focussed on displaying the raw data (e.g.~scatter plots) or a distributional summary (e.g.~box plots). What other types of quantities might we need to visualise? Descriptive statistics such as the sample mean are one possibility. These often feature in data analysis when `comparing groups'.

We need to know how to construct plots that display such summaries. Let's start with a simple question: how does the (arithmetic) mean body mass varies by sex and across penguin species? One option is to produce a bar plot for which the lengths of bars represent the mean body mass in each category.

There are two different routes to produce this with \textbf{ggplot2}. One way to build such a plot is to break the problem into two steps. In the first step, we calculate whatever it is we want to display, i.e.~the species- and sex-specific mean body mass. \textbf{dplyr} is usually the best tool to use for this first step:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_summary }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# group data by species and penguins}
  \FunctionTok{group\_by}\NormalTok{(species, sex) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# calculate mean body mass}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{mean\_mass =} \FunctionTok{mean}\NormalTok{(body\_mass\_g)) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# remove rows generated by sex = NA cases}
  \FunctionTok{na.omit}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'species'. You can override using the `.groups` argument.
\end{verbatim}

We used \texttt{group\_by} and \texttt{summarise} to calculate the set of means, which we decided to call \texttt{mean\_mass}. Notice that we used \texttt{na.omit} to exclude the \texttt{NA} categories that arise when sex is unknown. The resulting \texttt{penguins\_summary} object is a small 6 row by 3 column tibble:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# show the summary data}
\NormalTok{penguins\_summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
## # Groups:   species [3]
##   species   sex    mean_mass
##   <chr>     <chr>      <dbl>
## 1 Adelie    female     3369.
## 2 Adelie    male       4043.
## 3 Chinstrap female     3527.
## 4 Chinstrap male       3939.
## 5 Gentoo    female     4680.
## 6 Gentoo    male       5485.
\end{verbatim}

The second step uses \texttt{penguins\_summary} with \textbf{ggplot2} to create the required bar plot:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of body mass means}
\FunctionTok{ggplot}\NormalTok{(penguins\_summary,}
       \CommentTok{\# aesthetic mappings: mass (y) vs species (x) by sex (fill)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{fill =}\NormalTok{ sex, }\AttributeTok{y =}\NormalTok{ mean\_mass)) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_col to add bar plot layer \textquotesingle{}as is\textquotesingle{} with adjacent bars}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mean body mass (g)"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Sex"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-261-1} \end{center}

Two points about this are worth noting:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  We used \texttt{geom\_col} instead of \texttt{geom\_bar}. \texttt{geom\_bar} counts the observations in each category by default. Using \texttt{geom\_col} tells \textbf{ggplot2} to plot the information in \texttt{mean\_mass} `as is'.
\item
  We paid close attention to the names of things. The plotting data lives in \texttt{penguins\_summary} which means the y aesthetic must be associated with \texttt{mean\_mass} rather than \texttt{body\_mass\_g}.
\end{enumerate}

It is possible to produce this plot with less code by using \textbf{ggplot2}'s built-in `stat' facility (see box). We recommend the long-winded way when starting out with R because it makes it a bit easier to fix mistakes---we can check whether the right information is in a summary data set before plotting it.

\begin{infobox}{information}

\hypertarget{using-ggplot2-stats}{%
\subsubsection*{\texorpdfstring{Using \textbf{ggplot2} `stats'}{Using ggplot2 `stats'}}\label{using-ggplot2-stats}}
\addcontentsline{toc}{subsubsection}{Using \textbf{ggplot2} `stats'}

Another way to arrive at the above bar plot is by using the built-in \textbf{ggplot2} \texttt{stat} facility:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of body mass means}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{na.omit}\NormalTok{(penguins), }\CommentTok{\# \textless{}{-} remove missing values}
       \CommentTok{\# aesthetic mappings: mass (y) vs species (x) by sex (fill)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{fill =}\NormalTok{ sex, }\AttributeTok{y =}\NormalTok{ body\_mass\_g)) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_bar to add bar plot layer using a stats summary}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"summary"}\NormalTok{, }\AttributeTok{fun=}\NormalTok{mean, }\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mean body mass (g)"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Sex"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-262-1} \end{center}

This involves a couple of new tricks. When we add a layer using \texttt{geom\_bar} we set two additional arguments:

\begin{itemize}
\tightlist
\item
  \texttt{stat\ =\ "summary"} tells \textbf{ggplot2} not to plot the raw values of the y aesthetic mapping, but instead, to calculate and then plot a summary of the `y' variable.
\item
  \texttt{fun\ =\ mean} tells \textbf{ggplot2} how to summarise the `y' variable. The name of the function on the right-hand side can be any function that takes a vector of values as input and returns a summary. We want the \texttt{mean} function.
\end{itemize}

Notice that this works on the raw data (\texttt{penguins})---there is no need to manually calculate the means because that happens inside \textbf{ggplot2}.

\end{infobox}

\hypertarget{error-bars}{%
\subsection{Error bars}\label{error-bars}}

A descriptive statistic like the mean isn't much use on its own. To properly interpret means we also need to know something about their uncertainty. There are many ways to quantify the uncertainty of an estimate. Whichever one we are using, displaying the uncertainty typically involves adding \textbf{error bars} to a plot.

We'll demonstrate how to do this by extending the previous example to show the mean and standard error of body mass for each species.

\begin{infobox}{information}

\hypertarget{er.-standard-error}{%
\subsubsection*{Er\ldots. standard error?}\label{er.-standard-error}}
\addcontentsline{toc}{subsubsection}{Er\ldots. standard error?}

The standard error is a measure of how precise an estimate like the sample mean is. A small standard error indicates that we can have more confidence the estimate reflects the `true' value. The standard error of the mean can be calculated from a well-known formula: \[
\text{Standard Error} = \frac{\text{Standard Deviation}}{\sqrt{(\text{Sample Size})}} = \frac{\sigma}{\sqrt{n}}
\] It is hard to give an explanation of that formula without knowing a bit of statistical theory---it is just one of those things we have to learn. In terms of code that works with \textbf{dplyr}, that calculation looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standard\_error }\OtherTok{=} \FunctionTok{sd}\NormalTok{(x) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

This assumes the numeric variable we are working with is called \texttt{x}, and we want the result to be called \texttt{standard\_error}. Notice this uses a special \textbf{dplyr} function called \texttt{n} to find the sample size.

\end{infobox}

Once again, constructing the plot is a two-step process. Start by calculating the means and standard error of body mass for each species and sex combination:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_summary }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# group data by species and penguins}
  \FunctionTok{group\_by}\NormalTok{(species, sex) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# calculate summaries}
  \FunctionTok{summarise}\NormalTok{(}
    \CommentTok{\# mean mass}
    \AttributeTok{mean\_mass =} \FunctionTok{mean}\NormalTok{(body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
    \CommentTok{\# standard error}
    \AttributeTok{ster\_mass =} \FunctionTok{sd}\NormalTok{(body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{())}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# remove rows generated by sex = NA cases}
  \FunctionTok{na.omit}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'species'. You can override using the `.groups` argument.
\end{verbatim}

We use \textbf{dplyr} to calculate the means and standard errors of each species' body mass, which we called \texttt{mean\_mass} and \texttt{ster\_mass}, respectively. Again, we used \texttt{na.omit} to exclude the \texttt{NA} categories cases. The new \texttt{penguins\_summary} object is a 6 row by 4 column tibble:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# show the new summary data}
\NormalTok{penguins\_summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
## # Groups:   species [3]
##   species   sex    mean_mass ster_mass
##   <chr>     <chr>      <dbl>     <dbl>
## 1 Adelie    female     3369.      31.5
## 2 Adelie    male       4043.      40.6
## 3 Chinstrap female     3527.      48.9
## 4 Chinstrap male       3939.      62.1
## 5 Gentoo    female     4680.      37.0
## 6 Gentoo    male       5485.      40.1
\end{verbatim}

Next we use \texttt{penguins\_summary} to make the plot. We can use \texttt{geom\_col} to show the means as a bar plot, but what about the error bars? Use the unsurprisingly named \texttt{geom\_errorbar} to add those! Here is the code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of body mass means + SE\textquotesingle{}s}
\FunctionTok{ggplot}\NormalTok{(penguins\_summary, }
       \CommentTok{\# aesthetic mappings: mass (y) vs species (x) by sex (fill)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{fill =}\NormalTok{ sex, }\AttributeTok{y =}\NormalTok{ mean\_mass)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_col to add an adjacent bar plot layer}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_errorbar to add an error bar layer}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean\_mass }\SpecialCharTok{{-}}\NormalTok{ ster\_mass, }\AttributeTok{ymax =}\NormalTok{ mean\_mass }\SpecialCharTok{+}\NormalTok{ ster\_mass),}
                \CommentTok{\# customise size of hat + ensure error bars are centred}
                \AttributeTok{width =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.9}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# use a more professional theme }
  \FunctionTok{theme\_classic}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{12}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mean body mass (g)"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Sex"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-266-1} \end{center}

The only new things appear in the \texttt{geom\_errorbar} part:

\begin{itemize}
\tightlist
\item
  The \texttt{ymin} and \texttt{ymax} arguments of the \texttt{geom\_errorbar} function give the lower and upper limits of error bars. Here, we have plotted the mean +/- 1 standard error, i.e.~each error bar is two standard errors long.
\item
  Use the \texttt{width} argument to set the width of the `hat' on each error bar. A value of zero gets rid of it altogether.
\item
  The position has to be set in two places: \texttt{geom\_col} and \texttt{geom\_errorbar}. For a bar plot, we use the not-at-all-intuitive \texttt{position\ =\ position\_dodge(0.9)} to locate the error bars at the centre of each bar.
\end{itemize}

\begin{infobox}{warning}

\hypertarget{warning-1}{%
\subsubsection*{Warning!}\label{warning-1}}
\addcontentsline{toc}{subsubsection}{Warning!}

Data visualisations can include many different kinds of `error bar'--- standard deviation, standard error, 95\% confidence intervals, etc. When we include any error bars on a plot, we must remember to state which kind was used in the figure legend. Otherwise, readers will have no way of knowing how to interpret the plot.

\end{infobox}

\hypertarget{alternatives-to-bar-plots}{%
\subsection{Alternatives to bar plots}\label{alternatives-to-bar-plots}}

Do we have to use a bar plot to display means? Certainly not. In some ways bar plots are a bit old fashioned. People often prefer to show a set of means as points with error bars. This kind of visualisation is very easy to make now that we already have working bar plot code:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display points plot of body mass means + SE\textquotesingle{}s}
\FunctionTok{ggplot}\NormalTok{(penguins\_summary, }
       \CommentTok{\# aesthetic mappings: mass (y) vs species (x) by sex (colour)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{colour =}\NormalTok{ sex, }\AttributeTok{y =}\NormalTok{ mean\_mass)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_col to add an adjacent bar plot layer}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+}
  \CommentTok{\# use geom\_errorbar to add an error bar layer}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean\_mass }\SpecialCharTok{{-}}\NormalTok{ ster\_mass, }\AttributeTok{ymax =}\NormalTok{ mean\_mass }\SpecialCharTok{+}\NormalTok{ ster\_mass),}
                \CommentTok{\# customise size of hat + ensure error bars are centred}
                \AttributeTok{width =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.5}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# use a more professional theme }
  \FunctionTok{theme\_classic}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{12}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mean body mass (g)"}\NormalTok{, }\AttributeTok{colour =} \StringTok{"Sex"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-268-1} \end{center}

We made three small changes to the bar plot code to produce this. We\ldots{}

\begin{itemize}
\tightlist
\item
  mapped \texttt{sex} to the \texttt{colour} aesthetic instead of \texttt{fill},
\item
  switched from using \texttt{geom\_col} to \texttt{geom\_point}, and
\item
  altered the position adjustments to `dodge' by a smaller amount.
\end{itemize}

That's it!

\hypertarget{adding-text-annotations}{%
\section{Adding text annotations}\label{adding-text-annotations}}

We often need to include text annotations on a plot. For example, we might want to show sample sizes or highlight `statistically significant' differences. Adding text is no different from adding other kinds of objects to a plot---we use an appropriate geom (e.g.~\texttt{geom\_text}) to include textual information. Let's see how this works by adding sample size labels the bar chart we've been building.

We start by placing the labels we want to use in a data frame (or tibble) alongside any other variables used in aesthetic mappings. This can be distinct from the data set used to construct the plot but its often simplest to put everything together in one place. Let's do that by rebuilding the \texttt{penguins\_summary} data set to include the mean body mass, standard error and sample size for each group.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{penguins\_summary }\OtherTok{\textless{}{-}}\NormalTok{ penguins }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# group data by species and penguins}
  \FunctionTok{group\_by}\NormalTok{(species, sex) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# calculate summaries}
  \FunctionTok{summarise}\NormalTok{(}
    \CommentTok{\# mean mass}
    \AttributeTok{mean\_mass =} \FunctionTok{mean}\NormalTok{(body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
    \CommentTok{\# sample size}
    \AttributeTok{samp\_size =} \FunctionTok{n}\NormalTok{(),}
    \CommentTok{\# standard error}
    \AttributeTok{ster\_mass =} \FunctionTok{sd}\NormalTok{(body\_mass\_g, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{n}\NormalTok{())}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%} 
  \CommentTok{\# remove rows generated by sex = NA cases}
  \FunctionTok{na.omit}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'species'. You can override using the `.groups` argument.
\end{verbatim}

Then we add the text showing the sample size to our plot using the function \texttt{geom\_text}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# display bar plot of body mass means + SE\textquotesingle{}s + sample sizes}
\FunctionTok{ggplot}\NormalTok{(penguins\_summary, }
       \CommentTok{\# aesthetic mappings: mass (y) vs species (x) by sex (fill)}
       \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{fill =}\NormalTok{ sex, }\AttributeTok{y =}\NormalTok{ mean\_mass)) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_col to add an adjacent bar plot layer}
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# use geom\_errorbar to add an error bar layer}
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean\_mass }\SpecialCharTok{{-}}\NormalTok{ ster\_mass, }\AttributeTok{ymax =}\NormalTok{ mean\_mass }\SpecialCharTok{+}\NormalTok{ ster\_mass),}
                \CommentTok{\# customise size of hat + ensure error bars are centred}
                \AttributeTok{width =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.9}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# place sample size annotations above error bars}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ samp\_size, }\AttributeTok{y =}\NormalTok{ mean\_mass }\SpecialCharTok{+}\NormalTok{ ster\_mass }\SpecialCharTok{+} \DecValTok{200}\NormalTok{),}
            \AttributeTok{size =} \DecValTok{3}\NormalTok{, }\AttributeTok{colour =} \StringTok{"darkgrey"}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.9}\NormalTok{)) }\SpecialCharTok{+} 
  \CommentTok{\# use a more professional theme }
  \FunctionTok{theme\_classic}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{12}\NormalTok{) }\SpecialCharTok{+} 
  \CommentTok{\# specify labels for all mappings}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mean body mass (g)"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Sex"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-270-1} \end{center}

The \texttt{y\ =\ mean\_mass\ +\ ster\_mass\ +\ 200} aesthetic mapping in \texttt{geom\_text} positions each number just above the error bar. This works because we placed the textual information in the plotting data set, meaning we can use the x/y variables to set the position of the annotations. We also have to use the correct position adjustment to ensure the annotations are located at each bar's centre. Everything else inside \texttt{geom\_text} is adjusting the appearance of the actual text.

\hypertarget{saving-plots}{%
\section{Saving plots}\label{saving-plots}}

Plots can be saved using the \textbf{Export} button in the RStudio \textbf{Plots} tab. However, saving plots this way often leads to a pixelated, low resolution image. The \texttt{ggsave} function in \textbf{ggplot2} produces much better output and supports a wide range of image file types. There's not much to it. Using \texttt{ggsave} looks like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"penguins{-}plot.pdf"}\NormalTok{, }\AttributeTok{height =} \DecValTok{5}\NormalTok{, }\AttributeTok{width =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

By default, \texttt{ggsave} will save the last plot we made to file. If we had made the bar chart and then ran that \texttt{ggsave} line, R would save a copy of the plot to as a PDF file called \href{images/penguins-plot.pdf}{penguins-plot.pdf}.

Here is a quick summary of how the function works:

\begin{itemize}
\item
  The first argument is the path and name of the file we want to create. This example would save the plot to a file called \underline{penguins-plot.pdf}. Because we only provide a file name, \texttt{ggsave} would save it to the current working directory.
\item
  \texttt{ggsave} supports many different formats (e.g.~``pdf'', ``jpeg'', ``png'', ``svg''). This can be set via the \texttt{device} argument (e.g.~\texttt{device\ =\ "jpeg"}). Alternatively, if we don't set the format, \textbf{ggplot2} will guess it from the file extension.
\item
  The \texttt{width} and \texttt{height} arguments specify the plot dimensions. These usually require a bit of experimentation to get right. If we do not specify them, \texttt{ggsave} will use the current size of the plotting window.
\end{itemize}

\hypertarget{multi-panel-plots}{%
\section{Multi-panel plots}\label{multi-panel-plots}}

We have seen how to use \texttt{facet\_wrap} and \texttt{facet\_grid} to produce multi-panel plots. These functions are useful when a plot needs to show the same visualisation for different subsets of data. How do we produce a figure that shows a different visualisation in each panel?

There are many ways to do this using an external add-on package. We'll examine the framework provided by the \href{https://wilkelab.org/cowplot/articles/index.html}{\textbf{cowplot} package}. Cowplot provides various features that help create high-quality figures, including custom themes and facilities to arrange plots into multi-panel figures.

Constructing a multi-panel plot with \textbf{cowplot} happens in two stages. First, make the individual component plots using \textbf{ggplot2} as usual, but instead of `printing' them, assign each graphical object a name. Then use the \texttt{plot\_grid} function from \textbf{cowplot} to construct the multi-panel plot from the stored objects.

For example, assume we want to display at the bill morphology scatter plot and the mean body mass bar chart side-by-side. First we make the two plots assign them names (with minimal commenting to save space):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# first plot}
\NormalTok{plt\_a }\OtherTok{\textless{}{-}} 
  \FunctionTok{ggplot}\NormalTok{(penguins, }
         \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ bill\_length\_mm, }\AttributeTok{y =}\NormalTok{ bill\_depth\_mm, }\AttributeTok{colour =}\NormalTok{ species)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"cornflowerblue"}\NormalTok{, }\StringTok{"seagreen"}\NormalTok{, }\StringTok{"orangered3"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Bill length (mm)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Bill depth (mm)"}\NormalTok{, }\AttributeTok{colour =} \StringTok{"Species"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{12}\NormalTok{)}
\CommentTok{\# second plot}
\NormalTok{plt\_b }\OtherTok{\textless{}{-}} 
  \FunctionTok{ggplot}\NormalTok{(penguins\_summary, }
         \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ species, }\AttributeTok{fill =}\NormalTok{ sex, }\AttributeTok{y =}\NormalTok{ mean\_mass)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_col}\NormalTok{(}\AttributeTok{position =} \StringTok{"dodge"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_errorbar}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{ymin =}\NormalTok{ mean\_mass }\SpecialCharTok{{-}}\NormalTok{ ster\_mass, }\AttributeTok{ymax =}\NormalTok{ mean\_mass }\SpecialCharTok{+}\NormalTok{ ster\_mass), }
                \AttributeTok{width =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.9}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Species"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Mean body mass (g)"}\NormalTok{, }\AttributeTok{fill =} \StringTok{"Sex"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_classic}\NormalTok{(}\AttributeTok{base\_size =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Then we use \textbf{cowplot}'s \texttt{plot\_grid} to produce the two-panel plot:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_grid}\NormalTok{(}
  \CommentTok{\# two{-}panel plot}
\NormalTok{  plt\_a, plt\_b, }
  \CommentTok{\# set location and size of panels}
  \AttributeTok{nrow =} \DecValTok{1}\NormalTok{, }\AttributeTok{rel\_widths =} \FunctionTok{c}\NormalTok{(}\DecValTok{60}\NormalTok{, }\DecValTok{40}\NormalTok{), }
  \CommentTok{\# set the panel labels}
  \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"a)"}\NormalTok{, }\StringTok{"b)"}\NormalTok{), }\AttributeTok{label\_size =} \DecValTok{14}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{intro-bio-data-book_files/figure-latex/unnamed-chunk-273-1} \end{center}

Once we've made a multi-panel plot, we can use the \texttt{ggsave} function to save it as before. The \texttt{plot\_grid} function allows the figure to be customised in various ways. For example:

\begin{itemize}
\tightlist
\item
  \texttt{nrow} and \texttt{ncol} control the number of plots in each row/column,
\item
  \texttt{labels} sets the labels used for each panel,
\item
  \texttt{label\_size} controls the size of the label font, and
\item
  \texttt{rel\_widths} and \texttt{rel\_heights} control how much space each plot gets.
\end{itemize}

The package website has some \href{https://wilkelab.org/cowplot/articles/index.html}{good articles} that explain how this all works (along with the many other \textbf{cowplot} facilities).

\hypertarget{appendix-supplementary-material}{%
\appendix}


\hypertarget{getting-help}{%
\chapter{Getting help}\label{getting-help}}

\hypertarget{console-help}{%
\section{Introduction}\label{console-help}}

R has a comprehensive built-in help system orientated around the base R functions, and every good external package also comes with its own set of \textbf{help files}. These provide information about individual package functions and summarise the included data sets. They also sometimes give descriptions of how different parts of the package should be used, and if we're lucky, one or more `vignettes' that offer a practical demonstration of how to use the package.

We may as well get something out of the way early on. The word `help' in the phrase `help file' is a bit of a misnomer. It's more accurate to say R has an extensive \textbf{documentation} system. Help files are designed first and foremost to carefully document the different elements of a package, rather than explain how a particular function or the package as whole should be used to achieve a given end. They are aimed more at experienced users than novices. That said, help files often contain useful examples, and many package authors do try to make our life easier by providing functional demonstrations of their package.

It is important to get to grips with the built in help system. It contains a great deal of useful information which we need to really start using R effectively. The road to enlightenment is bumpy though.

\hypertarget{browsing-the-help-system}{%
\section{Browsing the help system}\label{browsing-the-help-system}}

Help files are a little like mini web pages, which means we can navigate among them using hyperlinks. One way to begin browsing the help system uses the \texttt{help.start} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help.start}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

When we run this function the \textbf{Package Index} page should open up in the \textbf{Help} tab of the bottom right pane in RStudio. This lists all the packages currently installed on a computer. We can view the help files associated with a package by clicking on the appropriate link. For example, all the functions that come with the base installation of R have a help file associated with them---we can click on the link to the R base package (\texttt{base}) to see these.

The packages that we install separately each have their own set of associated help files. We will see how to navigate these in a moment.

The help browser has Forward, Back, and Home buttons, just like a normal web browser. If we get lost in the mire of help pages we can always navigate backward until we get back to a familiar page. Clicking on the home button takes us to a page with three sections:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The \textbf{Manuals} section looks like it might be useful for novice users. Unfortunately, it's not. Even the ``Introduction to R'' manual is only helpful for someone who understands what terms like `data structure' and `data type' mean. The others are more or less impenetrable unless the reader already knows quite a bit about computing in general.
\item
  The \textbf{Reference} section is a little more helpful. The ``Packages'' link takes us to the same page opened by \texttt{help.start}. From here we can browse the help pages on a package-specific basis. The ``Search Engine \& Keywords'' link takes us to a page we can use to search for specific help pages, either by supplying a search term or by navigating through the different keywords.
\item
  The \textbf{Miscellaneous Material} section has a couple of potentially useful links. The ``User Manuals'' link lists any user manuals supplied by package authors. The ``Frequently Asked Questions'' link is definitely worth reviewing at some point, tough again, most of the FAQs are a little difficult for novice users to fully understand.
\end{enumerate}

\hypertarget{searching-for-help-files}{%
\section{Searching for help files}\label{searching-for-help-files}}

After browsing help files via \texttt{help.start} for a bit it quickly becomes apparent that this way of searching for help is very inefficient. We often know the name of the function we need to use and all we want to do is open that particular help file. We can do this using the \texttt{help} function:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help}\NormalTok{(}\AttributeTok{topic =}\NormalTok{ Trig)}
\end{Highlighting}
\end{Shaded}

After we run this line RStudio opens up the help file for the trigonometry topic in the \textbf{Help} tab. This file provides information about the various trigonometric functions such as \texttt{sin} or \texttt{cos} (we'll see how to make sense of such help pages in a bit).

The \texttt{help} function needs a minimum of one argument: the name of the topic or function of interest. When we use it like this the help function searches across packages, looking for a help file whose name gives \textbf{an exact match} to the name we supplied. In this case, we opened the help file associated with the \texttt{Trig} topic.

Most of the time we use the \texttt{help} function to find the help page for a specific function, rather than a general topic. This is fine if we can remember the name of the topic associated with different functions. Most of us cannot. Luckily, the help function will also match help pages by the name of the function(s) they cover:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help}\NormalTok{(}\AttributeTok{topic =}\NormalTok{ sin)}
\end{Highlighting}
\end{Shaded}

Here we searched for help on the \texttt{sin} function. This is part of the \texttt{Trig} topic so \texttt{help(topic\ =\ sin)} brings up the same page as the \texttt{help(topic\ =\ Trig)}.

By default, the \texttt{help} function only searches for files associated with the base functions or with packages that we have loaded in the current session with the \texttt{library} function. If we want to search for help on the \texttt{mutate} function---part of the \textbf{dplyr} package---but we haven't run \texttt{library(dplyr)} in the current session this will fail:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help}\NormalTok{(mutate)}
\end{Highlighting}
\end{Shaded}

Instead, we need tell \texttt{help} where to look by setting the \texttt{package} argument:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{help}\NormalTok{(mutate, }\AttributeTok{package =} \StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Even very experienced R users regularly forget how to use the odd function and have to dive into the help. It's for this reason that R has a built in shortcut for \texttt{help} accessed via \texttt{?}. For example, instead of typing \texttt{help(topic\ =\ sin)} into the Console we can bring up the help page for the \texttt{sin} function by using \texttt{?} like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{?sin}
\end{Highlighting}
\end{Shaded}

This is just a convenient shortcut that does the same thing as \texttt{help}. The only difference is that \texttt{?} does not allow us to set arguments such as \texttt{package}.

\hypertarget{nav-help}{%
\section{Navigating help files}\label{nav-help}}

Navigating help files is a little daunting at first. These files can be quite long and contain a lot of technical jargon. The help files associated with functions---the most common type---do at least have a consistent structure with a number of distinct sections. Wrestling with a help file is much easier if we at least understand what each section is for. After the title, there are eight sections we need to know about:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Description} gives us a short overview of what the function is meant to be used for. If the help page covers a family of related functions it gives a collective overview of all the functions. Always read this before diving into the rest of the help file.
\item
  \textbf{Usage} shows how the function(s) are meant to be used. It lists each member of the family as well as their common arguments. The argument names are listed on their own if they have no default, or in name-value pairs, where the value gives the default should we choose not to set it ourselves.
\item
  \textbf{Arguments} lists the allowed arguments along with a short description of what they do. This also tells us what what kind of data we're allowed to use with each argument, along with the allowable values (if relevant). Always read this section.
\item
  \textbf{Details} describes precisely how the function(s) behave, often in painful detail. This is often the hardest-to-comprehend section. We can sometimes get away with ignoring this section but when we really want to understand a function we need to wade through it.
\item
  \textbf{Value} explains what kind of object a function returns when it finishes doing whatever it does. We can often possible to guess what this will be from the type of function, but nonetheless, it is a good idea to check whether our reasoning is correct.
\item
  \textbf{References} just lists the key reference(s) for when if we really need to know the `hows' and `whys' of a function. We can usually skip this information. The one exception is if the function implements a particular analysis tool. It's best to know how such tools work before trying to use them.
\item
  \textbf{See Also} gives links to the help pages of related functions. These are usually functions that do something similar to the function of interest or are meant to be used in conjunction with it. We can often learn quite a bit about packages or related functions by following the links in this section.
\item
  \textbf{Examples} provides one or more examples of how to use the function. These are stand-alone examples, so there's nothing to stop us running them. This is often the most useful section of all. Seeing a function in action is a very good way to cut through the jargon and understand how it works.
\end{enumerate}

\hypertarget{vignettes}{%
\section{Vignettes}\label{vignettes}}

The purpose of a package vignette is to provide a relatively brief, practical account of one or more of its features. Not all packages come with vignettes, though the best packages often do. We use the \texttt{vignette} function to view all the available vignettes in Rstudio. This will open up a tab that lists each vignette under their associated package name along with a brief description. A package will often have more than one vignette.

If we just want to see the vignettes associated with a particular package, we have to set the \texttt{package} argument. For example, to see the vignettes associated with \textbf{dplyr} we use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vignette}\NormalTok{(}\AttributeTok{package =} \StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Each vignette has a name (the ``topic'') and is available either as a PDF or HTML file (or both). We can view a particular vignette by passing the \texttt{vignette} function the \texttt{package} and \texttt{topic} arguments. For example, to view the ``grouping'' vignette in the \textbf{dplyr} package we would use:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vignette}\NormalTok{(}\AttributeTok{topic =} \StringTok{"grouping"}\NormalTok{, }\AttributeTok{package =} \StringTok{"dplyr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{vignette} function is fine, but it is more convenient to browse the list of vignettes inside a web browser. This allows us to open a particular vignette directly by clicking on its link, rather than working at the Console. We can use the \texttt{browseVignettes} function to do this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{browseVignettes}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This will open a page in our browser showing the vignettes we can view. As usual, we can narrow our options to a specific package by setting the \texttt{package} argument.

\hypertarget{project-scripts-data}{%
\chapter{Managing projects, scripts and data files}\label{project-scripts-data}}

Content will be added in block three.

  \bibliography{book.bib,packages.bib}

\end{document}
