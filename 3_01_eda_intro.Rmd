# Exploratory data analysis

## Introduction

Exploratory data analysis (EDA) was promoted by the statistician John Tukey in his 1977 book, "Exploratory Data Analysis". The broad goal of EDA is to help us formulate and refine hypotheses that lead to informative analyses or further data collection. The core objectives of EDA are:

-   to suggest hypotheses about the causes of observed phenomena,

-   to guide the selection of appropriate statistical tools and techniques,

-   to assess the assumptions on which statistical analysis will be based,

-   to provide a foundation for further data collection.

EDA involves a mix of numerical and visual methods of analysis. Statistical methods are sometimes used to supplement EDA. However, the main purpose of EDA is to facilitate understanding before diving into formal statistical modelling. Even if we think we already know what kind of analysis we need to pursue, it's always a good idea to **explore a data set before diving into the analysis**. At the very least, this will help determine whether or not our plans are sensible. Very often, it uncovers new patterns and insights.

In this chapter, we're going to examine some basic concepts that underpin EDA:

1.  classifying different **types of variables**, and
2.  distinguishing between **populations and samples**.

This will set us up to learn how to explore our data in later chapters.

## Statistical variables and data {#variables}

In the [Data frames](#chapter-data-frames) chapter, we pointed out that the word 'variable' can mean one of two things. In the context of programming, a variable is a name-value association that we create when we run some code. Statisticians use the word in a different way. To them, a variable is any characteristic or quantity that can be measured, classified or experimentally controlled. Much of statistics is about quantifying and explaining the variation in such quantities as best we can.

Species richness, relative abundance, infection status, enzyme activity, gene frequency, and blood glucose concentration are all examples of statistical variables we encounter in the biological sciences. These as statistical variables because their values vary between different observations. For example, 'annual fitness'---measured as the number of offspring produced---is a variable that differs both among the organisms in a population and over the life cycle of a given individual.

There are different ways to describe statistical variables according to the manner in which they can be analysed, measured, or presented. It's important to be clear about what kind of variables we're dealing with because this determines how we should visualise the data, and later, how we might analyse it statistically. There are many different ways to go about classifying variables. However, we only need to be aware of two fairly simple classification schemes in this book: numeric vs categorical variables and ratio vs interval scales (for numeric variables only).

### Numeric vs categorical variables

**Numeric variables** have values that describe a measurable quantity as a number, like 'how many' or 'how much'. Numeric variables are also called quantitative variables; the data collected containing numeric variables are called quantitative data. Numeric variables may be further described as either continuous or discrete:

-   **Continuous numeric variable**: Observations can take any value in a set of real numbers, i.e. numbers represented with decimals. This set is typically either 'every possible number' (e.g. the change in protein concentration can be positive or negative, and very large or very small) or 'all the positive numbers' (e.g. protein concentration may be very large or very small, but it is strictly positive). Examples of continuous variables include mass, age, time, and temperature.

-   **Discrete numeric variable**: Observations can take a value based on a count from a set of whole values, e.g. 1, 2, 3, 4, 5, and so on. A discrete variable cannot take the value of a fraction between one value and the next closest value. Examples of discrete variables include the number of individuals in a population, the number of offspring produced ('reproductive fitness'), and the number of infected individuals in an experiment. All of these are measured as whole units.

**Categorical variables** have values that describe a characteristic of a data unit, like 'what type' or 'which category'. Categorical variables fall into mutually exclusive (in one category or in another) and exhaustive (include all possible options) categories. Categorical variables are qualitative variables and tend to be represented by a non-numeric value; the data collected for a categorical variable are called qualitative data. Categorical variables may be further described as ordinal or nominal:

-   **Ordinal variable**: Observations can take a value that can be logically ordered or ranked. The categories associated with ordinal variables can be ranked higher or lower than another, but do not necessarily establish a numeric difference between each category. Examples of ordinal categorical variables include academic grades (e.g. A, B, C) and size classes (e.g. small, medium, large).

-   **Nominal variable**: Observations can take a value that is not able to be organised in a logical sequence. Examples of nominal categorical variables include sex (see *C. elegans* example), human blood group (A, B, AB and O), genotype (e.g. AA, Aa, aa), experimental conditions (e.g. control vs enhanced nutrition), and mortality status (alive vs dead).

::: {.infobox .warning data-latex="{warning}"}
#### Do not use numbers to classify categorical variables {.unnumbered}

Be careful when classifying variables. It is dangerous to assume that just because a numerical scheme has been used to describe it, a variable it must not be categorical. There is nothing to stop someone from using numbers to describe a categorical variable (e.g. *C. elegans* sex: Male = 1, Hermaphrodite = 2). That said, although we can use numbers to describe categories, it does not mean we should. Using numbers gets confusing and can lead to mistakes. It is much clearer to use a non-numeric recording scheme based on words or acronyms to record categorical variables (e.g. *C. elegans* sex: Male = "Male", Hermaphrodite = "Herm").
:::

### Ratio vs interval scales

A second way of classifying numeric variables (**not** categorical variables) relates to the scale they are measured on. The measurement scale is important because it determines how things like differences, ratios, and variability are interpreted.

-   **Ratio scale**: This scale does possess a meaningful zero value. It takes its name from the fact that a measurement on this scale represents a ratio between a measure of the magnitude of a quantity and a unit of the same kind. What this means in simple terms is that it is meaningful to say that something is "twice as ..." as something else when working with a variable measured on a ratio scales. Ratio scales most often appear when we work with physical quantities. For example, we can say that one tree is twice as big as another, or that one elephant has twice the mass of another, because length and mass are measured on ratio scales.

-   **Interval scale**: This allows for the degree of difference between measurements, but not the ratio between them. This kind of scale does not have a unique, non-arbitrary zero value. A good example of an interval scale is date, which we measure relative to an arbitrary epoch (e.g. AD). It makes no sense to say that 2000 AD is twice as long as 1000 AD. However, we can compare ratios of differences on an interval scale. For example, it does make sense to talk about the amount of time that has passed between two dates, i.e. we can to say that twice as much time has passed since the epoch in 2000 AD versus 1000 AD.

Keep in mind that the distinction between ratio and interval scales is a property of the scale of measurement, not the thing being measured. For example, when we measure temperature in ยบ C we're working on an interval scale defined relative to the freezing and boiling temperatures of water under standard conditions. It doesn't make any sense to say that 30ยบ C is twice as hot as 15ยบ C. However, if we measured the same two temperatures on the Kelvin scale, it is meaningful to say that 303.2K is 1.05 times hotter than 288.2K. This is because the Kelvin scale is relative to a true zero (absolute zero).

## Populations and samples {#populations-samples}

Whenever we collect data, we are working with a sample of objects from a wider population. We usually want to know something about the wider population, but since it is impossible to study every member of the population, we study the properties of one or more samples instead. For example, a physiologist might be interested in understanding how exercise habits affect human lung function. Since they obviously can't study every person on the planet, they have to study a (hopefully) representative sample of people.

The problem with using samples is that they are 'noisy'. If we were to repeat the same data collection protocol more than once, we expect to end up with a different sample each time, even if the wider population never changes. This results purely from chance variation in the creation of the sample. Picking apart the relationship between samples and populations is the basis of much of statistics. This topic is best dealt with in a dedicated statistics book---i.e. not this book.

The reason we mention the distinction between populations and samples now is that EDA is primarily concerned with exploring the properties of samples---i.e. EDA aims to characterise a sample without trying to say too much about the wider population from which it is derived.

### Sample distributions

When we say that 'EDA is primarily concerned with exploring the properties samples', we really mean EDA is concerned with the **exploring the properties of the variables in a sample**. In fact, we can be even more precise---when we talk about 'exploring a variable' what we are really alluding to is its **sample distribution**.

The sample distribution of a variable simply describes the relative frequency with which different values occur in the sample. Imagine we took a sample of undergraduates and measured their height. The majority of students would be around about 1.7m tall, even though there would obviously be plenty of variation among students. Men would tend to be slightly taller than women, and very small or very tall people would be rare. We know from experience that no one in this sample would be over 3 meters tall. These are all statements about a hypothetical sample distribution of undergraduate heights.

### Relationships

So far, we've been thinking about samples of one statistical variable. However, a sample may involve more than one variable. In reality, data analysis is often concerned with relationships among two or more variables. These relationships might involve the same (e.g. numeric vs numeric) or different (e.g. numeric vs categorical) types of variable. In either case, EDA is used to understand how the values of one variable in a sample depend on those of the other.

## Types of EDA

Our goal when exploring the sample distribution of a variable is to answer questions such as, *What are the most common values of the variable* and *How much do observations differ from one another*? Rather than simply describing these properties in verbal terms, as we did above, we want to describe in a more informative way. There are two ways to go about this:

1.  **Calculate descriptive statistics**. Descriptive statistics are used to quantify the basic features of a sample distribution. They provide simple summaries about the sample that can be used to make comparisons and draw preliminary conclusions. For example, we often use 'the mean' to summarise the 'most likely' values of a variable in a sample.

2.  **Construct graphical summaries**. Descriptive statistics are not much use on their own---a few numbers can't capture every aspect of a sample distribution. Graphical summaries are a powerful complement to descriptive statistics because they allow us to present a lot of information about a sample in a manner that is easy for people to understand.
